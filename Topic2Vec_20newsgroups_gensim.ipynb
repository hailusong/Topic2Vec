{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic2Vec_20newsgroups on Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyorient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. IMPORTING DOCS FROM 20 NEWSGROUPS DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['comp.sys.ibm.pc.hardware',\n",
    "'comp.sys.mac.hardware',\n",
    "'comp.windows.x',\n",
    "'rec.sport.baseball',\n",
    "'rec.sport.hockey',\n",
    "'sci.med',\n",
    "'sci.space',\n",
    "'soc.religion.christian']\n",
    "\n",
    "n_topics = len(categories)\n",
    "\n",
    "categories_source = {}\n",
    "\n",
    "for cat in categories:\n",
    "    categories_source[cat] = cat.replace('.', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comp.sys.ibm.pc.hardware': 'comp_sys_ibm_pc_hardware',\n",
       " 'comp.sys.mac.hardware': 'comp_sys_mac_hardware',\n",
       " 'comp.windows.x': 'comp_windows_x',\n",
       " 'rec.sport.baseball': 'rec_sport_baseball',\n",
       " 'rec.sport.hockey': 'rec_sport_hockey',\n",
       " 'sci.med': 'sci_med',\n",
       " 'sci.space': 'sci_space',\n",
       " 'soc.religion.christian': 'soc_religion_christian'}"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      remove=('headers', 'footers', 'quotes'),\n",
    "                                      categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.sys.ibm.pc.hardware comp_sys_ibm_pc_hardware\n",
      "comp.sys.mac.hardware comp_sys_mac_hardware\n",
      "comp.windows.x comp_windows_x\n",
      "rec.sport.baseball rec_sport_baseball\n",
      "rec.sport.hockey rec_sport_hockey\n",
      "sci.med sci_med\n",
      "sci.space sci_space\n",
      "soc.religion.christian soc_religion_christian\n"
     ]
    }
   ],
   "source": [
    "for i,j in categories_source.items():\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOTAL NUMBER OF DOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4744"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_docs = newsgroups_train.filenames.shape[0]\n",
    "n_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(newsgroups_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/home/aimladmin/scikit_learn_data/20news_home/20news-bydate-train/sci.space/61065',\n",
       "       '/home/aimladmin/scikit_learn_data/20news_home/20news-bydate-train/rec.sport.hockey/52618',\n",
       "       '/home/aimladmin/scikit_learn_data/20news_home/20news-bydate-train/comp.windows.x/67032',\n",
       "       ...,\n",
       "       '/home/aimladmin/scikit_learn_data/20news_home/20news-bydate-train/rec.sport.hockey/52576',\n",
       "       '/home/aimladmin/scikit_learn_data/20news_home/20news-bydate-train/soc.religion.christian/20809',\n",
       "       '/home/aimladmin/scikit_learn_data/20news_home/20news-bydate-train/soc.religion.christian/20733'],\n",
       "      dtype='<U96')"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4744"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hmmm. I seem to recall that the attraction of solid state record-\\nplayers and radios in the 1960s wasn't better performance but lower\\nper-unit cost than vacuum-tube systems.\\n\\n\\tMind you, my father was a vacuum-tube fan in the 60s (Switched\\nto solid-state in the mid-seventies and then abruptly died; no doubt\\nthere's a lesson in that) and his account could have been biased.\""
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             text          lemma  log_probability  stop?  isalpha?  \\\n",
      "0           Hello          hello            -20.0  False      True   \n",
      "1             the            the            -20.0   True      True   \n",
      "2               >              >            -20.0  False     False   \n",
      "3               <              <            -20.0  False     False   \n",
      "4           wolrd          wolrd            -20.0  False      True   \n",
      "5               !              !            -20.0  False     False   \n",
      "6              \\n             \\n            -20.0  False     False   \n",
      "7           Where          where            -20.0  False      True   \n",
      "8              we         -PRON-            -20.0   True      True   \n",
      "9             Are             be            -20.0  False      True   \n",
      "10            are             be            -20.0   True      True   \n",
      "11             Be             be            -20.0  False      True   \n",
      "12         become         become            -20.0   True      True   \n",
      "13          never          never            -20.0   True      True   \n",
      "14          today          today            -20.0  False      True   \n",
      "15  unfortunately  unfortunately            -20.0  False      True   \n",
      "16              ?              ?            -20.0  False     False   \n",
      "17             \\n             \\n            -20.0  False     False   \n",
      "18           Will           will            -20.0  False      True   \n",
      "19           that           that            -20.0   True      True   \n",
      "20            The            the            -20.0  False      True   \n",
      "21        Walnurs        walnurs            -20.0  False      True   \n",
      "22             or             or            -20.0   True      True   \n",
      "23           they         -PRON-            -20.0   True      True   \n",
      "24             or             or            -20.0   True      True   \n",
      "25             he         -PRON-            -20.0   True      True   \n",
      "26             or             or            -20.0   True      True   \n",
      "27            she         -PRON-            -20.0   True      True   \n",
      "28           join           join            -20.0  False      True   \n",
      "29             us         -PRON-            -20.0   True      True   \n",
      "30             as             as            -20.0   True      True   \n",
      "31              a              a            -20.0   True      True   \n",
      "32         lovely         lovely            -20.0  False      True   \n",
      "33           team           team            -20.0  False      True   \n",
      "34             's             's            -20.0  False     False   \n",
      "35          party          party            -20.0  False      True   \n",
      "\n",
      "    punctuation?  whitespace?  number?  out of vocab.?  \n",
      "0          False        False    False            True  \n",
      "1          False        False    False            True  \n",
      "2          False        False    False            True  \n",
      "3          False        False    False            True  \n",
      "4          False        False    False            True  \n",
      "5           True        False    False            True  \n",
      "6          False         True    False            True  \n",
      "7          False        False    False            True  \n",
      "8          False        False    False            True  \n",
      "9          False        False    False            True  \n",
      "10         False        False    False            True  \n",
      "11         False        False    False            True  \n",
      "12         False        False    False            True  \n",
      "13         False        False    False            True  \n",
      "14         False        False    False            True  \n",
      "15         False        False    False            True  \n",
      "16          True        False    False            True  \n",
      "17         False         True    False            True  \n",
      "18         False        False    False            True  \n",
      "19         False        False    False            True  \n",
      "20         False        False    False            True  \n",
      "21         False        False    False            True  \n",
      "22         False        False    False            True  \n",
      "23         False        False    False            True  \n",
      "24         False        False    False            True  \n",
      "25         False        False    False            True  \n",
      "26         False        False    False            True  \n",
      "27         False        False    False            True  \n",
      "28         False        False    False            True  \n",
      "29         False        False    False            True  \n",
      "30         False        False    False            True  \n",
      "31         False        False    False            True  \n",
      "32         False        False    False            True  \n",
      "33         False        False    False            True  \n",
      "34         False        False    False            True  \n",
      "35         False        False    False            True  \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# for quick reference goes to https://github.com/hailusong/lda2vec/blob/master/lda2vec/preprocess.py\n",
    "# nlp = spacy.load('en')\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser'])\n",
    "\n",
    "if 1 == 1:\n",
    "    parsed_review = nlp('Hello the > < wolrd!\\nWhere we Are are Be become never today unfortunately?\\nWill that The Walnurs or they or he or she join us as a lovely team\\'s party')\n",
    "    token_attributes = [(token.orth_,\n",
    "                     token.lemma_,\n",
    "                     token.prob,\n",
    "                     token.is_stop,\n",
    "                     token.is_alpha,\n",
    "                     token.is_punct,\n",
    "                     token.is_space,\n",
    "                     token.like_num,\n",
    "                     token.is_oov)\n",
    "                    for token in parsed_review]\n",
    "\n",
    "    df = pd.DataFrame(token_attributes,\n",
    "                      columns=['text',\n",
    "                               'lemma',\n",
    "                               'log_probability',\n",
    "                               'stop?',\n",
    "                               'isalpha?',\n",
    "                               'punctuation?',\n",
    "                               'whitespace?',\n",
    "                               'number?',\n",
    "                               'out of vocab.?'])\n",
    "\n",
    "    # df.loc[:, 'stop?':'out of vocab.?'] = (df.loc[:, 'stop?':'out of vocab.?']\n",
    "    #                                       .applymap(lambda x: 'Yes' if x else ''))\n",
    "\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase Modeling\n",
    "Code from [Modern NLP in Python](http://nbviewer.jupyter.org/github/skipgram/modern-nlp-in-python/blob/master/executable/Modern_NLP_in_Python.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_tokens = set()\n",
    "\n",
    "def punct_space(token):\n",
    "    \"\"\"\n",
    "    helper function to eliminate tokens\n",
    "    that are pure punctuation or whitespace\n",
    "    \"\"\"\n",
    "    \n",
    "    result = token.is_punct or token.is_space or token.is_stop or not token.is_alpha\n",
    "    # result = token.is_punct or token.is_space\n",
    "    if result:\n",
    "       removed_tokens.add(token.text)\n",
    "\n",
    "    return result\n",
    "\n",
    "def line_review(filename):\n",
    "    \"\"\"\n",
    "    generator function to read in reviews from the file\n",
    "    and un-escape the original line breaks in the text\n",
    "    \"\"\"\n",
    "    \n",
    "    with codecs.open(filename, encoding='utf_8') as f:\n",
    "        for review in f:\n",
    "            yield review.replace('\\\\n', '\\n')\n",
    "\n",
    "def line_asis(filename):\n",
    "    \"\"\"\n",
    "    generator function to read in reviews from the file\n",
    "    and un-escape the original line breaks in the text\n",
    "    \"\"\"\n",
    "    \n",
    "    # with codecs.open(filename, encoding='utf_8') as f:\n",
    "    with open(filename, 'r') as f:\n",
    "        # for line in f:\n",
    "        #     yield line\n",
    "        return [line.rstrip('\\n') for line in f]\n",
    "\n",
    "def line_sklearn_data(sklearn_data):\n",
    "    \"\"\"\n",
    "    generator function to read in sklearn data from the list\n",
    "    and un-escape the original line breaks in the text\n",
    "    \"\"\"\n",
    "    \n",
    "    for data in sklearn_data:\n",
    "        yield data.replace('\\\\n', '\\n').replace('\\n', ' ').lower()\n",
    "        # yield data\n",
    "    \n",
    "def line_sklearn_data_keepcase(sklearn_data):\n",
    "    \"\"\"\n",
    "    generator function to read in sklearn data from the list\n",
    "    and un-escape the original line breaks in the text\n",
    "    \"\"\"\n",
    "    \n",
    "    for data in sklearn_data:\n",
    "        yield data.replace('\\\\n', '\\n').replace('\\n', ' ')\n",
    "        # yield data\n",
    "    \n",
    "def lemmatized_sentence_corpus(sentences):\n",
    "    \"\"\"\n",
    "    generator function to use spaCy to parse reviews,\n",
    "    lemmatize the text, and yield sentences\n",
    "    \"\"\"\n",
    "    \n",
    "    for sent in nlp.pipe(sentences,\n",
    "                                  batch_size=10000, n_threads=4):\n",
    "        # for sent in parsed_review.sents:\n",
    "        # for sent in parsed_review:\n",
    "        yield ' '.join([token.lemma_ for token in sent if not punct_space(token)])\n",
    "\n",
    "def no_lemmatized_sentence_corpus(sentences):\n",
    "    \"\"\"\n",
    "    generator function to use spaCy to parse reviews,\n",
    "    lemmatize the text, and yield sentences\n",
    "    \"\"\"\n",
    "    \n",
    "    for sent in nlp.pipe(sentences,\n",
    "                                  batch_size=10000, n_threads=4):\n",
    "        # for sent in parsed_review.sents:\n",
    "        # for sent in parsed_review:\n",
    "        yield ' '.join([token.text for token in sent if not punct_space(token)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare corups in different flavours: with/without NLP, with/without Lemma, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4744it [00:00, 91037.43it/s]\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "\n",
    "if 1 == 1:\n",
    "    with codecs.open('./withoutnlp.txt', 'w', encoding='utf_8') as f:\n",
    "        for sentence in tqdm(line_sklearn_data(newsgroups_train.data)):\n",
    "            f.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking <class 'spacy.lang.en.English'> <class 'method'>\n",
      ">> >>hello my word. here am i again.\n",
      ">> >>where is it?\n",
      ">>0>>Hmmm. I seem to recall that the attraction of solid state record-\n",
      "players and radios in the 1960s wasn't better performance but lower\n",
      "per-unit cost than vacuum-tube systems.\n",
      "\n",
      "\tMind you, my father was a vacuum-tube fan in the 60s (Switched\n",
      "to solid-state in the mid-seventies and then abruptly died; no doubt\n",
      "there's a lesson in that) and his account could have been biased.\n",
      ">>1>>hmmm. i seem to recall that the attraction of solid state record- players and radios in the 1960s wasn't better performance but lower per-unit cost than vacuum-tube systems.  \tmind you, my father was a vacuum-tube fan in the 60s (switched to solid-state in the mid-seventies and then abruptly died; no doubt there's a lesson in that) and his account could have been biased.\n",
      ">>2a>>hello word\n",
      ">>2a>>\n",
      ">>2>>hmmm recall attraction solid state players radios better performance lower unit cost vacuum tube systems mind father vacuum tube fan switched solid state mid seventies abruptly died doubt lesson account biased\n",
      ">>3>>hmmm recall attraction solid state player radio good performance low unit cost vacuum tube system mind father vacuum tube fan switch solid state mid seventy abruptly die doubt lesson account bias\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "\n",
    "# nlp - https://spacy.io/api/language\n",
    "# https://spacy.io/usage/linguistic-features#section-sbd\n",
    "print('Checking {} {}'.format(type(nlp), type(nlp.pipe)))\n",
    "\n",
    "strs = ['Hello my word. Here am I again.', 'where is it?']\n",
    "\n",
    "for data in line_sklearn_data(strs):\n",
    "    print('>> >>{}'.format(data))\n",
    "\n",
    "print('>>0>>{}'.format(newsgroups_train.data[0]))\n",
    "\n",
    "for data in line_sklearn_data(newsgroups_train.data[0:1]):\n",
    "    print('>>1>>{}'.format(data))\n",
    "\n",
    "for data in no_lemmatized_sentence_corpus(line_sklearn_data(strs)):\n",
    "    print('>>2a>>{}'.format(data))\n",
    "\n",
    "for data in no_lemmatized_sentence_corpus(line_sklearn_data(newsgroups_train.data[0:1])):\n",
    "    print('>>2>>{}'.format(data))\n",
    "\n",
    "for data in lemmatized_sentence_corpus(line_sklearn_data(newsgroups_train.data[0:1])):\n",
    "    print('>>3>>{}'.format(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4744it [01:57, 40.34it/s]\n",
      "4744it [01:58, 39.91it/s]\n"
     ]
    }
   ],
   "source": [
    "if 1 == 1:\n",
    "    with codecs.open('./withnlp-nolemma.txt', 'w', encoding='utf_8') as f:\n",
    "        for sentence in tqdm(no_lemmatized_sentence_corpus(line_sklearn_data(newsgroups_train.data))):\n",
    "            f.write(sentence + '\\n')\n",
    "\n",
    "    with codecs.open('./withnlp-lemma.txt', 'w', encoding='utf_8') as f:\n",
    "        for sentence in tqdm(lemmatized_sentence_corpus(line_sklearn_data(newsgroups_train.data))):\n",
    "            f.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4744it [00:00, 96856.34it/s]\n"
     ]
    }
   ],
   "source": [
    "if 1 == 1:\n",
    "    with codecs.open('./withoutnlp-keepcase.txt', 'w', encoding='utf_8') as f:\n",
    "        for sentence in tqdm(line_sklearn_data_keepcase(newsgroups_train.data)):\n",
    "            f.write(sentence + '\\n')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_directory = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_sentences_filepath = os.path.join(intermediate_directory,\n",
    "                                          'unigram_sentences_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 µs, sys: 1e+03 ns, total: 11 µs\n",
      "Wall time: 14.5 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 0 == 1:\n",
    "    removed_tokens = set()\n",
    "    print('Original >>>')\n",
    "    print(newsgroups_train.data[1:2])\n",
    "\n",
    "    print('New >>>')\n",
    "    for sentence in tqdm(lemmatized_sentence_corpus(line_sklearn_data(newsgroups_train.data[1:2]))):\n",
    "        print(sentence + '\\n')\n",
    "\n",
    "    print(removed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4744it [02:00, 39.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min, sys: 18.1 s, total: 3min 18s\n",
      "Wall time: 2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 1 == 1:\n",
    "    with codecs.open(unigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "        for sentence in tqdm(lemmatized_sentence_corpus(line_sklearn_data(newsgroups_train.data))):\n",
    "            f.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_sentences = LineSentence(unigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right suppose problem xmncolormap xtncolormap truly literate being set want start application new colormap chicken egg sort problem look xt faq example let know maybe improve example\n",
      "\n",
      "read right say essence large economy nation discretionary fund waste lunar facility certainly partially case apollo real lunar colony probably require continue military scientific commercial reason money approach conceivable luna military purpose possible luna commercial purpose likely luna scientific purpose year lunar base predicate funding level little different find antarctic base person base moon million year use grad student gary\n",
      "\n",
      "probably mean blood pressure go treadmill normal ask mean answer person gordon bank skepticism chastity intellect shameful surrender soon\n",
      "\n",
      "hey folk course develope x window application encounter problem transform x window bitmap postscript file library routine source code job\n",
      "\n",
      "post game interview larussa claim sparky good manager basebal explain history sparky soften blow lose tiger tim timothy law snyder department computer science reiss georgetown university washington dc\n",
      "\n",
      "united state tv schedule april devil islander pittsburgh est abc eastern time zone april st louis chicago cdt abc cent mou time zone april los angele calgary pdt abc pacific time zone april devil islander pittsburgh espn april tba espn april tba espn somebody send cbc tsn schedule post\n",
      "\n",
      "answer get reflex sympathetic dystrophy forever hope good job reattach hope know month gordon bank skepticism chastity intellect shameful surrender soon\n",
      "\n",
      "tell message come try lead edge flaky motherboard friend game replace doc mother board cheertron board award bio sticker say vi tell switch blue block mean fdc sh idea jumper replace hard drive modem instal math co process bit league doc lose help appreciate news regularly help e mail thank\n",
      "\n",
      "wife breast feed boy month month month respectively year old respectively far everybody fairly normal notice negative correlation ear infection length time nurse small sample notice year old eat lot breast feeding understand unfit mother charge tactic low folk divorce child custody battle develop nation practice breast feed year old screw good use cow milk commercial formula doctor\n",
      "\n",
      "okay try install ncsa telnet couple okay bunch machine true blue ibms fallon phonenet card dastar card belive name correct doc telnet run appletalk driver little success succesfully instal telnet appletalk like help config file telnet btw reply e mail possible thank jeremy jeremy zawodny computer science undergrad bowl green state university\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print a few example lemmatized sentences\n",
    "for unigram_sentence in it.islice(unigram_sentences, 230, 240):\n",
    "    print(' '.join(unigram_sentence))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_model_filepath = os.path.join(intermediate_directory, 'bigram_model_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.04 s, sys: 60.5 ms, total: 2.1 s\n",
      "Wall time: 2.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute modeling yourself.\n",
    "if 1 == 1:\n",
    "    # gensim Phrases\n",
    "    # automatically detect common phrases – multi-word expressions / word n-grams – from a stream of sentences.\n",
    "    #\n",
    "    # example\n",
    "    # >>> sentences = Text8Corpus(datapath('testcorpus.txt'))     <- load training example data\n",
    "    # >>> phrases = Phrases(sentences, min_count=1, threshold=1)  <- train the Phrases model\n",
    "    # >>> phrases[[u'trees', u'graph', u'minors']]                <- apply trained model to sentence\n",
    "    # [u'trees_graph', u'minors']                                 <- identify phrases 'trees_graph'\n",
    "    #\n",
    "    # >>> phrases.add_vocab([[\"hello\", \"world\"], [\"meow\"]])       <- update model with new sentences\n",
    "    # \n",
    "    # >>> bigram = Phraser(phrases)                               <- construct faster model (this is only an wrapper)\n",
    "    # >>> bigram[[u'trees', u'graph', u'minors']]                 <- apply model to sentence\n",
    "    # [u'trees_graph', u'minors']\n",
    "    #\n",
    "    bigram_model = Phrases(unigram_sentences)\n",
    "    bigram_model.save(bigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the finished model from disk\n",
    "bigram_model = Phrases.load(bigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare to apply the trained Phrases model to the unigram lemmatized sentences\n",
    "bigram_sentences_filepath = os.path.join(intermediate_directory,\n",
    "                                         'bigram_sentences_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/anaconda/envs/fastai-cpu/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "4623it [00:02, 2146.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.14 s, sys: 24.8 ms, total: 2.16 s\n",
      "Wall time: 2.16 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 1 == 1:\n",
    "    with codecs.open(bigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "        for unigram_sentence in tqdm(unigram_sentences):\n",
    "            bigram_sentence = ' '.join(bigram_model[unigram_sentence])\n",
    "            f.write(bigram_sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right suppose problem xmncolormap xtncolormap truly literate being set want start application new colormap chicken egg sort problem look xt faq example let_know maybe improve example\n",
      "\n",
      "read right say essence large economy nation discretionary fund waste lunar facility certainly partially case apollo real lunar_colony probably require continue military scientific commercial reason money approach conceivable luna military purpose possible luna commercial purpose likely luna scientific purpose year lunar_base predicate funding level little different find antarctic base person base moon million year use grad_student gary\n",
      "\n",
      "probably mean blood_pressure go treadmill normal ask mean answer person gordon_bank skepticism_chastity intellect_shameful surrender_soon\n",
      "\n",
      "hey folk course develope x window application encounter problem transform x window bitmap postscript file library routine source_code job\n",
      "\n",
      "post game interview larussa claim sparky good manager basebal explain history sparky soften blow lose tiger tim timothy law snyder department computer_science reiss georgetown university washington_dc\n",
      "\n",
      "united_state tv schedule april devil islander pittsburgh est abc eastern time_zone april st_louis chicago cdt abc cent mou time_zone april los_angele calgary pdt abc pacific time_zone april devil islander pittsburgh espn april tba espn april tba espn somebody send cbc tsn schedule post\n",
      "\n",
      "answer get reflex sympathetic dystrophy forever hope good_job reattach hope know month gordon_bank skepticism_chastity intellect_shameful surrender_soon\n",
      "\n",
      "tell message come try lead edge flaky motherboard friend game replace doc mother_board cheertron board award bio sticker say vi tell switch blue block mean fdc sh idea jumper replace hard_drive modem instal math co process bit league doc lose help_appreciate news regularly help e_mail thank\n",
      "\n",
      "wife breast feed boy month month month respectively year_old respectively far everybody fairly normal notice negative correlation ear infection length time nurse small sample notice year_old eat lot breast feeding understand unfit mother charge tactic low folk divorce child custody battle develop nation practice breast feed year_old screw good use cow milk commercial formula doctor\n",
      "\n",
      "okay try install ncsa telnet couple okay bunch machine true blue ibms fallon phonenet card dastar card belive name correct doc telnet run appletalk driver little success succesfully instal telnet appletalk like help config_file telnet btw reply_e mail possible thank jeremy jeremy zawodny computer_science undergrad bowl green state university\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print out a few examples of bigram on lemmatized sentences.\n",
    "# note that vice_versa, original_question, etc. are now considered as phrases\n",
    "bigram_sentences = LineSentence(bigram_sentences_filepath)\n",
    "\n",
    "for bigram_sentence in it.islice(bigram_sentences, 230, 240):\n",
    "    print(' '.join(bigram_sentence))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_model_filepath = os.path.join(intermediate_directory,\n",
    "                                      'trigram_model_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.27 s, sys: 11.8 ms, total: 1.28 s\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute modeling yourself.\n",
    "if 1 == 1:\n",
    "    trigram_model = Phrases(bigram_sentences)\n",
    "    trigram_model.save(trigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the finished model from disk\n",
    "trigram_model = Phrases.load(trigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.phrases.Phrases"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trigram_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_sentences_filepath = os.path.join(intermediate_directory,\n",
    "                                          'trigram_sentences_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/anaconda/envs/fastai-cpu/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "4623it [00:02, 2153.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.14 s, sys: 24.7 ms, total: 2.16 s\n",
      "Wall time: 2.15 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 1 == 1:\n",
    "    with codecs.open(trigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "        for bigram_sentence in tqdm(bigram_sentences):\n",
    "            trigram_sentence = ' '.join(trigram_model[bigram_sentence])\n",
    "            f.write(trigram_sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_sentences = LineSentence(trigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right suppose problem xmncolormap xtncolormap truly literate being set want start application new colormap chicken egg sort problem look xt faq example let_know maybe improve example\n",
      "\n",
      "read right say essence large economy nation discretionary fund waste lunar facility certainly partially case apollo real lunar_colony probably require continue military scientific commercial reason money approach conceivable luna military purpose possible luna commercial purpose likely luna scientific purpose year lunar_base predicate funding level little different find antarctic base person base moon million year use grad_student gary\n",
      "\n",
      "probably mean blood_pressure go treadmill normal ask mean answer person gordon_bank_skepticism_chastity intellect_shameful_surrender_soon\n",
      "\n",
      "hey folk course develope x_window application encounter problem transform x_window bitmap postscript file library routine source_code job\n",
      "\n",
      "post game interview larussa claim sparky good manager basebal explain history sparky soften blow lose tiger tim timothy law snyder department computer_science reiss georgetown university washington_dc\n",
      "\n",
      "united_state tv schedule april devil islander pittsburgh est abc eastern time_zone april st_louis_chicago cdt abc cent mou time_zone april los_angele calgary pdt abc pacific time_zone april devil islander pittsburgh espn april tba espn april tba espn somebody send cbc tsn schedule post\n",
      "\n",
      "answer get reflex sympathetic dystrophy forever hope good_job reattach hope know month gordon_bank_skepticism_chastity intellect_shameful_surrender_soon\n",
      "\n",
      "tell message come try lead edge flaky motherboard friend game replace doc mother_board cheertron board award bio sticker say vi tell switch blue block mean fdc sh idea jumper replace hard_drive modem instal math co process bit league doc lose help_appreciate news regularly help e_mail_thank\n",
      "\n",
      "wife breast feed boy month month month respectively year_old respectively far everybody fairly normal notice negative correlation ear infection length time nurse small sample notice year_old eat lot breast feeding understand unfit mother charge tactic low folk divorce child custody battle develop nation practice breast feed year_old screw good use cow milk commercial formula doctor\n",
      "\n",
      "okay try install ncsa telnet couple okay bunch machine true blue ibms fallon phonenet card dastar card belive name correct doc telnet run appletalk driver little success succesfully instal telnet appletalk like help config_file telnet btw reply_e_mail possible thank jeremy jeremy zawodny computer_science undergrad bowl green state university\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print a few trigram examples on lemmatized sentences\n",
    "# note that bigram words are still there but we see a few trigrams now.\n",
    "# like san_jose_sharks, learn_how_to\n",
    "for trigram_sentence in it.islice(trigram_sentences, 230, 240):\n",
    "    print(' '.join(trigram_sentence))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_reviews_filepath = os.path.join(intermediate_directory,\n",
    "                                        'trigram_transformed_reviews_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 7.39 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# NOT NEED TO RUN THIS AS WE HAVE DONE ALL STEPS HERE BEFORE\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 0 == 1:\n",
    "    with codecs.open(trigram_reviews_filepath, 'w', encoding='utf_8') as f:\n",
    "        for parsed_review in nlp.pipe(line_review(review_txt_filepath),\n",
    "                                      batch_size=10000, n_threads=4):\n",
    "            # lemmatize the text, removing punctuation and whitespace\n",
    "            unigram_review = [token.lemma_ for token in parsed_review\n",
    "                              if not punct_space(token)]\n",
    "            \n",
    "            # apply the first-order and second-order phrase models\n",
    "            bigram_review = bigram_model[unigram_review]\n",
    "            trigram_review = trigram_model[bigram_review]\n",
    "            \n",
    "            # remove any remaining stopwords\n",
    "            trigram_review = [term for term in trigram_review\n",
    "                              if term not in spacy.en.STOPWORDS]\n",
    "            \n",
    "            # write the transformed review as a line in the new file\n",
    "            trigram_review = u' '.join(trigram_review)\n",
    "            f.write(trigram_review + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "\n",
      "Transformed:\n",
      "\n",
      "simply wish thank dave mielke share tract concern god_love welcome great source comfort\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print('Original:' + u'\\n')\n",
    "#\n",
    "# for review in it.islice(line_review(review_txt_filepath), 11, 12):\n",
    "#    print(review)\n",
    "trigram_reviews_filepath = trigram_sentences_filepath\n",
    "\n",
    "print('----' + u'\\n')\n",
    "print('Transformed:' + u'\\n')\n",
    "\n",
    "with codecs.open(trigram_reviews_filepath, encoding='utf_8') as f:\n",
    "    for review in it.islice(f, 11, 12):\n",
    "        print(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LDA to find the topic most-associated with each word\n",
    "both **sklearn** and **gensim** LDA implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "intermediate_directory = '.'\n",
    "trigram_dictionary_filepath = os.path.join(intermediate_directory,\n",
    "                                           'trigram_dict_all.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "727it [00:00, 7179.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ./withnlp-lemma.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4623it [00:00, 7484.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 678 ms, sys: 8.37 ms, total: 686 ms\n",
      "Wall time: 676 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to learn the dictionary yourself.\n",
    "if 1 == 1:\n",
    "    trigram_reviews_filepath = './withnlp-lemma.txt'\n",
    "    print('loading data from {}'.format(trigram_reviews_filepath))\n",
    "    trigram_reviews = LineSentence(trigram_reviews_filepath)\n",
    "\n",
    "    # learn the dictionary by iterating over all of the reviews\n",
    "    trigram_dictionary = Dictionary(tqdm(trigram_reviews))\n",
    "    \n",
    "    # filter tokens that are very rare or too common from\n",
    "    # the dictionary (filter_extremes) and reassign integer ids (compactify)\n",
    "    trigram_dictionary.filter_extremes(no_below=10, no_above=0.03)\n",
    "    trigram_dictionary.compactify()\n",
    "\n",
    "    trigram_dictionary.save(trigram_dictionary_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the finished dictionary from disk\n",
    "trigram_dictionary = Dictionary.load(trigram_dictionary_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.corpora.dictionary.Dictionary'> 246561 4623 390822\n"
     ]
    }
   ],
   "source": [
    "# This module implements the concept of a Dictionary – a mapping between words and their integer ids.\n",
    "# ops supported: \n",
    "# - doc2bow\n",
    "# - doc2idx\n",
    "# - filter_extremes\n",
    "# - filter_n_most_frequent\n",
    "# - compactify\n",
    "#\n",
    "# compactify: Assign new word ids to all words, shrinking any gaps.\n",
    "print(type(trigram_dictionary), trigram_dictionary.num_nnz, trigram_dictionary.num_docs, trigram_dictionary.num_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_bow_filepath = os.path.join(intermediate_directory,\n",
    "                                    'trigram_bow_corpus_all.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigram_bow_generator(filepath):\n",
    "    \"\"\"\n",
    "    generator function to read reviews from a file\n",
    "    and yield a bag-of-words representation\n",
    "    \"\"\"\n",
    "    \n",
    "    for review in LineSentence(filepath):\n",
    "        yield trigram_dictionary.doc2bow(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MmCorpus from bow generator on ./withnlp-lemma.txt\n",
      "CPU times: user 654 ms, sys: 12 ms, total: 666 ms\n",
      "Wall time: 667 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to build the bag-of-words corpus yourself.\n",
    "if 1 == 1:\n",
    "    print('MmCorpus from bow generator on {}'.format(trigram_reviews_filepath))\n",
    "    # generate bag-of-words representations for\n",
    "    # all reviews and save them as a matrix\n",
    "    MmCorpus.serialize(trigram_bow_filepath,\n",
    "                       trigram_bow_generator(trigram_reviews_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the finished bag-of-words corpus from disk\n",
    "trigram_bow_corpus = MmCorpus(trigram_bow_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.corpora.mmcorpus.MmCorpus'>\n"
     ]
    }
   ],
   "source": [
    "# Corpus in the Matrix Market format.\n",
    "print(type(trigram_bow_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['account',\n",
       " 'bias',\n",
       " 'die',\n",
       " 'doubt',\n",
       " 'father',\n",
       " 'hmmm',\n",
       " 'lesson',\n",
       " 'mid',\n",
       " 'performance',\n",
       " 'radio',\n",
       " 'recall',\n",
       " 'solid',\n",
       " 'switch',\n",
       " 'tube',\n",
       " 'unit',\n",
       " 'vacuum']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_index = 0\n",
    "[trigram_dictionary[id] for (id, bow_count) in trigram_bow_corpus[document_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alabama',\n",
       " 'atlanta',\n",
       " 'bay',\n",
       " 'beach',\n",
       " 'begin',\n",
       " 'believer',\n",
       " 'blue',\n",
       " 'bruin',\n",
       " 'canada',\n",
       " 'canuck',\n",
       " 'capital',\n",
       " 'car',\n",
       " 'conference',\n",
       " 'cool',\n",
       " 'dalla',\n",
       " 'devil',\n",
       " 'diego',\n",
       " 'direction',\n",
       " 'dream',\n",
       " 'drug']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_index = 1\n",
    "[trigram_dictionary.id2token[id] for (id, bow_count) in trigram_bow_corpus[document_index]][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2a Sklearn LDA implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import spacy \n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "intermediate_directory = '.'\n",
    "# trigram_reviews_filepath = os.path.join(intermediate_directory, 'trigram_transformed_reviews_all.txt')\n",
    "# trigram_sentences_filepath = os.path.join(intermediate_directory, 'trigram_sentences_all.txt')\n",
    "# train_data = line_review(trigram_sentences_filepath)\n",
    "# train_data = lemmatized_sentence_corpus(line_sklearn_data(newsgroups_train.data))\n",
    "# train_data = newsgroups_train.data\n",
    "# train_data = no_lemmatized_sentence_corpus(line_sklearn_data(newsgroups_train.data))\n",
    "# train_data = line_asis('./withoutnlp.txt')\n",
    "# train_data = line_asis('./withnlp-lemma.txt')\n",
    "# train_data = line_asis('./withnlp-nolemma.txt')\n",
    "train_data = line_asis('./trigram_sentences_all.txt')\n",
    "\n",
    "# for train_line in it.islice(train_data, 0, 10):\n",
    "#    print(train_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['hmmm recall attraction solid_state player radio good performance low unit cost vacuum tube system mind father vacuum tube fan switch solid_state mid seventy abruptly die doubt lesson account bias',\n",
       "  'nhl year get reliable source dream year_ago initially think take strong drug realization begin league start direction walt disney conference anaheim mighty chipmunk change new la king hockey movie la flame see san_jose_shark san_diego bruin tijuana red_wing hockey_team follow car industry dalla star houston oiler texas_ranger seattle canuck norm green conference alabama white hawk biloxi blue tampa_bay_lightning miami blade helsinki jet hear start get anthem montreal quebecois sp canada atlanta devil orlando penquin key west islander hartford_whaler whaler huh palm beach capital anahaim team becomm real begin believe rest message sure future turn believer nhl abandond ice rink expensive cool rink subtropic local hardly know ice nhl roller skate hockey_league way create public interest game local supportere play_game yard'],\n",
       " [\"Hmmm. I seem to recall that the attraction of solid state record-\\nplayers and radios in the 1960s wasn't better performance but lower\\nper-unit cost than vacuum-tube systems.\\n\\n\\tMind you, my father was a vacuum-tube fan in the 60s (Switched\\nto solid-state in the mid-seventies and then abruptly died; no doubt\\nthere's a lesson in that) and his account could have been biased.\",\n",
       "  \"Well, here it is, NHL in the year 2000.\\nI got these from a very reliable source in a dream some years ago and \\nalthough I initially thought I had just been taking too many too strong \\ndrugs now it seems the realization has really begun...  You can see the \\nleague has already started to move to this direction.\\n\\n   *The Walt Disney Conference*\\nAnaheim Mighty Chipmunks    -Franchise name to be changed after each new \\nLA Kings                      hockey movie         \\nLA Flames                   -We've seen some of that\\nSan Jose Sharks\\nSan Diego Bruins\\nTijuana Red Wings   -Detroit's hockey team will follow its car industry...\\nDallas Stars           \\nHouston Oilers\\nTexas Rangers\\nSeattle Canucks\\n\\n   *The Norm Green Conference*\\nAlabama White Hawks\\nBiloxi Blues\\nTampa Bay Lightning\\nMiami Blades\\nHelsinki Jets        -You've heard them starting getting used to the anthem\\nMontreal Quebecois (sp?)                 -There will be no 'Canada'\\nAtlanta Devils\\nOrlando Penquins\\nKey West Islanders\\nHartford Whalers                        The Whalers will never move, huh?\\nPalm Beach Capitals\\n\\n  Now that the Anahaim team is becomming real I'm really beginning to believe\\nthe rest of the 'message'.  I'm sure the future will turn you into believers \\ntoo.  After 2000 the NHL will abandond ice-rinks.  It's so expensive to cool \\ndown the rinks in the subtropics and the locals hardly know what ice is \\nanyway.  NHL will become a roller skating hockey league.  That way it can \\ncreate more public interest in the game when local supporteres can play the \\ngame in their back yards !\"])"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_data[:2], newsgroups_train.data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit vectorizer without lemmatization done in 7.571s.\n"
     ]
    }
   ],
   "source": [
    "# train_data = line_review(trigram_sentences_filepath)\n",
    "# train_data = lemmatized_sentence_corpus(line_sklearn_data(newsgroups_train.data))\n",
    "\n",
    "tf_vectorizer = CountVectorizer(encoding='utf-8', analyzer='word', stop_words='english',\n",
    "                                ngram_range = (1,1), min_df = 2, token_pattern = '[a-zA-Z]{2,}').fit(train_data)\n",
    "print(\"fit vectorizer without lemmatization done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.feature_extraction.text.CountVectorizer"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='[a-zA-Z]{2,}', tokenizer=None,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get_feature_names() returns vocabulary\n",
    "n_features = len(tf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14196"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['aa',\n",
       "  'aaa',\n",
       "  'aaron',\n",
       "  'aas',\n",
       "  'ab',\n",
       "  'abandon',\n",
       "  'abbott',\n",
       "  'abbreviation',\n",
       "  'abc',\n",
       "  'abd'],\n",
       " ['zoom',\n",
       "  'zooming',\n",
       "  'zorro',\n",
       "  'zou',\n",
       "  'zpixmap',\n",
       "  'zterm',\n",
       "  'zubov',\n",
       "  'zupancic',\n",
       "  'zupcic',\n",
       "  'zyxel']]"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tf_vectorizer.get_feature_names()[:10], tf_vectorizer.get_feature_names()[-10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = line_review(trigram_sentences_filepath)\n",
    "# train_data = lemmatized_sentence_corpus(line_sklearn_data(newsgroups_train.data))\n",
    "# train_data = newsgroups_train.data\n",
    "# train_data = no_lemmatized_sentence_corpus(line_sklearn_data(newsgroups_train.data))\n",
    "# train_data = line_asis('./withoutnlp.txt')\n",
    "# train_data = line_asis('./withoutnlp-keepcase.txt')\n",
    "# train_data = line_asis('./withnlp-lemma.txt')\n",
    "# train_data = line_asis('./withnlp-nolemma.txt')\n",
    "train_data = line_asis('./trigram_sentences_all.txt')\n",
    "\n",
    "tf_docs = tf_vectorizer.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4623x14196 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 223639 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.decomposition.online_lda.LatentDirichletAllocation"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/fastai-cpu/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 15.652s.\n"
     ]
    }
   ],
   "source": [
    "# print(\"Fitting LDA models with tf features, n_samples=%d and n_features=%d...\"\n",
    "#       % (n_docs, n_features))\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=0)\n",
    "t0 = time()\n",
    "lda.fit(tf_docs)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model:\n",
      "Topic #0:\n",
      "gm baltimore john utica adirondack moncton rochester providence springfield binghamton cape cdi vs breton st fredericton disc vision terminator halifax\n",
      "Topic #1:\n",
      "file window program use entry server widget application include available run set motif version line display information source code list\n",
      "Topic #2:\n",
      "game year good win team think player play season like run hit league score look right fan lose come time\n",
      "Topic #3:\n",
      "space launch nasa year center orbit satellite mission research program earth report shuttle health high information national lunar use food\n",
      "Topic #4:\n",
      "play pt game team hockey period la goal nhl new playoff pittsburgh player season power cup shot detroit van pp\n",
      "Topic #5:\n",
      "jb het sea spacewalk scott te ns en utrecht kan andrew karma boy compaq mil snd dortmund cin tex wright\n",
      "Topic #6:\n",
      "god people think know believe good say time christian jesus come like thing church day way question want life mean\n",
      "Topic #7:\n",
      "drive know like work use problem time card good thank mac think need disk new mb want try support scsi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tf_feature_names is vocabulary\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "n_top_words = 20\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 14196)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row# of lda.components_ is topic#\n",
    "# columns are the topic's unnormalized word weights (for all vocabulary words), in the sequence of the vocabulary word order\n",
    "per_topic_distr_LDA = lda.components_\n",
    "per_topic_distr_LDA.shape\n",
    "#per_topic_distr_LDA.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2b Gensim LDA implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_filepath = os.path.join(intermediate_directory, 'lda_model_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.88 s, sys: 268 ms, total: 9.15 s\n",
      "Wall time: 5.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to train the LDA model yourself.\n",
    "if 1 == 1:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "\n",
    "        # workers => sets the parallelism, and should be\n",
    "        # set to your number of physical cores minus one\n",
    "        # lda = LdaMulticore(trigram_bow_corpus,\n",
    "        #                   num_topics=7,\n",
    "        #                   id2word=trigram_dictionary,\n",
    "        #                   workers=3)\n",
    "        lda = LdaModel(trigram_bow_corpus,\n",
    "                           num_topics=7,\n",
    "                           id2word=trigram_dictionary)\n",
    "\n",
    "    lda.save(lda_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the finished LDA model from disk\n",
    "lda = LdaModel.load(lda_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nasa id is 823, topics is []\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'space'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-33a0d29e95dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# find out topics by word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtest_word\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'nasa'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'space'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'good'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'go'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrigram_dictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_word\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_term_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} id is {}, topics is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrigram_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'space'"
     ]
    }
   ],
   "source": [
    "# find out topics by word\n",
    "for test_word in ['nasa', 'space', 'good', 'go']:\n",
    "    test_id = trigram_dictionary.token2id[test_word]\n",
    "    test_topics = lda.get_term_topics(test_id)\n",
    "    print('{} id is {}, topics is {}'.format(trigram_dictionary[test_id], test_id, test_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_topic(topic_number, topn=10):\n",
    "    \"\"\"\n",
    "    accept a user-supplied topic number and\n",
    "    print out a formatted list of the top terms\n",
    "    \"\"\"\n",
    "        \n",
    "    # print('{:20} {}'.format('term', 'frequency') + '\\n')\n",
    "\n",
    "    # tf_list = [(term, frequency) for term, frequency in lda.show_topic(topic_number, topn)]\n",
    "    tf_list = [term for term, frequency in lda.show_topic(topic_number, topn)]\n",
    "    print('Topic {}: {}'.format(topic_number, ' '.join(tf_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: law truth keyboard key paul colormap score pain hell belief pick argument puck faith value human evidence offense mouse brave\n",
      "Topic 1: motif manager server widget xt user offer client port modem screen xlib function serial mit code resource patch toolkit character\n",
      "Topic 2: entry period king la flame pt pittsburgh chicago blue april vs pp goal trade playoff calgary captain shot chi score\n",
      "Topic 3: nasa launch mission orbit shuttle dc rocket flight center satellite spacecraft m bank fund faq gordon earth tax skepticism april\n",
      "Topic 4: msg food disease center religion belief doctor bible earth christianity cause patient switch lunar father faith moon adaptec reaction cancer\n",
      "Topic 5: scsi controller driver mb bus tape device mode floppy s ide interface ram adaptec fast video hardware server transfer port\n",
      "Topic 6: church simms catholic law gm service st nasa station baseball bishop canon pope scripture de american orthodox language bible development\n"
     ]
    }
   ],
   "source": [
    "for topic_id in range(0,7):\n",
    "    explore_topic(topic_id, topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 pyLDAVis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDAvis_data_filepath = os.path.join(intermediate_directory, 'ldavis_prepared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.4 s, sys: 193 ms, total: 6.6 s\n",
      "Wall time: 4.28 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/fastai-cpu/lib/python3.6/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pickle\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import warnings\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim.prepare(lda, trigram_bow_corpus,\n",
    "                                              trigram_dictionary)\n",
    "\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el44711399540405504082043278544\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el44711399540405504082043278544_data = {\"mdsDat\": {\"x\": [-0.007188118879488028, 8.873582130125966e-05, -0.003295257384225844, 0.03958809519632925, -0.006368003416966467, 0.0124065113029343, -0.03523196263988449], \"y\": [-0.012448302121216361, -0.01824858622354909, -0.019274922519388872, 0.02146679026478587, 0.022742463550277273, -0.013714869625239792, 0.019477426674330965], \"topics\": [1, 2, 3, 4, 5, 6, 7], \"cluster\": [1, 1, 1, 1, 1, 1, 1], \"Freq\": [17.5190486907959, 16.441673278808594, 14.790002822875977, 14.545564651489258, 13.635759353637695, 11.731843948364258, 11.33610725402832]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\"], \"Freq\": [204.0, 463.0, 274.0, 229.0, 227.0, 236.0, 392.0, 85.0, 130.0, 132.0, 268.0, 95.0, 107.0, 96.0, 98.0, 184.0, 280.0, 489.0, 74.0, 358.0, 121.0, 86.0, 92.0, 98.0, 109.0, 221.0, 215.0, 136.0, 71.0, 73.0, 34.25247573852539, 15.715639114379883, 7.024092197418213, 7.109299659729004, 53.376956939697266, 41.252315521240234, 5.705540180206299, 36.24100112915039, 36.77442169189453, 34.556026458740234, 39.83179473876953, 34.09064483642578, 21.11815643310547, 14.902172088623047, 9.878653526306152, 9.76551628112793, 6.446408271789551, 20.36404037475586, 16.240266799926758, 8.677678108215332, 29.32975959777832, 8.560193061828613, 42.1256103515625, 6.421154022216797, 10.71544075012207, 24.755878448486328, 5.760560989379883, 40.902427673339844, 10.176462173461914, 5.987671375274658, 73.29212188720703, 20.811267852783203, 67.81725311279297, 192.43252563476562, 50.73027420043945, 171.08287048339844, 30.747900009155273, 52.662109375, 102.16243743896484, 60.29470443725586, 78.654296875, 50.30916213989258, 30.59014320373535, 62.74131774902344, 37.331787109375, 78.91389465332031, 102.79674530029297, 55.86143493652344, 41.89877700805664, 64.28143310546875, 65.34635162353516, 49.57154083251953, 101.69806671142578, 68.8274917602539, 67.23703002929688, 65.83702850341797, 73.16081237792969, 64.60425567626953, 56.97392272949219, 73.67198944091797, 65.16303253173828, 69.96060943603516, 52.27904510498047, 55.741050720214844, 54.596435546875, 59.937461853027344, 57.48373794555664, 57.73378372192383, 58.86790466308594, 56.04853057861328, 57.40613555908203, 56.331138610839844, 21.49269676208496, 40.472354888916016, 34.583351135253906, 30.756053924560547, 26.61607551574707, 28.305397033691406, 19.97810173034668, 10.259891510009766, 16.294740676879883, 15.984197616577148, 26.583425521850586, 40.3581657409668, 10.507052421569824, 9.971176147460938, 7.181356430053711, 17.387052536010742, 6.543809413909912, 5.1418938636779785, 7.711119651794434, 22.546289443969727, 8.961983680725098, 15.026037216186523, 10.049306869506836, 15.273073196411133, 9.010603904724121, 11.006403923034668, 5.257200717926025, 5.895191192626953, 9.491096496582031, 6.257170677185059, 120.87184143066406, 10.730536460876465, 12.243313789367676, 31.211177825927734, 24.005882263183594, 80.5526351928711, 14.872739791870117, 119.76260375976562, 63.7531852722168, 39.80696487426758, 95.1076889038086, 48.75810623168945, 52.7011604309082, 43.379112243652344, 49.27037048339844, 60.157142639160156, 46.21985626220703, 77.98993682861328, 99.76753997802734, 29.1650447845459, 74.21733856201172, 87.4836196899414, 83.41192626953125, 46.65692901611328, 64.01200866699219, 77.69416809082031, 55.915287017822266, 93.65431213378906, 56.50579833984375, 62.855594635009766, 64.21058654785156, 81.77909851074219, 46.91096878051758, 56.28387451171875, 62.86213302612305, 52.451683044433594, 55.976619720458984, 48.963008880615234, 49.8865966796875, 50.03962326049805, 50.64528274536133, 15.873285293579102, 15.564148902893066, 8.63236141204834, 8.007354736328125, 20.14710235595703, 10.599388122558594, 12.64205551147461, 9.798623085021973, 11.311421394348145, 8.515881538391113, 7.8259124755859375, 4.955286979675293, 7.609643936157227, 11.612505912780762, 5.969239234924316, 12.39687728881836, 8.062037467956543, 5.50148344039917, 5.104371070861816, 20.204469680786133, 5.935221195220947, 12.44742202758789, 18.196468353271484, 10.943472862243652, 7.709077835083008, 13.433515548706055, 11.344475746154785, 16.055931091308594, 5.33806037902832, 10.284358978271484, 15.437954902648926, 38.74463653564453, 19.83780288696289, 89.73615264892578, 44.422969818115234, 16.40789222717285, 53.615238189697266, 62.62679672241211, 104.09900665283203, 52.36876678466797, 95.13734436035156, 78.1583023071289, 61.21285629272461, 78.63714599609375, 42.169952392578125, 59.60565185546875, 52.61725616455078, 74.49968719482422, 39.1958122253418, 31.336767196655273, 55.7841911315918, 59.81705856323242, 44.273006439208984, 82.66991424560547, 49.67567443847656, 92.3985595703125, 37.86323928833008, 51.06415557861328, 49.51015090942383, 52.748260498046875, 46.53874969482422, 42.06216049194336, 70.37992858886719, 46.17848205566406, 47.32850646972656, 61.351863861083984, 73.79241180419922, 48.9085693359375, 60.910301208496094, 61.54131317138672, 50.219539642333984, 55.26687240600586, 52.33240509033203, 50.310489654541016, 51.61076736450195, 49.83625793457031, 49.77516555786133, 166.54608154296875, 34.96088790893555, 38.22459030151367, 28.628921508789062, 20.752836227416992, 21.47900390625, 14.584871292114258, 9.836519241333008, 22.342716217041016, 32.27616882324219, 41.52958297729492, 7.436850547790527, 45.098480224609375, 64.40348052978516, 23.283023834228516, 6.455905914306641, 9.718798637390137, 18.881694793701172, 19.420713424682617, 7.102194309234619, 31.30978012084961, 6.0008721351623535, 14.402231216430664, 34.84952926635742, 7.757355690002441, 5.436498165130615, 7.803850173950195, 11.914027214050293, 6.695547103881836, 40.630428314208984, 16.436378479003906, 40.894126892089844, 24.292449951171875, 29.558780670166016, 82.25267791748047, 140.98370361328125, 75.18071746826172, 76.76087951660156, 42.3263053894043, 24.429126739501953, 47.28482437133789, 60.545570373535156, 64.07877349853516, 71.3946304321289, 55.10381317138672, 47.9450798034668, 43.152740478515625, 59.95537567138672, 59.703250885009766, 75.19567108154297, 47.5754508972168, 59.26802444458008, 50.69091796875, 55.599334716796875, 55.244693756103516, 48.698219299316406, 56.2418098449707, 51.880226135253906, 51.21215057373047, 47.51448059082031, 50.877532958984375, 49.914215087890625, 44.077415466308594, 46.169525146484375, 45.00625991821289, 18.217531204223633, 12.902266502380371, 11.827627182006836, 11.864679336547852, 49.617210388183594, 5.366292953491211, 50.55546951293945, 13.948530197143555, 53.36538314819336, 41.329185485839844, 51.81987762451172, 8.126927375793457, 45.55061340332031, 20.57736587524414, 7.398809909820557, 8.293638229370117, 24.770912170410156, 5.947221755981445, 40.62915802001953, 32.25395584106445, 42.519989013671875, 39.61825942993164, 11.406579971313477, 11.58227252960205, 7.427009105682373, 6.238264560699463, 27.760042190551758, 8.475214004516602, 8.444742202758789, 43.197975158691406, 18.42738151550293, 26.4860897064209, 27.1842041015625, 23.792551040649414, 114.15303039550781, 71.32421112060547, 50.758827209472656, 37.758094787597656, 78.3061752319336, 42.18650817871094, 43.00090789794922, 52.30622482299805, 56.164703369140625, 44.52506637573242, 44.80803680419922, 59.68250274658203, 60.886138916015625, 67.70470428466797, 46.78431701660156, 54.6334228515625, 51.766273498535156, 48.84034729003906, 51.070865631103516, 62.41604995727539, 48.95719909667969, 55.20082092285156, 46.518463134765625, 44.235408782958984, 42.542579650878906, 13.057799339294434, 10.72659683227539, 9.46227741241455, 6.756115436553955, 5.183887481689453, 14.648454666137695, 10.725554466247559, 13.220454216003418, 8.043707847595215, 93.75181579589844, 8.44566535949707, 91.0814437866211, 6.409615993499756, 7.55896520614624, 14.281821250915527, 12.99715805053711, 10.316081047058105, 4.041939735412598, 9.691490173339844, 23.349929809570312, 11.90417194366455, 10.741459846496582, 4.645540237426758, 10.173376083374023, 7.272039890289307, 5.051007270812988, 6.235770225524902, 5.310076713562012, 3.620858907699585, 14.735962867736816, 11.626433372497559, 13.464288711547852, 20.61928939819336, 13.370344161987305, 21.404537200927734, 42.35853576660156, 17.783506393432617, 45.52809524536133, 65.96427154541016, 15.339570045471191, 43.23252868652344, 32.48330307006836, 36.86711120605469, 24.066911697387695, 40.11665344238281, 25.43965721130371, 34.73540496826172, 32.08357238769531, 29.561534881591797, 21.6951961517334, 57.32480239868164, 47.65473175048828, 29.14786148071289, 47.973270416259766, 29.110410690307617, 50.367164611816406, 46.02776336669922, 37.95524597167969, 44.675254821777344, 40.89842224121094, 44.67362976074219, 37.724853515625, 35.701255798339844, 36.01850891113281, 33.72890090942383, 39.562889099121094, 43.57654571533203, 39.465972900390625, 40.27402114868164, 39.166343688964844, 40.21971130371094, 43.712860107421875, 41.68540954589844, 40.828277587890625, 40.69832229614258, 38.0810432434082, 39.99274826049805, 38.46809768676758, 38.523956298828125, 29.652475357055664, 28.98126220703125, 25.59479331970215, 12.014174461364746, 26.00564956665039, 127.51914978027344, 10.066597938537598, 29.0866756439209, 31.463481903076172, 34.579898834228516, 4.997170925140381, 32.317039489746094, 56.63748550415039, 36.63859176635742, 50.95539474487305, 55.08773422241211, 21.758804321289062, 34.395606994628906, 10.476110458374023, 28.840970993041992, 28.042804718017578, 85.32747650146484, 10.636850357055664, 20.93334197998047, 7.781724452972412, 31.645689010620117, 6.412147045135498, 24.96881866455078, 167.97010803222656, 7.636523723602295, 36.66646194458008, 43.39310836791992, 33.54848861694336, 58.92751693725586, 31.121196746826172, 42.62538146972656, 50.53499984741211, 58.465423583984375, 30.88450050354004, 58.000160217285156, 56.796302795410156, 54.65741729736328, 48.247257232666016, 62.10794448852539, 48.996849060058594, 43.134456634521484, 42.23012924194336, 46.82697296142578, 45.96803283691406, 47.170894622802734, 48.03217315673828, 40.34469985961914, 38.833675384521484, 38.85157775878906, 40.27031326293945, 37.8240852355957, 37.61695098876953, 37.21274185180664], \"Term\": [\"gm\", \"entry\", \"pt\", \"keyboard\", \"la\", \"key\", \"church\", \"bos\", \"van\", \"char\", \"o\", \"pit\", \"det\", \"tor\", \"chi\", \"output\", \"satellite\", \"server\", \"que\", \"scsi\", \"null\", \"buf\", \"stl\", \"mon\", \"cal\", \"sin\", \"hell\", \"int\", \"nyr\", \"nyi\", \"migraine\", \"coprocessor\", \"grasp\", \"laptop\", \"universe\", \"vram\", \"spelling\", \"surrender\", \"intellect\", \"shameful\", \"skepticism\", \"chastity\", \"headache\", \"math\", \"cat\", \"dimension\", \"contradiction\", \"motion\", \"arrogant\", \"smiley\", \"trust\", \"xsun\", \"absolute\", \"openlook\", \"overhead\", \"guideline\", \"aka\", \"gordon\", \"glory\", \"descend\", \"font\", \"imake\", \"pain\", \"server\", \"doubt\", \"entry\", \"edge\", \"cache\", \"screen\", \"chicago\", \"truth\", \"string\", \"street\", \"floppy\", \"contrib\", \"section\", \"c\", \"pay\", \"bank\", \"copy\", \"sin\", \"package\", \"widget\", \"value\", \"format\", \"human\", \"motif\", \"interface\", \"site\", \"period\", \"faith\", \"user\", \"library\", \"command\", \"xt\", \"science\", \"rule\", \"bus\", \"center\", \"resource\", \"launch\", \"earth\", \"baerga\", \"symbol\", \"cursor\", \"easter\", \"yeast\", \"undefined\", \"asynchronous\", \"simmon\", \"amateur\", \"corn\", \"alomar\", \"doug\", \"tracking\", \"synchronous\", \"dd\", \"gold\", \"spaceflight\", \"noring\", \"goddess\", \"senator\", \"grey\", \"allergic\", \"charter\", \"orchid\", \"ns\", \"revenue\", \"contend\", \"alexander\", \"telnet\", \"paris\", \"satellite\", \"init\", \"antenna\", \"eric\", \"burst\", \"chip\", \"hypothesis\", \"center\", \"shuttle\", \"radio\", \"science\", \"commercial\", \"l\", \"market\", \"tool\", \"evidence\", \"cancer\", \"m\", \"launch\", \"resurrection\", \"faith\", \"mb\", \"s\", \"flame\", \"national\", \"user\", \"star\", \"server\", \"event\", \"orbit\", \"driver\", \"widget\", \"theory\", \"hardware\", \"church\", \"nhl\", \"nasa\", \"city\", \"size\", \"mode\", \"earth\", \"gainey\", \"gun\", \"le\", \"hextall\", \"tower\", \"republic\", \"reward\", \"jsc\", \"italy\", \"laserwriter\", \"stealth\", \"administrative\", \"spare\", \"integration\", \"ribbon\", \"hz\", \"chamber\", \"bag\", \"bolt\", \"jagr\", \"perceive\", \"pipe\", \"jan\", \"adb\", \"boost\", \"gas\", \"messy\", \"cold\", \"technician\", \"france\", \"sp\", \"hp\", \"socket\", \"goal\", \"r\", \"gilmour\", \"belief\", \"ram\", \"launch\", \"project\", \"period\", \"april\", \"video\", \"nasa\", \"int\", \"mark\", \"output\", \"controller\", \"p\", \"absolute\", \"b\", \"truth\", \"minute\", \"mb\", \"fix\", \"widget\", \"os\", \"ide\", \"option\", \"event\", \"playoff\", \"flyer\", \"scsi\", \"lunar\", \"rom\", \"motif\", \"server\", \"single\", \"s\", \"c\", \"mission\", \"user\", \"satellite\", \"function\", \"center\", \"driver\", \"orbit\", \"gm\", \"providence\", \"rochester\", \"cape\", \"protestant\", \"needle\", \"probert\", \"clement\", \"prophecy\", \"dma\", \"baltimore\", \"foolish\", \"printer\", \"aid\", \"irq\", \"hewlett\", \"latin\", \"council\", \"dialog\", \"shortly\", \"cure\", \"devote\", \"jew\", \"doctrine\", \"bomb\", \"yup\", \"eve\", \"popup\", \"packard\", \"jewish\", \"colour\", \"pope\", \"orthodox\", \"espn\", \"hell\", \"church\", \"health\", \"st\", \"philadelphia\", \"suffer\", \"religion\", \"tape\", \"sin\", \"driver\", \"box\", \"scripture\", \"black\", \"disease\", \"patient\", \"period\", \"ranger\", \"national\", \"field\", \"bible\", \"hardware\", \"rate\", \"april\", \"child\", \"medical\", \"paul\", \"controller\", \"faith\", \"die\", \"image\", \"scsi\", \"pitt\", \"fever\", \"partition\", \"wash\", \"pit\", \"prescription\", \"mon\", \"amiga\", \"cal\", \"bos\", \"det\", \"cy\", \"tor\", \"nl\", \"sb\", \"slg\", \"era\", \"yount\", \"pitcher\", \"que\", \"chi\", \"stl\", \"rod\", \"gp\", \"kinda\", \"intestine\", \"sec\", \"obp\", \"ctrl\", \"stat\", \"marry\", \"phi\", \"nyi\", \"hot\", \"scsi\", \"food\", \"vs\", \"al\", \"o\", \"throw\", \"ice\", \"t\", \"ide\", \"water\", \"msg\", \"score\", \"resource\", \"motif\", \"mouse\", \"port\", \"d\", \"final\", \"nhl\", \"c\", \"interface\", \"widget\", \"bus\", \"doctor\", \"la\", \"stereo\", \"xputimage\", \"playing\", \"rubber\", \"loud\", \"quack\", \"fielder\", \"gc\", \"ximage\", \"keyboard\", \"divorce\", \"key\", \"boggs\", \"gxxor\", \"clemen\", \"anderson\", \"oriole\", \"mussina\", \"chipset\", \"sox\", \"inning\", \"galileo\", \"journey\", \"muslim\", \"sandberg\", \"meaningful\", \"tomorrow\", \"swell\", \"tolerance\", \"sparc\", \"innings\", \"contribution\", \"gain\", \"verse\", \"observation\", \"normal\", \"sabbath\", \"rocket\", \"o\", \"diagnose\", \"average\", \"pin\", \"spirit\", \"weight\", \"friend\", \"family\", \"move\", \"winner\", \"picture\", \"wife\", \"earth\", \"chip\", \"respond\", \"mission\", \"spacecraft\", \"code\", \"service\", \"red\", \"score\", \"contact\", \"port\", \"division\", \"father\", \"lunar\", \"son\", \"fast\", \"controller\", \"mode\", \"manager\", \"disease\", \"orbit\", \"s\", \"nasa\", \"period\", \"center\", \"image\", \"mb\", \"motif\", \"church\", \"suck\", \"edm\", \"ott\", \"lyme\", \"sj\", \"pt\", \"proton\", \"tb\", \"nyr\", \"min\", \"africa\", \"de\", \"van\", \"stream\", \"null\", \"char\", \"japanese\", \"bos\", \"argv\", \"que\", \"nyi\", \"la\", \"methodology\", \"filename\", \"liver\", \"buf\", \"communion\", \"phi\", \"entry\", \"intensive\", \"cub\", \"contest\", \"chi\", \"output\", \"remark\", \"int\", \"n\", \"law\", \"tor\", \"bible\", \"rule\", \"section\", \"date\", \"church\", \"technology\", \"paul\", \"clear\", \"c\", \"s\", \"launch\", \"widget\", \"function\", \"pick\", \"sin\", \"goal\", \"size\", \"d\", \"code\"], \"Total\": [204.0, 463.0, 274.0, 229.0, 227.0, 236.0, 392.0, 85.0, 130.0, 132.0, 268.0, 95.0, 107.0, 96.0, 98.0, 184.0, 280.0, 489.0, 74.0, 358.0, 121.0, 86.0, 92.0, 98.0, 109.0, 221.0, 215.0, 136.0, 71.0, 73.0, 43.684608459472656, 22.446584701538086, 12.902338981628418, 13.462981224060059, 103.73567962646484, 80.27323150634766, 11.179158210754395, 71.32747650146484, 74.20283508300781, 70.0936279296875, 81.50439453125, 70.8635482788086, 44.14497375488281, 31.875764846801758, 21.27755355834961, 21.599628448486328, 14.391667366027832, 45.710811614990234, 36.80131149291992, 19.716339111328125, 66.8003158569336, 19.58315658569336, 96.45111846923828, 14.722838401794434, 24.764511108398438, 57.691768646240234, 13.470226287841797, 95.94745635986328, 24.11407470703125, 14.238533973693848, 175.8832550048828, 49.66967010498047, 164.14218139648438, 489.3175964355469, 127.43975067138672, 463.91607666015625, 75.41475677490234, 135.16419982910156, 276.5313415527344, 164.11827087402344, 227.6639404296875, 136.9085693359375, 77.31666564941406, 186.85569763183594, 99.99610900878906, 256.0838623046875, 360.77813720703125, 166.82186889648438, 117.23419189453125, 213.95932006835938, 221.9285125732422, 149.82598876953125, 447.30352783203125, 251.86062622070312, 254.4907989501953, 247.42543029785156, 320.4407043457031, 252.5200653076172, 198.142333984375, 358.4481506347656, 275.9497985839844, 333.5632019042969, 168.74560546875, 209.35459899902344, 198.9394073486328, 297.6713562011719, 253.22061157226562, 265.8866271972656, 367.6943054199219, 247.4511260986328, 393.78729248046875, 293.4892578125, 32.56505584716797, 62.09590530395508, 54.1656608581543, 51.16856384277344, 48.072174072265625, 51.84849548339844, 36.71946716308594, 19.721982955932617, 32.60266876220703, 32.5113410949707, 54.51908493041992, 82.90359497070312, 21.700428009033203, 21.01107406616211, 15.213764190673828, 36.961448669433594, 13.986108779907227, 11.0651216506958, 16.653423309326172, 49.195865631103516, 19.57527732849121, 32.88108444213867, 22.160486221313477, 34.00227737426758, 20.110177993774414, 24.58047103881836, 11.753376007080078, 13.268057823181152, 21.451370239257812, 14.284584999084473, 280.3385009765625, 24.587745666503906, 28.646015167236328, 77.79379272460938, 58.93305206298828, 227.63023376464844, 35.25487518310547, 367.6943054199219, 184.72071838378906, 109.20455932617188, 297.6713562011719, 138.63465881347656, 151.89993286132812, 123.26451873779297, 144.1050567626953, 183.7467803955078, 135.33204650878906, 270.4750061035156, 393.78729248046875, 78.0831298828125, 275.9497985839844, 358.9920654296875, 338.4947509765625, 152.47134399414062, 246.27224731445312, 333.5632019042969, 201.5319366455078, 489.3175964355469, 211.01480102539062, 257.6539611816406, 272.69110107421875, 447.30352783203125, 157.63616943359375, 246.5818634033203, 392.6268310546875, 223.372314453125, 298.0459899902344, 194.57550048828125, 217.83155822753906, 232.79139709472656, 293.4892578125, 30.648517608642578, 30.55181121826172, 17.190757751464844, 16.161874771118164, 40.9119873046875, 21.740779876708984, 25.993919372558594, 20.222047805786133, 23.812702178955078, 18.45857810974121, 17.052640914916992, 10.808450698852539, 16.608381271362305, 25.92691993713379, 13.402519226074219, 27.943851470947266, 18.504365921020508, 12.740640640258789, 12.012530326843262, 47.839813232421875, 14.230277061462402, 30.244409561157227, 44.42225646972656, 26.848194122314453, 18.930789947509766, 33.334537506103516, 28.300901412963867, 40.34344482421875, 13.423112869262695, 26.03806495666504, 39.27446746826172, 103.23160552978516, 52.190372467041016, 283.07177734375, 133.38294982910156, 44.31704330444336, 173.63165283203125, 208.96397399902344, 393.78729248046875, 174.73805236816406, 358.4481506347656, 286.853515625, 214.26744079589844, 298.0459899902344, 136.86936950683594, 212.34341430664062, 184.29502868652344, 287.19921875, 127.40234375, 96.45111846923828, 206.5726776123047, 227.6639404296875, 153.47767639160156, 358.9920654296875, 185.19464111328125, 447.30352783203125, 127.60844421386719, 197.35287475585938, 190.34088134765625, 211.01480102539062, 174.80409240722656, 150.13645935058594, 358.6875915527344, 181.98475646972656, 192.06593322753906, 320.4407043457031, 489.3175964355469, 206.54296875, 338.4947509765625, 360.77813720703125, 235.45164489746094, 333.5632019042969, 280.3385009765625, 251.11599731445312, 367.6943054199219, 272.69110107421875, 257.6539611816406, 204.22390747070312, 46.94107437133789, 53.05031967163086, 42.686988830566406, 31.377275466918945, 37.10116195678711, 25.239702224731445, 17.514080047607422, 42.13083267211914, 63.490745544433594, 82.0769271850586, 15.173675537109375, 93.15059661865234, 136.13682556152344, 50.201332092285156, 13.941909790039062, 21.014423370361328, 42.284915924072266, 43.63203430175781, 15.986085891723633, 72.00968170166016, 13.807517051696777, 33.3165283203125, 82.0746078491211, 18.302051544189453, 12.854641914367676, 18.51691436767578, 28.271642684936523, 16.032461166381836, 97.6042251586914, 39.565887451171875, 100.16651153564453, 59.69640350341797, 73.4908676147461, 215.93331909179688, 392.6268310546875, 228.5656280517578, 236.81903076171875, 128.01382446289062, 65.23736572265625, 147.641357421875, 204.07235717773438, 221.9285125732422, 272.69110107421875, 197.02493286132812, 161.17874145507812, 139.52059936523438, 229.5528564453125, 233.1170654296875, 358.4481506347656, 165.24208068847656, 246.27224731445312, 194.75927734375, 246.27682495117188, 246.5818634033203, 190.9844512939453, 286.853515625, 234.5111846923828, 225.776611328125, 191.51080322265625, 287.19921875, 275.9497985839844, 165.04505920410156, 257.6932067871094, 358.6875915527344, 25.796968460083008, 19.378068923950195, 20.43720817565918, 22.622949600219727, 95.08860778808594, 10.421704292297363, 98.57450103759766, 27.622726440429688, 109.41213989257812, 85.27922058105469, 107.21874237060547, 16.90618896484375, 96.03571319580078, 43.52131652832031, 16.27225685119629, 18.28366470336914, 55.748470306396484, 13.43951416015625, 91.98966979980469, 74.36454010009766, 98.13531494140625, 92.5833740234375, 27.653539657592773, 28.166702270507812, 18.25904083251953, 15.375410079956055, 70.48982238769531, 21.615921020507812, 21.685659408569336, 111.65072631835938, 47.64274215698242, 68.75599670410156, 73.16154479980469, 63.843223571777344, 358.6875915527344, 222.45187377929688, 153.63243103027344, 111.1524887084961, 268.4503173828125, 128.49856567382812, 132.9739227294922, 171.00828552246094, 197.35287475585938, 146.08737182617188, 150.85353088378906, 239.16920471191406, 247.4511260986328, 320.4407043457031, 185.4527587890625, 245.06680297851562, 228.06198120117188, 204.52285766601562, 223.372314453125, 360.77813720703125, 252.5200653076172, 447.30352783203125, 265.8866271972656, 195.75628662109375, 227.62432861328125, 21.772010803222656, 18.92620277404785, 18.44707679748535, 13.526309967041016, 11.54314136505127, 32.98540496826172, 24.87142562866211, 31.495441436767578, 19.606063842773438, 229.5450439453125, 20.937076568603516, 236.60589599609375, 16.684633255004883, 19.748897552490234, 37.44078826904297, 34.37397766113281, 27.3471736907959, 10.85328483581543, 26.05725860595703, 62.9771614074707, 32.112083435058594, 29.192995071411133, 12.7662992477417, 29.169021606445312, 21.067110061645508, 14.73243236541748, 18.34536361694336, 15.643052101135254, 10.705358505249023, 43.60164260864258, 34.508541107177734, 40.04541778564453, 62.639617919921875, 40.160888671875, 66.38799285888672, 140.66525268554688, 55.79039764404297, 164.0562744140625, 268.4503173828125, 47.56178283691406, 168.98057556152344, 120.57735443115234, 143.7107696533203, 83.9416732788086, 163.15432739257812, 90.40412139892578, 137.53164672851562, 126.38263702392578, 115.28720092773438, 75.67281341552734, 293.4892578125, 227.63023376464844, 114.38169860839844, 235.45164489746094, 115.79027557373047, 272.97601318359375, 240.31539916992188, 178.180908203125, 239.16920471191406, 210.9416961669922, 245.06680297851562, 195.2066192626953, 177.0640106201172, 181.98475646972656, 160.43492126464844, 229.56752014160156, 287.19921875, 232.79139709472656, 245.1362762451172, 229.5528564453125, 257.6539611816406, 338.4947509765625, 298.0459899902344, 358.4481506347656, 367.6943054199219, 257.6932067871094, 358.9920654296875, 320.4407043457031, 392.6268310546875, 56.16667556762695, 55.2455940246582, 53.116981506347656, 25.120086669921875, 55.32740020751953, 274.15655517578125, 22.05052947998047, 65.0280990600586, 71.11653137207031, 78.17922973632812, 11.40087890625, 74.07481384277344, 130.94464111328125, 87.67108917236328, 121.97056579589844, 132.004150390625, 53.05044937133789, 85.27922058105469, 26.364925384521484, 74.36454010009766, 73.16154479980469, 227.62432861328125, 28.672880172729492, 56.89995574951172, 21.252866744995117, 86.45604705810547, 17.5446834564209, 68.75599670410156, 463.91607666015625, 21.609237670898438, 104.32643127441406, 126.85406494140625, 98.13531494140625, 184.29502868652344, 93.15785217285156, 136.86936950683594, 172.50921630859375, 222.20111083984375, 96.03571319580078, 246.27682495117188, 253.22061157226562, 256.0838623046875, 207.91799926757812, 392.6268310546875, 242.5616455078125, 191.51080322265625, 185.44113159179688, 360.77813720703125, 338.4947509765625, 393.78729248046875, 447.30352783203125, 251.11599731445312, 216.93128967285156, 221.9285125732422, 283.07177734375, 217.83155822753906, 228.06198120117188, 272.97601318359375], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.4986000061035156, 1.3854000568389893, 1.1338000297546387, 1.1032999753952026, 1.0773999691009521, 1.076200008392334, 1.0693000555038452, 1.0648000240325928, 1.0398999452590942, 1.034600019454956, 1.0259000062942505, 1.01010000705719, 1.0045000314712524, 0.9815000295639038, 0.9746000170707703, 0.9480999708175659, 0.9387999773025513, 0.9333000183105469, 0.923799991607666, 0.9211999773979187, 0.9187999963760376, 0.9143000245094299, 0.9135000109672546, 0.9121000170707703, 0.90420001745224, 0.895799994468689, 0.8924000263214111, 0.8892999887466431, 0.8791999816894531, 0.8755999803543091, 0.8665000200271606, 0.871999979019165, 0.8579999804496765, 0.8086000084877014, 0.8208000063896179, 0.7443000078201294, 0.8446999788284302, 0.7993000149726868, 0.7461000084877014, 0.7404999732971191, 0.679099977016449, 0.7408000230789185, 0.8145999908447266, 0.650600016117096, 0.756600022315979, 0.5647000074386597, 0.4864000082015991, 0.6478000283241272, 0.7129999995231628, 0.5393999814987183, 0.5192000269889832, 0.6358000040054321, 0.260699987411499, 0.444599986076355, 0.4108000099658966, 0.4180000126361847, 0.2648000121116638, 0.37869998812675476, 0.49549999833106995, 0.15970000624656677, 0.2985999882221222, 0.18000000715255737, 0.5701000094413757, 0.4185999929904938, 0.4487999975681305, 0.13920000195503235, 0.2590999901294708, 0.21469999849796295, -0.09009999781847, 0.25690001249313354, -0.18379999697208405, 0.09130000323057175, 1.389799952507019, 1.3773000240325928, 1.3566999435424805, 1.2963000535964966, 1.2142000198364258, 1.2000999450683594, 1.1966999769210815, 1.151900053024292, 1.111799955368042, 1.0953999757766724, 1.0871000289916992, 1.0855000019073486, 1.0801000595092773, 1.059999942779541, 1.0546000003814697, 1.051200032234192, 1.045799970626831, 1.0390000343322754, 1.0354000329971313, 1.0250999927520752, 1.0240999460220337, 1.0221999883651733, 1.0145000219345093, 1.0049999952316284, 1.002500057220459, 1.0018999576568604, 1.0008000135421753, 0.9940999746322632, 0.9898999929428101, 0.9799000024795532, 0.9641000032424927, 0.9761999845504761, 0.955299973487854, 0.8920999765396118, 0.9071999788284302, 0.7664999961853027, 0.942300021648407, 0.6836000084877014, 0.7415000200271606, 0.7961999773979187, 0.6643999814987183, 0.7603999972343445, 0.7468000054359436, 0.7609999775886536, 0.7321000099182129, 0.6887999773025513, 0.7310000061988831, 0.5618000030517578, 0.4323999881744385, 0.8205000162124634, 0.4921000003814697, 0.3935000002384186, 0.40459999442100525, 0.6212000250816345, 0.4580000042915344, 0.3483000099658966, 0.5231999754905701, 0.15189999341964722, 0.4878000020980835, 0.3946000039577484, 0.35920000076293945, 0.10610000044107437, 0.5932999849319458, 0.3280999958515167, -0.026599999517202377, 0.3564000129699707, 0.13300000131130219, 0.42559999227523804, 0.3314000070095062, 0.2680000066757202, 0.04839999973773956, 1.2532999515533447, 1.236799955368042, 1.2223999500274658, 1.208899974822998, 1.2029000520706177, 1.1928000450134277, 1.1904000043869019, 1.1866999864578247, 1.1668000221252441, 1.1375999450683594, 1.1324000358581543, 1.1312999725341797, 1.1306999921798706, 1.1080000400543213, 1.1023999452590942, 1.0985000133514404, 1.080399990081787, 1.0714000463485718, 1.055400013923645, 1.049299955368042, 1.0368000268936157, 1.0233999490737915, 1.0187000036239624, 1.013800024986267, 1.0127999782562256, 1.0024000406265259, 0.9970999956130981, 0.9898999929428101, 0.9890999794006348, 0.9822999835014343, 0.9775000214576721, 0.9312000274658203, 0.9438999891281128, 0.7623999714851379, 0.8118000030517578, 0.9175999760627747, 0.7361000180244446, 0.7062000036239624, 0.5807999968528748, 0.7062000036239624, 0.5848000049591064, 0.6110000014305115, 0.6583999991416931, 0.5788000226020813, 0.7339000105857849, 0.6407999992370605, 0.6577000021934509, 0.5618000030517578, 0.7324000000953674, 0.7870000004768372, 0.6021000146865845, 0.5745999813079834, 0.6679999828338623, 0.44279998540878296, 0.595300018787384, 0.33410000801086426, 0.6962000131607056, 0.5593000054359436, 0.5645999908447266, 0.5248000025749207, 0.5878000259399414, 0.6388000249862671, 0.2827000021934509, 0.5397999882698059, 0.5105000138282776, 0.2581000030040741, 0.019500000402331352, 0.4706999957561493, 0.19609999656677246, 0.14270000159740448, 0.366100013256073, 0.1136000007390976, 0.23280000686645508, 0.3034999966621399, -0.052299998700618744, 0.21160000562667847, 0.2671000063419342, 1.7238999605178833, 1.6332000494003296, 1.600100040435791, 1.52839994430542, 1.5145000219345093, 1.3812999725341797, 1.3795000314712524, 1.3509999513626099, 1.2935999631881714, 1.2512999773025513, 1.2466000318527222, 1.2148000001907349, 1.2024999856948853, 1.1793999671936035, 1.159600019454956, 1.1579999923706055, 1.1567000150680542, 1.1216000318527222, 1.118399977684021, 1.1166000366210938, 1.0950000286102295, 1.094599962234497, 1.0892000198364258, 1.0713000297546387, 1.0694999694824219, 1.0672999620437622, 1.0637999773025513, 1.0636999607086182, 1.0547000169754028, 1.0514999628067017, 1.049399971961975, 1.031999945640564, 1.0288000106811523, 1.0170999765396118, 0.9627000093460083, 0.9036999940872192, 0.8159999847412109, 0.8012999892234802, 0.8212000131607056, 0.9455999732017517, 0.7893000245094299, 0.7128000259399414, 0.6855999827384949, 0.5878000259399414, 0.6538000106811523, 0.715399980545044, 0.7544000148773193, 0.5853999853134155, 0.5656999945640564, 0.3662000000476837, 0.6827999949455261, 0.5034999847412109, 0.5819000005722046, 0.43959999084472656, 0.4320000112056732, 0.5612999796867371, 0.2985999882221222, 0.41929998993873596, 0.44429999589920044, 0.5339999794960022, 0.19709999859333038, 0.21799999475479126, 0.6075999736785889, 0.20839999616146088, -0.1477999985218048, 1.6446000337600708, 1.5857000350952148, 1.4456000328063965, 1.347100019454956, 1.3420000076293945, 1.3286999464035034, 1.3246999979019165, 1.3092000484466553, 1.2745000123977661, 1.2681000232696533, 1.2654000520706177, 1.2599999904632568, 1.2466000318527222, 1.243399977684021, 1.204300045967102, 1.2020000219345093, 1.1813000440597534, 1.1771999597549438, 1.1753000020980835, 1.157099962234497, 1.1561000347137451, 1.1437000036239624, 1.1068999767303467, 1.1038000583648682, 1.092900037765503, 1.090399980545044, 1.0606000423431396, 1.0562000274658203, 1.049399971961975, 1.0428999662399292, 1.0426000356674194, 1.0384999513626099, 1.0024000406265259, 1.0053999423980713, 0.847599983215332, 0.8550000190734863, 0.8849999904632568, 0.9128000140190125, 0.7603999972343445, 0.8787000179290771, 0.8634999990463257, 0.8079000115394592, 0.73580002784729, 0.8043000102043152, 0.7785999774932861, 0.6043000221252441, 0.5903000235557556, 0.43790000677108765, 0.6151999831199646, 0.49160000681877136, 0.5095999836921692, 0.5604000091552734, 0.5167999863624573, 0.23800000548362732, 0.35190001130104065, -0.0997999981045723, 0.2493000030517578, 0.5051000118255615, 0.31529998779296875, 1.631600022315979, 1.5750000476837158, 1.4752999544143677, 1.448699951171875, 1.3423000574111938, 1.3310999870300293, 1.301800012588501, 1.2747999429702759, 1.2518999576568604, 1.2474000453948975, 1.2350000143051147, 1.1881999969482422, 1.1862000226974487, 1.1825000047683716, 1.1791000366210938, 1.170300006866455, 1.1679999828338623, 1.1550999879837036, 1.1538000106811523, 1.1506999731063843, 1.1505000591278076, 1.1430000066757202, 1.1319999694824219, 1.0894999504089355, 1.079200029373169, 1.0723999738693237, 1.0637999773025513, 1.062399983406067, 1.0587999820709229, 1.0580999851226807, 1.054900050163269, 1.052899956703186, 1.0317000150680542, 1.0429999828338623, 1.0110000371932983, 0.9427000284194946, 0.9994999766349792, 0.8610000014305115, 0.739300012588501, 1.011299967765808, 0.779699981212616, 0.8313000202178955, 0.7824000120162964, 0.8935999870300293, 0.7400000095367432, 0.8748999834060669, 0.7667999863624573, 0.7718999981880188, 0.7818999886512756, 0.8934999704360962, 0.5098000168800354, 0.5791000127792358, 0.7756999731063843, 0.5519999861717224, 0.7621999979019165, 0.4528000056743622, 0.490200012922287, 0.5964999794960022, 0.4650999903678894, 0.5023999810218811, 0.4406999945640564, 0.499099999666214, 0.5414999723434448, 0.5230000019073486, 0.583299994468689, 0.3846000134944916, 0.2572000026702881, 0.36820000410079956, 0.3368000090122223, 0.37450000643730164, 0.2856000065803528, 0.09600000083446503, 0.17579999566078186, -0.029500000178813934, -0.05820000171661377, 0.23080000281333923, -0.05169999971985817, 0.023000000044703484, -0.17870000004768372, 1.5384000539779663, 1.531999945640564, 1.447100043296814, 1.4395999908447266, 1.4221999645233154, 1.4117000102996826, 1.3931000232696533, 1.3725999593734741, 1.3617000579833984, 1.3614000082015991, 1.3523999452590942, 1.3476999998092651, 1.3391000032424927, 1.3047000169754028, 1.3042999505996704, 1.3033000230789185, 1.2860000133514404, 1.2691999673843384, 1.2541999816894531, 1.2300000190734863, 1.2181999683380127, 1.1959999799728394, 1.1855000257492065, 1.1771999597549438, 1.1725000143051147, 1.1720999479293823, 1.1706000566482544, 1.164199948310852, 1.1612999439239502, 1.1369999647140503, 1.131500005722046, 1.1044000387191772, 1.1038000583648682, 1.0369000434875488, 1.0808000564575195, 1.010599970817566, 0.949400007724762, 0.8420000076293945, 1.0427000522613525, 0.7311999797821045, 0.6823999881744385, 0.6327999830245972, 0.7164000272750854, 0.33320000767707825, 0.5777000188827515, 0.6866000294685364, 0.6976000070571899, 0.13539999723434448, 0.18060000240802765, 0.05510000139474869, -0.05420000106096268, 0.34869998693466187, 0.4569000005722046, 0.43459999561309814, 0.22709999978542328, 0.42640000581741333, 0.375, 0.18440000712871552], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.910699844360352, -7.689799785614014, -8.495200157165527, -8.483099937438965, -6.467100143432617, -6.724800109863281, -8.703100204467773, -6.854300022125244, -6.839700222015381, -6.901899814605713, -6.759799957275391, -6.915500164031982, -7.394400119781494, -7.743000030517578, -8.15410041809082, -8.165599822998047, -8.581000328063965, -7.430699825286865, -7.6570000648498535, -8.283699989318848, -7.065899848937988, -8.29740047454834, -6.703800201416016, -8.58489990234375, -8.072799682617188, -7.235400199890137, -8.693499565124512, -6.73330020904541, -8.12440013885498, -8.654800415039062, -6.150000095367432, -7.408999919891357, -6.227700233459473, -5.184800148010254, -6.51800012588501, -5.3024001121521, -7.018700122833252, -6.480599880218506, -5.81790018081665, -6.345300197601318, -6.079400062561035, -6.526299953460693, -7.023799896240234, -6.305500030517578, -6.824699878692627, -6.076099872589111, -5.811699867248535, -6.421599864959717, -6.709199905395508, -6.281199932098389, -6.264800071716309, -6.541100025177002, -5.822500228881836, -6.212900161743164, -6.236299991607666, -6.257299900054932, -6.151800155639648, -6.276199817657471, -6.401899814605713, -6.144899845123291, -6.267600059509277, -6.196599960327148, -6.4878997802734375, -6.423799991607666, -6.444499969482422, -6.351200103759766, -6.39300012588501, -6.388700008392334, -6.369200229644775, -6.418300151824951, -6.394400119781494, -6.413300037384033, -7.313300132751465, -6.6803998947143555, -6.837699890136719, -6.954899787902832, -7.0995001792907715, -7.038000106811523, -7.38640022277832, -8.052800178527832, -7.590199947357178, -7.609399795532227, -7.1006999015808105, -6.683199882507324, -8.029000282287598, -8.081299781799316, -8.409500122070312, -7.525300025939941, -8.5024995803833, -8.743599891662598, -8.338399887084961, -7.265500068664551, -8.187999725341797, -7.671199798583984, -8.07349967956543, -7.654900074005127, -8.182600021362305, -7.982600212097168, -8.721400260925293, -8.606900215148926, -8.13070011138916, -8.547300338745117, -5.586299896240234, -8.00790023803711, -7.876100063323975, -6.940299987792969, -7.202700138092041, -5.992099761962891, -7.68149995803833, -5.5954999923706055, -6.22599983215332, -6.697000026702881, -5.826000213623047, -6.494200229644775, -6.416399955749512, -6.611100196838379, -6.483699798583984, -6.28410005569458, -6.547599792480469, -6.024499893188477, -5.778200149536133, -7.0081000328063965, -6.073999881744385, -5.909599781036377, -5.957200050354004, -6.5381999015808105, -6.2220001220703125, -6.028299808502197, -6.3572001457214355, -5.841400146484375, -6.346700191497803, -6.240200042724609, -6.218900203704834, -5.9770002365112305, -6.532800197601318, -6.350599765777588, -6.240099906921387, -6.42110013961792, -6.356100082397461, -6.489999771118164, -6.47130012512207, -6.468200206756592, -6.456200122833252, -7.510499954223633, -7.530200004577637, -8.119600296020508, -8.19480037689209, -7.27209997177124, -7.914400100708008, -7.738100051879883, -7.9928998947143555, -7.849400043487549, -8.133199691772461, -8.217700004577637, -8.674699783325195, -8.245699882507324, -7.8231000900268555, -8.488499641418457, -7.757699966430664, -8.187999725341797, -8.570099830627441, -8.645099639892578, -7.2692999839782715, -8.49429988861084, -7.753699779510498, -7.373899936676025, -7.882400035858154, -8.232799530029297, -7.6774001121521, -7.846399784088135, -7.499100208282471, -8.600299835205078, -7.944499969482422, -7.538300037384033, -6.618199825286865, -7.287600040435791, -5.778299808502197, -6.481400012969971, -7.477399826049805, -6.293300151824951, -6.138000011444092, -5.629799842834473, -6.31689977645874, -5.719799995422363, -5.916399955749512, -6.160799980163574, -5.910299777984619, -6.5335001945495605, -6.187399864196777, -6.312099933624268, -5.964399814605713, -6.606599807739258, -6.830399990081787, -6.253699779510498, -6.183899879455566, -6.484799861907959, -5.860300064086914, -6.369699954986572, -5.749100208282471, -6.641200065612793, -6.342100143432617, -6.373000144958496, -6.309599876403809, -6.434899806976318, -6.535999774932861, -6.021299839019775, -6.442699909210205, -6.418099880218506, -6.1585001945495605, -5.973899841308594, -6.385200023651123, -6.165800094604492, -6.1554999351501465, -6.358799934387207, -6.263000011444092, -6.317500114440918, -6.35699987411499, -6.331399917602539, -6.366399765014648, -6.367599964141846, -5.143199920654297, -6.7042999267578125, -6.614999771118164, -6.904099941253662, -7.225800037384033, -7.191400051116943, -7.578499794006348, -7.972400188446045, -7.1519999504089355, -6.784200191497803, -6.532100200653076, -8.252099990844727, -6.449699878692627, -6.093299865722656, -7.110799789428711, -8.393500328063965, -7.984399795532227, -7.320300102233887, -7.292200088500977, -8.298100471496582, -6.814599990844727, -8.46660041809082, -7.591100215911865, -6.707499980926514, -8.20989990234375, -8.565400123596191, -8.203900337219238, -7.780799865722656, -8.357099533081055, -6.553999900817871, -7.459000110626221, -6.547500133514404, -7.068299770355225, -6.872099876403809, -5.848700046539307, -5.309899806976318, -5.938600063323975, -5.917799949645996, -6.5131001472473145, -7.062699794769287, -6.402299880981445, -6.155099868774414, -6.098400115966797, -5.990300178527832, -6.249300003051758, -6.388400077819824, -6.493800163269043, -6.164899826049805, -6.169099807739258, -5.938399791717529, -6.396200180053711, -6.176400184631348, -6.332799911499023, -6.240300178527832, -6.246699810028076, -6.372900009155273, -6.228799819946289, -6.309599876403809, -6.322500228881836, -6.397500038146973, -6.329100131988525, -6.348199844360352, -6.472599983215332, -6.426199913024902, -6.451700210571289, -7.291500091552734, -7.636499881744385, -7.723499774932861, -7.720300197601318, -6.289599895477295, -8.513799667358398, -6.2708001136779785, -7.558499813079834, -6.216700077056885, -6.472300052642822, -6.246099948883057, -8.098699569702148, -6.375100135803223, -7.1697001457214355, -8.19260025024414, -8.078399658203125, -6.9842000007629395, -8.41100025177002, -6.4893999099731445, -6.720300197601318, -6.443900108337402, -6.514599800109863, -7.759699821472168, -7.7444000244140625, -8.188799858093262, -8.363200187683105, -6.870299816131592, -8.05679988861084, -8.060400009155273, -6.428100109100342, -7.280099868774414, -6.917300224304199, -6.891300201416016, -7.024499893188477, -5.456399917602539, -5.926700115203857, -6.2667999267578125, -6.562699794769287, -5.8333001136779785, -6.4517998695373535, -6.432700157165527, -6.236800193786621, -6.165599822998047, -6.397900104522705, -6.391499996185303, -6.104899883270264, -6.08489990234375, -5.978799819946289, -6.348400115966797, -6.193299770355225, -6.247200012207031, -6.3053998947143555, -6.260700225830078, -6.060100078582764, -6.302999973297119, -6.1828999519348145, -6.354100227355957, -6.404399871826172, -6.443399906158447, -7.474100112915039, -7.67080020904541, -7.796199798583984, -8.133099555969238, -8.39799976348877, -7.3592000007629395, -7.670899868011475, -7.4618000984191895, -7.958600044250488, -5.502900123596191, -7.909900188446045, -5.531799793243408, -8.185700416564941, -8.02079963684082, -7.384500026702881, -7.478799819946289, -7.709799766540527, -8.64680004119873, -7.772299766540527, -6.892899990081787, -7.5665998458862305, -7.669400215148926, -8.507599830627441, -7.723700046539307, -8.059499740600586, -8.42389965057373, -8.213199615478516, -8.373900413513184, -8.756799697875977, -7.3531999588012695, -7.590199947357178, -7.44350004196167, -7.017300128936768, -7.450500011444092, -6.979899883270264, -6.297399997711182, -7.165200233459473, -6.225200176239014, -5.854400157928467, -7.3130998611450195, -6.276899814605713, -6.56279993057251, -6.436200141906738, -6.86269998550415, -6.3516998291015625, -6.807199954986572, -6.495800018310547, -6.575200080871582, -6.6570000648498535, -6.966400146484375, -5.994800090789795, -6.179500102996826, -6.67110013961792, -6.172900199890137, -6.672399997711182, -6.124199867248535, -6.214300155639648, -6.407100200653076, -6.244100093841553, -6.332399845123291, -6.244100093841553, -6.4131999015808105, -6.468299865722656, -6.459499835968018, -6.525199890136719, -6.365600109100342, -6.269000053405762, -6.368100166320801, -6.347799777984619, -6.375699996948242, -6.3491997718811035, -6.265900135040283, -6.313399791717529, -6.334099769592285, -6.337299823760986, -6.403800010681152, -6.354800224304199, -6.393700122833252, -6.392199993133545, -6.619699954986572, -6.642600059509277, -6.7667999267578125, -7.523099899291992, -6.750899791717529, -5.160900115966797, -7.699999809265137, -6.638899803161621, -6.560400009155273, -6.46589994430542, -8.400300025939941, -6.533599853515625, -5.972499847412109, -6.408100128173828, -6.0782999992370605, -6.00029993057251, -6.929200172424316, -6.47130012512207, -7.660099983215332, -6.64739990234375, -6.67549991607666, -5.562699794769287, -7.644899845123291, -6.967899799346924, -7.957399845123291, -6.554599761962891, -8.151000022888184, -6.791600227355957, -4.88539981842041, -7.97629976272583, -6.407299995422363, -6.238900184631348, -6.496200084686279, -5.9328999519348145, -6.571300029754639, -6.256800174713135, -6.08650016784668, -5.940800189971924, -6.578999996185303, -5.948800086975098, -5.969699859619141, -6.0081000328063965, -6.132900238037109, -5.880300045013428, -6.117499828338623, -6.244900226593018, -6.26609992980957, -6.162700176239014, -6.181300163269043, -6.155399799346924, -6.13730001449585, -6.311699867248535, -6.349899768829346, -6.3495001792907715, -6.313600063323975, -6.376299858093262, -6.381800174713135, -6.392600059509277]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 2, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 3, 4, 5, 7, 1, 2, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 3, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 3, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 6, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 3, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 2, 3, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 6, 7, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 5, 6, 7, 1, 2, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 5, 6, 7, 1, 2, 3, 4, 5, 6], \"Freq\": [0.43545374274253845, 0.031103838235139847, 0.3214063346385956, 0.02073589153587818, 0.04147178307175636, 0.07257562130689621, 0.07257562130689621, 0.0372464545071125, 0.074492909014225, 0.40971097350120544, 0.0372464545071125, 0.074492909014225, 0.2607251703739166, 0.11173935979604721, 0.09252019971609116, 0.09252019971609116, 0.462600976228714, 0.09252019971609116, 0.09252019971609116, 0.09252019971609116, 0.08771253377199173, 0.08771253377199173, 0.08771253377199173, 0.08771253377199173, 0.08771253377199173, 0.08771253377199173, 0.43856269121170044, 0.1983298808336258, 0.05876440927386284, 0.05876440927386284, 0.4701152741909027, 0.05141885578632355, 0.08814661204814911, 0.06610996276140213, 0.4454268217086792, 0.07423780113458633, 0.14847560226917267, 0.14847560226917267, 0.07423780113458633, 0.07423780113458633, 0.07423780113458633, 0.15294304490089417, 0.1169564425945282, 0.1079597994685173, 0.08096984773874283, 0.3418726921081543, 0.1079597994685173, 0.08996649831533432, 0.0753689780831337, 0.4522138833999634, 0.1507379561662674, 0.0753689780831337, 0.0753689780831337, 0.1507379561662674, 0.0912378653883934, 0.4561893343925476, 0.0912378653883934, 0.1824757307767868, 0.12165048718452454, 0.06082524359226227, 0.030412621796131134, 0.01834220066666603, 0.49523940682411194, 0.03668440133333206, 0.03668440133333206, 0.22010640799999237, 0.09171100705862045, 0.12839540839195251, 0.06134467199444771, 0.49075737595558167, 0.09201700985431671, 0.09201700985431671, 0.09201700985431671, 0.09201700985431671, 0.06134467199444771, 0.14480829238891602, 0.14480829238891602, 0.036202073097229004, 0.07240414619445801, 0.506829023361206, 0.10860622674226761, 0.036202073097229004, 0.1454588770866394, 0.05818354710936546, 0.17455065250396729, 0.05818354710936546, 0.08727532625198364, 0.37819308042526245, 0.05818354710936546, 0.06981773674488068, 0.41890642046928406, 0.1745443493127823, 0.06981773674488068, 0.13963547348976135, 0.06981773674488068, 0.13247179985046387, 0.11504129320383072, 0.2719157934188843, 0.19522158801555634, 0.0941246971487999, 0.09063859283924103, 0.10109689831733704, 0.07585836201906204, 0.1896459013223648, 0.1896459013223648, 0.03792918100953102, 0.03792918100953102, 0.03792918100953102, 0.3792918026447296, 0.43476712703704834, 0.29890239238739014, 0.05434589087963104, 0.05434589087963104, 0.08151883631944656, 0.05434589087963104, 0.05446702241897583, 0.5446702241897583, 0.1634010672569275, 0.05446702241897583, 0.05446702241897583, 0.08170053362846375, 0.05446702241897583, 0.136110320687294, 0.136110320687294, 0.18937088549137115, 0.06509623676538467, 0.14202815294265747, 0.2544671297073364, 0.0769319161772728, 0.1210227832198143, 0.1016591340303421, 0.2710910439491272, 0.1984773576259613, 0.1113409623503685, 0.1161818727850914, 0.0822954922914505, 0.6448630094528198, 0.1535388082265854, 0.061415523290634155, 0.09212328493595123, 0.15697798132896423, 0.07848899066448212, 0.4709339439868927, 0.07848899066448212, 0.15697798132896423, 0.07848899066448212, 0.08528584241867065, 0.07310215383768082, 0.048734769225120544, 0.5117150545120239, 0.08528584241867065, 0.12183692306280136, 0.07310215383768082, 0.3582572638988495, 0.10235921293497086, 0.0682394802570343, 0.017059870064258575, 0.16206875443458557, 0.05117960646748543, 0.24736811220645905, 0.13246431946754456, 0.1612609177827835, 0.3110032081604004, 0.09790841490030289, 0.08638978004455566, 0.08638978004455566, 0.12094569206237793, 0.18272121250629425, 0.07714895904064178, 0.11775366961956024, 0.22738640010356903, 0.08120942860841751, 0.08120942860841751, 0.23550733923912048, 0.15768280625343323, 0.07167400419712067, 0.0931762084364891, 0.3081982135772705, 0.107511006295681, 0.17918500304222107, 0.07884140312671661, 0.11987078189849854, 0.05993539094924927, 0.05993539094924927, 0.05993539094924927, 0.1798061728477478, 0.3596123456954956, 0.11987078189849854, 0.16649281978607178, 0.41623204946517944, 0.16649281978607178, 0.08324640989303589, 0.08324640989303589, 0.054638683795928955, 0.32783210277557373, 0.43710947036743164, 0.054638683795928955, 0.054638683795928955, 0.054638683795928955, 0.1584719866514206, 0.1584719866514206, 0.4225919842720032, 0.1056479960680008, 0.0528239980340004, 0.0528239980340004, 0.0528239980340004, 0.02345237135887146, 0.03517855703830719, 0.03517855703830719, 0.01172618567943573, 0.4807736277580261, 0.01172618567943573, 0.3986903131008148, 0.14718949794769287, 0.18271799385547638, 0.10658549517393112, 0.2791524827480316, 0.10150999575853348, 0.09643449634313583, 0.08628349751234055, 0.034699711948633194, 0.057832855731248856, 0.17349857091903687, 0.023133141919970512, 0.3238639831542969, 0.011566570959985256, 0.3701302707195282, 0.16968406736850739, 0.4072417616844177, 0.10181044042110443, 0.050905220210552216, 0.050905220210552216, 0.20362088084220886, 0.03393681347370148, 0.21813808381557465, 0.07898103445768356, 0.18428906798362732, 0.14291805028915405, 0.17676706612110138, 0.13163505494594574, 0.06769802421331406, 0.28549402952194214, 0.1302739679813385, 0.1718507707118988, 0.06375109404325485, 0.1718507707118988, 0.04712037369608879, 0.1302739679813385, 0.39211565256118774, 0.09617931395769119, 0.2367490828037262, 0.05178886279463768, 0.1405697613954544, 0.022195225581526756, 0.05918727070093155, 0.054838523268699646, 0.06397827714681625, 0.09139753878116608, 0.054838523268699646, 0.4844069480895996, 0.054838523268699646, 0.19193482398986816, 0.11822772771120071, 0.33990469574928284, 0.08128155767917633, 0.14778465032577515, 0.11822772771120071, 0.11083849519491196, 0.08128155767917633, 0.04685268551111221, 0.11713171005249023, 0.023426342755556107, 0.6793639063835144, 0.04685268551111221, 0.04685268551111221, 0.04685268551111221, 0.46997883915901184, 0.1409936547279358, 0.09399576485157013, 0.046997882425785065, 0.1409936547279358, 0.09399576485157013, 0.046997882425785065, 0.16045938432216644, 0.32635805010795593, 0.1414218246936798, 0.11422532051801682, 0.09246812015771866, 0.1115056723356247, 0.05439300835132599, 0.1080825999379158, 0.0540412999689579, 0.4323303997516632, 0.1080825999379158, 0.1080825999379158, 0.0540412999689579, 0.0540412999689579, 0.12878383696079254, 0.06060415506362915, 0.2727186977863312, 0.03787759691476822, 0.06060415506362915, 0.02272655814886093, 0.416653573513031, 0.045125365257263184, 0.45125362277030945, 0.13537609577178955, 0.18050146102905273, 0.045125365257263184, 0.09025073051452637, 0.045125365257263184, 0.47979533672332764, 0.04233488440513611, 0.014111627824604511, 0.014111627824604511, 0.21167440712451935, 0.014111627824604511, 0.22578604519367218, 0.08152009546756744, 0.04076004773378372, 0.06114007160067558, 0.02038002386689186, 0.43817049264907837, 0.01019001193344593, 0.34646040201187134, 0.36559000611305237, 0.10967700183391571, 0.1340496689081192, 0.1584223359823227, 0.07311800122261047, 0.07921116799116135, 0.07311800122261047, 0.18336012959480286, 0.10660472512245178, 0.14498242735862732, 0.2217378318309784, 0.1705675572156906, 0.08954796940088272, 0.0852837786078453, 0.1757235825061798, 0.355840265750885, 0.11861341446638107, 0.04832398518919945, 0.05711016431450844, 0.21086829900741577, 0.03953780606389046, 0.07675404846668243, 0.15350809693336487, 0.15350809693336487, 0.11513106524944305, 0.383770227432251, 0.07675404846668243, 0.07131453603506088, 0.16045770049095154, 0.05603284761309624, 0.35911962389945984, 0.09933096170425415, 0.09933096170425415, 0.15791074931621552, 0.1439030021429062, 0.2518302798271179, 0.1130666509270668, 0.12334543466567993, 0.17473936080932617, 0.09764847159385681, 0.08736968040466309, 0.1887391358613968, 0.12402857840061188, 0.11863603442907333, 0.17256149649620056, 0.10245838761329651, 0.07010310888290405, 0.2264869660139084, 0.08012651652097702, 0.05341767892241478, 0.1335441917181015, 0.05341767892241478, 0.24037955701351166, 0.37392374873161316, 0.05341767892241478, 0.11419383436441422, 0.05709691718220711, 0.5709691643714905, 0.05709691718220711, 0.11419383436441422, 0.05709691718220711, 0.14286969602108002, 0.1685129702091217, 0.13920636475086212, 0.10623644292354584, 0.12088974565267563, 0.1831662803888321, 0.13554304838180542, 0.12393587082624435, 0.0495743490755558, 0.3965947926044464, 0.07436152547597885, 0.0991486981511116, 0.0991486981511116, 0.17351022362709045, 0.22746866941452026, 0.07582288980484009, 0.176920086145401, 0.40438875555992126, 0.05054859444499016, 0.02527429722249508, 0.05054859444499016, 0.2674887478351593, 0.1624038815498352, 0.12419120222330093, 0.07642535865306854, 0.08597853034734726, 0.1289677917957306, 0.15762729942798615, 0.15147727727890015, 0.35344696044921875, 0.17311687767505646, 0.057705625891685486, 0.08655843883752823, 0.06491883099079132, 0.1226244568824768, 0.05699732527136803, 0.11399465054273605, 0.11399465054273605, 0.05699732527136803, 0.17099197208881378, 0.11399465054273605, 0.34198394417762756, 0.13273809850215912, 0.12799745798110962, 0.13273809850215912, 0.08059098571538925, 0.1659226268529892, 0.19436649978160858, 0.1611819714307785, 0.08508193492889404, 0.4254096746444702, 0.08508193492889404, 0.08508193492889404, 0.17016386985778809, 0.17016386985778809, 0.22072607278823853, 0.05518151819705963, 0.22072607278823853, 0.04729844629764557, 0.04729844629764557, 0.07094766944646835, 0.33897218108177185, 0.4169079065322876, 0.0694846510887146, 0.1389693021774292, 0.0694846510887146, 0.1389693021774292, 0.0694846510887146, 0.0694846510887146, 0.37001439929008484, 0.16000622510910034, 0.10000389069318771, 0.0700027272105217, 0.1400054544210434, 0.08000311255455017, 0.0700027272105217, 0.14982987940311432, 0.07491493970155716, 0.09988658130168915, 0.07491493970155716, 0.14982987940311432, 0.32463139295578003, 0.07491493970155716, 0.1323123425245285, 0.15320375561714172, 0.2576608657836914, 0.17757707834243774, 0.08356568962335587, 0.15320375561714172, 0.04178284481167793, 0.712803304195404, 0.13365061581134796, 0.04455020651221275, 0.0891004130244255, 0.29912227392196655, 0.1962990015745163, 0.09814950078725815, 0.08880192786455154, 0.07010678201913834, 0.09814950078725815, 0.14488735795021057, 0.03075849823653698, 0.4921359717845917, 0.03075849823653698, 0.03075849823653698, 0.33834347128868103, 0.03075849823653698, 0.03075849823653698, 0.11824547499418259, 0.07094728201627731, 0.07094728201627731, 0.4493328034877777, 0.11824547499418259, 0.09459637850522995, 0.09459637850522995, 0.04611342400312424, 0.04611342400312424, 0.04611342400312424, 0.04611342400312424, 0.3689073920249939, 0.32279396057128906, 0.09222684800624847, 0.19170597195625305, 0.09585298597812653, 0.028755895793437958, 0.04792649298906326, 0.19170597195625305, 0.09585298597812653, 0.35465604066848755, 0.11109617352485657, 0.15275724232196808, 0.08332213014364243, 0.4304976761341095, 0.06943510472774506, 0.08332213014364243, 0.055548086762428284, 0.09230940788984299, 0.6461658477783203, 0.036923762410879135, 0.036923762410879135, 0.036923762410879135, 0.05538564547896385, 0.1107712909579277, 0.059149935841560364, 0.059149935841560364, 0.059149935841560364, 0.4731994867324829, 0.1774498075246811, 0.1774498075246811, 0.1052345484495163, 0.13154318928718567, 0.18416045606136322, 0.14031273126602173, 0.2280081957578659, 0.04384772852063179, 0.1666213721036911, 0.19719313085079193, 0.1346684694290161, 0.16833560168743134, 0.08657259494066238, 0.07214382290840149, 0.10581094771623611, 0.23086024820804596, 0.19718985259532928, 0.460109680891037, 0.06572995334863663, 0.06572995334863663, 0.06572995334863663, 0.06572995334863663, 0.06572995334863663, 0.04049959406256676, 0.10799892246723175, 0.10799892246723175, 0.0674993246793747, 0.10799892246723175, 0.12149878591299057, 0.431995689868927, 0.42139169573783875, 0.07023195177316666, 0.1404639035463333, 0.1404639035463333, 0.1404639035463333, 0.03730690851807594, 0.06528709083795547, 0.04663363844156265, 0.027980182319879532, 0.48498982191085815, 0.055960364639759064, 0.28912854194641113, 0.14484862983226776, 0.21727295219898224, 0.4345459043979645, 0.07242431491613388, 0.14484862983226776, 0.07242431491613388, 0.06307585537433624, 0.0841011330485344, 0.0841011330485344, 0.21025283634662628, 0.14717699587345123, 0.31537926197052, 0.0841011330485344, 0.1145947054028511, 0.1145947054028511, 0.1145947054028511, 0.4354598820209503, 0.0458378829061985, 0.091675765812397, 0.091675765812397, 0.2544759511947632, 0.060589514672756195, 0.133296936750412, 0.266593873500824, 0.12117902934551239, 0.066648468375206, 0.090884268283844, 0.46297091245651245, 0.09259418398141861, 0.09259418398141861, 0.09259418398141861, 0.23148545622825623, 0.046297091990709305, 0.046297091990709305, 0.17425180971622467, 0.08712590485811234, 0.1001947894692421, 0.2613777220249176, 0.12633256614208221, 0.16989551484584808, 0.07841331511735916, 0.13319221138954163, 0.15880608558654785, 0.09220998734235764, 0.15880608558654785, 0.1690516471862793, 0.19466553628444672, 0.09733276814222336, 0.23881079256534576, 0.04776215925812721, 0.09552431851625443, 0.04776215925812721, 0.09552431851625443, 0.3820972740650177, 0.09552431851625443, 0.03150065243244171, 0.047250982373952866, 0.07875163108110428, 0.5040104389190674, 0.18900392949581146, 0.09450196474790573, 0.03150065243244171, 0.08173428475856781, 0.14814339578151703, 0.16346856951713562, 0.2094441056251526, 0.22476927936077118, 0.097059465944767, 0.07151749730110168, 0.2193126529455185, 0.03655210882425308, 0.04873614385724068, 0.4264412820339203, 0.06092018261551857, 0.08528825640678406, 0.12184036523103714, 0.4001891016960144, 0.13339637219905853, 0.10200899094343185, 0.08631529659032822, 0.10985583066940308, 0.10985583066940308, 0.06277476251125336, 0.07237321883440018, 0.48248812556266785, 0.14474643766880035, 0.06031101569533348, 0.10855982452630997, 0.048248812556266785, 0.08443541824817657, 0.1246832013130188, 0.23469778895378113, 0.18335765600204468, 0.26036787033081055, 0.07701021432876587, 0.06600875407457352, 0.04767299070954323, 0.19080767035484314, 0.17377126216888428, 0.1260693520307541, 0.14651302993297577, 0.09199655055999756, 0.19421494007110596, 0.07496015727519989, 0.05862974748015404, 0.6058407425880432, 0.019543249160051346, 0.07817299664020538, 0.05862974748015404, 0.09771624952554703, 0.09771624952554703, 0.4110601246356964, 0.17238005995750427, 0.14586004614830017, 0.05304001644253731, 0.06630001962184906, 0.05304001644253731, 0.10608003288507462, 0.03620198369026184, 0.05430297181010246, 0.05430297181010246, 0.01810099184513092, 0.2896158695220947, 0.01810099184513092, 0.5249287486076355, 0.36860114336013794, 0.06897799670696259, 0.058200180530548096, 0.05388905853033066, 0.04311124607920647, 0.045266807079315186, 0.3621344566345215, 0.08968856185674667, 0.23319025337696075, 0.053813137114048004, 0.07175084948539734, 0.4484427869319916, 0.08968856185674667, 0.017937712371349335, 0.10283596813678741, 0.398489385843277, 0.1671084463596344, 0.03856348991394043, 0.10283596813678741, 0.11569046229124069, 0.06427247822284698, 0.09524992853403091, 0.14967846870422363, 0.10885706543922424, 0.4082139730453491, 0.06803566217422485, 0.1360713243484497, 0.04082139953970909, 0.05400467664003372, 0.10800935328006744, 0.05400467664003372, 0.4320374131202698, 0.16201403737068176, 0.05400467664003372, 0.16201403737068176, 0.09951908886432648, 0.2701232433319092, 0.2511672079563141, 0.0947800800204277, 0.10425809025764465, 0.07108505815267563, 0.1137361004948616, 0.10884544253349304, 0.3265363276004791, 0.17415271699428558, 0.14149907231330872, 0.08707635849714279, 0.08707635849714279, 0.08163408190011978, 0.23555009067058563, 0.268164724111557, 0.06522925943136215, 0.18119238317012787, 0.09784388542175293, 0.07610079646110535, 0.07610079646110535, 0.11061442643404007, 0.12167587131261826, 0.055307213217020035, 0.14379875361919403, 0.1659216433763504, 0.27653607726097107, 0.13273730874061584, 0.13068050146102905, 0.20473279058933258, 0.11325643956661224, 0.13503652811050415, 0.10454440861940384, 0.17424067854881287, 0.14374855160713196, 0.12424885481595993, 0.10165815055370331, 0.08471512794494629, 0.23720234632492065, 0.12989652156829834, 0.20331630110740662, 0.11295349895954132, 0.10320945829153061, 0.051604729145765305, 0.051604729145765305, 0.051604729145765305, 0.6708614826202393, 0.051604729145765305, 0.051604729145765305, 0.15403631329536438, 0.11809450387954712, 0.09242178499698639, 0.2618617117404938, 0.10782541334629059, 0.10782541334629059, 0.15917085111141205, 0.1608271300792694, 0.04020678251981735, 0.12062034755945206, 0.0804135650396347, 0.12062034755945206, 0.4422746002674103, 0.04020678251981735, 0.1405976414680481, 0.07029882073402405, 0.298770010471344, 0.035149410367012024, 0.052724119275808334, 0.035149410367012024, 0.36906883120536804, 0.13201458752155304, 0.16624058783054352, 0.15646173059940338, 0.08800972253084183, 0.23958201706409454, 0.09778857976198196, 0.1222357228398323, 0.15119227766990662, 0.19978979229927063, 0.26998621225357056, 0.11879393458366394, 0.05399724096059799, 0.11879393458366394, 0.09179531037807465, 0.07214470207691193, 0.3082546591758728, 0.07870331406593323, 0.24922716617584229, 0.17052385210990906, 0.05902748554944992, 0.06558609753847122, 0.33715856075286865, 0.13379308581352234, 0.10703446716070175, 0.17660686373710632, 0.14449653029441833, 0.04816551133990288, 0.053517233580350876, 0.08658789843320847, 0.24644246697425842, 0.27974551916122437, 0.07992728799581528, 0.18649700284004211, 0.07326667755842209, 0.03996364399790764, 0.4150480329990387, 0.20468121767044067, 0.09096943587064743, 0.09665502607822418, 0.09096943587064743, 0.05117030441761017, 0.045484717935323715, 0.12137456983327866, 0.1798141747713089, 0.0809163749217987, 0.18430952727794647, 0.31917014718055725, 0.06293495744466782, 0.0494488961994648, 0.13180722296237946, 0.06590361148118973, 0.06590361148118973, 0.4613252580165863, 0.06590361148118973, 0.06590361148118973, 0.06590361148118973, 0.2632708251476288, 0.16896484792232513, 0.07858829945325851, 0.16110602021217346, 0.11395303905010223, 0.09430596232414246, 0.1218118667602539, 0.1920265555381775, 0.11521593481302261, 0.384053111076355, 0.03840531036257744, 0.07681062072515488, 0.03840531036257744, 0.11521593481302261, 0.07967916131019592, 0.15322916209697723, 0.134841650724411, 0.09806665778160095, 0.1900041550397873, 0.24516664445400238, 0.09193749725818634, 0.19911116361618042, 0.14336004853248596, 0.19911116361618042, 0.08760891109704971, 0.10752002894878387, 0.10353780537843704, 0.1592889428138733, 0.15964338183403015, 0.15964338183403015, 0.11175036430358887, 0.06385734677314758, 0.11175036430358887, 0.3352510929107666, 0.06385734677314758, 0.0652560144662857, 0.16314002871513367, 0.5220481157302856, 0.03262800723314285, 0.16314002871513367, 0.03262800723314285, 0.03262800723314285, 0.10276437550783157, 0.17127396166324615, 0.20552875101566315, 0.10276437550783157, 0.03425479307770729, 0.3768027126789093, 0.03425479307770729, 0.059997834265232086, 0.11999566853046417, 0.38998591899871826, 0.14999458193778992, 0.08999674767255783, 0.08999674767255783, 0.059997834265232086, 0.0635012537240982, 0.0317506268620491, 0.1270025074481964, 0.22225438058376312, 0.0317506268620491, 0.41275814175605774, 0.0635012537240982, 0.09025873243808746, 0.04512936621904373, 0.36103492975234985, 0.1353880912065506, 0.15795277059078217, 0.11282341182231903, 0.09025873243808746, 0.4146955609321594, 0.08293911069631577, 0.12440866976976395, 0.16587822139263153, 0.12440866976976395, 0.04146955534815788, 0.04146955534815788, 0.019586345180869102, 0.09303513914346695, 0.009793172590434551, 0.8177299499511719, 0.019586345180869102, 0.02937951870262623, 0.009793172590434551, 0.10598018765449524, 0.1201108768582344, 0.3179405629634857, 0.10951285809278488, 0.11657820641994476, 0.08478415012359619, 0.14130692183971405, 0.06004771217703819, 0.48038169741630554, 0.06004771217703819, 0.12009542435407639, 0.06004771217703819, 0.12009542435407639, 0.12009542435407639, 0.02705521695315838, 0.4599386751651764, 0.02705521695315838, 0.16233129799365997, 0.10822086781263351, 0.10822086781263351, 0.05411043390631676, 0.42731720209121704, 0.05211185663938522, 0.04168948531150818, 0.02084474265575409, 0.17718030512332916, 0.031267113983631134, 0.23971453309059143, 0.03550291433930397, 0.10650873929262161, 0.14201165735721588, 0.07100582867860794, 0.42603495717048645, 0.03550291433930397, 0.17751456797122955, 0.542537271976471, 0.07750532776117325, 0.1550106555223465, 0.1550106555223465, 0.07750532776117325, 0.07750532776117325, 0.15325453877449036, 0.4597635865211487, 0.1021696925163269, 0.1021696925163269, 0.05108484625816345, 0.05108484625816345, 0.43333739042282104, 0.08666747808456421, 0.08666747808456421, 0.06933397799730301, 0.052000485360622406, 0.06933397799730301, 0.20800194144248962, 0.03273128345608711, 0.13092513382434845, 0.5237005352973938, 0.06546256691217422, 0.22911898791790009, 0.03273128345608711, 0.03273128345608711, 0.10127147287130356, 0.05063573643565178, 0.05063573643565178, 0.20254294574260712, 0.10127147287130356, 0.40508589148521423, 0.20254294574260712, 0.11355255544185638, 0.22710511088371277, 0.15005159378051758, 0.22304965555667877, 0.10949710756540298, 0.08516441285610199, 0.09327530860900879, 0.4757053554058075, 0.09061054140329361, 0.11326317489147186, 0.06795790791511536, 0.11326317489147186, 0.09061054140329361, 0.045305270701646805, 0.1706293374300003, 0.14000354707241058, 0.08750221878290176, 0.32813331484794617, 0.12687821686267853, 0.07875199615955353, 0.06562666594982147, 0.10188330709934235, 0.11577647924423218, 0.1389317810535431, 0.37974685430526733, 0.18524236977100372, 0.023155296221375465, 0.05094165354967117, 0.14345237612724304, 0.14345237612724304, 0.07172618806362152, 0.43035709857940674, 0.07172618806362152, 0.07172618806362152, 0.07172618806362152, 0.06187400966882706, 0.12374801933765411, 0.49499207735061646, 0.06187400966882706, 0.18562203645706177, 0.06187400966882706, 0.07831684499979019, 0.06265347450971603, 0.12530694901943207, 0.17229706048965454, 0.3759208619594574, 0.09398021548986435, 0.10964358597993851, 0.18405215442180634, 0.1549912989139557, 0.37779128551483154, 0.07749564945697784, 0.08718260377645493, 0.048434779047966, 0.07749564945697784, 0.26674702763557434, 0.13337351381778717, 0.1454983800649643, 0.12529027462005615, 0.1010405421257019, 0.14145676791667938, 0.08891567587852478, 0.056729741394519806, 0.42547306418418884, 0.056729741394519806, 0.08509461581707001, 0.14182434976100922, 0.08509461581707001, 0.17018923163414001, 0.14314419031143188, 0.07157209515571594, 0.42943257093429565, 0.28628838062286377, 0.03578604757785797, 0.03578604757785797, 0.07520271837711334, 0.20304733514785767, 0.11280407011508942, 0.10528380423784256, 0.32337167859077454, 0.11280407011508942, 0.06768244504928589, 0.07093892246484756, 0.12667664885520935, 0.25842034816741943, 0.07600598782300949, 0.28375568985939026, 0.14187784492969513, 0.04053652659058571, 0.18626800179481506, 0.17462626099586487, 0.10089517384767532, 0.17850683629512787, 0.1358204185962677, 0.1474621742963791, 0.07373108714818954, 0.4227932393550873, 0.16106408834457397, 0.06039903312921524, 0.040266022086143494, 0.12079806625843048, 0.08053204417228699, 0.12079806625843048, 0.12201199680566788, 0.4473773241043091, 0.12201199680566788, 0.040670666843652725, 0.12201199680566788, 0.12201199680566788, 0.040670666843652725, 0.06228185072541237, 0.06228185072541237, 0.06228185072541237, 0.15570463240146637, 0.24912740290164948, 0.3736911118030548, 0.06228185072541237, 0.05795666575431824, 0.08693499863147736, 0.08693499863147736, 0.08693499863147736, 0.3187616765499115, 0.3477399945259094, 0.05795666575431824, 0.08767484128475189, 0.12420602142810822, 0.306861937046051, 0.07306236773729324, 0.058449894189834595, 0.029224947094917297, 0.31416818499565125, 0.26998963952064514, 0.07713989913463593, 0.46283939480781555, 0.07713989913463593, 0.03856994956731796, 0.03856994956731796, 0.03856994956731796, 0.4986332356929779, 0.040429722517728806, 0.01347657386213541, 0.01347657386213541, 0.20214861631393433, 0.02695314772427082, 0.21562518179416656, 0.09255301207304001, 0.23138251900672913, 0.13882951438426971, 0.09255301207304001, 0.046276506036520004, 0.09255301207304001, 0.37021204829216003, 0.25740528106689453, 0.1227625235915184, 0.13464276492595673, 0.1544431746006012, 0.19404397904872894, 0.08712179213762283, 0.051481056958436966, 0.06503891199827194, 0.13007782399654388, 0.13007782399654388, 0.13007782399654388, 0.39023348689079285, 0.06503891199827194, 0.06503891199827194, 0.23903748393058777, 0.03983958065509796, 0.0995989516377449, 0.45815518498420715, 0.07967916131019592, 0.05975937098264694, 0.01991979032754898, 0.08398878574371338, 0.08398878574371338, 0.4619383215904236, 0.04199439287185669, 0.08398878574371338, 0.04199439287185669, 0.20997196435928345, 0.0627092719078064, 0.0209030918776989, 0.4180618226528168, 0.1045154556632042, 0.18812783062458038, 0.146321639418602, 0.0418061837553978, 0.09004495292901993, 0.11255618929862976, 0.40520229935646057, 0.11255618929862976, 0.11255618929862976, 0.045022476464509964, 0.09004495292901993, 0.16964983940124512, 0.13194987177848816, 0.11309988796710968, 0.05654994398355484, 0.0942499116063118, 0.03769996389746666, 0.41469958424568176, 0.1200605258345604, 0.0600302629172802, 0.09004539996385574, 0.4202118515968323, 0.09004539996385574, 0.0300151314586401, 0.15007565915584564, 0.04098183289170265, 0.05122729018330574, 0.020490916445851326, 0.4200637936592102, 0.15368187427520752, 0.14343641698360443, 0.1639273315668106, 0.1566624790430069, 0.07833123952150345, 0.07833123952150345, 0.1566624790430069, 0.07833123952150345, 0.39165619015693665, 0.07833123952150345, 0.09890194982290268, 0.14835292100906372, 0.494509756565094, 0.04945097491145134, 0.04945097491145134, 0.14835292100906372, 0.04945097491145134, 0.1775103658437729, 0.10566093772649765, 0.07184943556785583, 0.03803793713450432, 0.14369887113571167, 0.3846057951450348, 0.07607587426900864, 0.1350497454404831, 0.2047528475522995, 0.12198041379451752, 0.06099020689725876, 0.034851547330617905, 0.409505695104599, 0.034851547330617905, 0.10953477770090103, 0.16430217027664185, 0.054767388850450516, 0.10953477770090103, 0.3833717405796051, 0.16430217027664185, 0.054767388850450516, 0.13166563212871552, 0.34891390800476074, 0.15141546726226807, 0.0855826586484909, 0.15799875557422638, 0.05266625061631203, 0.06583281606435776, 0.04832523688673973, 0.18890775740146637, 0.07029125839471817, 0.08347086608409882, 0.18890775740146637, 0.04832523688673973, 0.3734222948551178, 0.5199442505836487, 0.07427775114774704, 0.14855550229549408, 0.14855550229549408, 0.1083507090806961, 0.4875781834125519, 0.27087676525115967, 0.05417535454034805, 0.1083507090806961, 0.09517272561788559, 0.23793181777000427, 0.047586362808942795, 0.47586363554000854, 0.14275908470153809, 0.047586362808942795, 0.14474819600582123, 0.25394418835639954, 0.2641019821166992, 0.06856493651866913, 0.05586772412061691, 0.09141991287469864, 0.1193537786602974, 0.1440136879682541, 0.09000854939222336, 0.1215115413069725, 0.13951325416564941, 0.1215115413069725, 0.1215115413069725, 0.2610248029232025, 0.05817079171538353, 0.1745123714208603, 0.5235371589660645, 0.05817079171538353, 0.11634158343076706, 0.05817079171538353, 0.05817079171538353, 0.30815616250038147, 0.21333888173103333, 0.08889120072126389, 0.04148256033658981, 0.1303737610578537, 0.11259552836418152, 0.10666944086551666, 0.14115743339061737, 0.047052476555109024, 0.23526237905025482, 0.047052476555109024, 0.047052476555109024, 0.09410495311021805, 0.3764198124408722, 0.1732630580663681, 0.1732630580663681, 0.08663152903318405, 0.43315765261650085, 0.08663152903318405, 0.1263842135667801, 0.19781877100467682, 0.2527684271335602, 0.1263842135667801, 0.038464758545160294, 0.19781877100467682, 0.05494965612888336, 0.11942633986473083, 0.03980877995491028, 0.03980877995491028, 0.07961755990982056, 0.1592351198196411, 0.03980877995491028, 0.47770535945892334, 0.1257047802209854, 0.28838154673576355, 0.1515851765871048, 0.10352157801389694, 0.1515851765871048, 0.06654958426952362, 0.11091598123311996, 0.15501581132411957, 0.08566663414239883, 0.18357136845588684, 0.12238090485334396, 0.17133326828479767, 0.16317453980445862, 0.11830154061317444, 0.09889640659093857, 0.1883741021156311, 0.28256115317344666, 0.12244316935539246, 0.11773381382226944, 0.11302445828914642, 0.0800589919090271, 0.1298021525144577, 0.3488432765007019, 0.12168952077627182, 0.1298021525144577, 0.08112634718418121, 0.05678844079375267, 0.1298021525144577, 0.0839582234621048, 0.1679164469242096, 0.1049477830529213, 0.0209895558655262, 0.377811998128891, 0.1469268947839737, 0.0629686713218689, 0.4705769419670105, 0.09411539137363434, 0.12548717856407166, 0.06274358928203583, 0.09411539137363434, 0.09411539137363434, 0.031371794641017914, 0.1364932656288147, 0.2423451840877533, 0.2312028855085373, 0.0835673063993454, 0.1058519184589386, 0.1114230751991272, 0.089138463139534, 0.20363235473632812, 0.06787745654582977, 0.06787745654582977, 0.13575491309165955, 0.06787745654582977, 0.33938726782798767, 0.06787745654582977, 0.15059132874011993, 0.20374120771884918, 0.09301228821277618, 0.2258870005607605, 0.14173302054405212, 0.12401638925075531, 0.05757903680205345, 0.10600369423627853, 0.1413382589817047, 0.38868018984794617, 0.1766728162765503, 0.07066912949085236, 0.07066912949085236, 0.03533456474542618, 0.10462848097085953, 0.20925696194171906, 0.03487616032361984, 0.06975232064723969, 0.06975232064723969, 0.10462848097085953, 0.38363778591156006, 0.7783061861991882, 0.04578271508216858, 0.04578271508216858, 0.04578271508216858, 0.04578271508216858, 0.02289135754108429, 0.06395560503005981, 0.0895378515124321, 0.07674672454595566, 0.03837336227297783, 0.243031308054924, 0.05116448551416397, 0.4476892352104187, 0.14334332942962646, 0.15637452900409698, 0.28668665885925293, 0.11076529324054718, 0.11728090047836304, 0.11728090047836304, 0.05864045023918152, 0.15714479982852936, 0.13590900599956512, 0.21235783398151398, 0.12316753715276718, 0.059460192918777466, 0.20386351644992828, 0.10617891699075699, 0.1546448916196823, 0.21478456258773804, 0.17612335085868835, 0.10309659689664841, 0.07732244580984116, 0.16753196716308594, 0.10309659689664841, 0.07101228088140488, 0.07101228088140488, 0.09130150079727173, 0.040578443557024, 0.5173751711845398, 0.030433833599090576, 0.18260300159454346, 0.22781126201152802, 0.13106949627399445, 0.1903628259897232, 0.07177615165710449, 0.21220774948596954, 0.11858668178319931, 0.04368983209133148, 0.43753325939178467, 0.10938331484794617, 0.021876662969589233, 0.10938331484794617, 0.1312599778175354, 0.15313664078712463, 0.04375332593917847, 0.1779428869485855, 0.17255067825317383, 0.0916675478219986, 0.13480521738529205, 0.25343382358551025, 0.12402079999446869, 0.0593142956495285, 0.1454210728406906, 0.16723424196243286, 0.1599631905555725, 0.0872526466846466, 0.10179474949836731, 0.25448688864707947, 0.0727105364203453, 0.09280525147914886, 0.2253841906785965, 0.053031571209430695, 0.24527102708816528, 0.2983025908470154, 0.06628946959972382, 0.019886840134859085, 0.06856589019298553, 0.03428294509649277, 0.17141473293304443, 0.27426356077194214, 0.03428294509649277, 0.34282946586608887, 0.03428294509649277, 0.09213800728321075, 0.09213800728321075, 0.27641400694847107, 0.368552029132843, 0.09213800728321075, 0.208684504032135, 0.12752941250801086, 0.08115508407354355, 0.09854546189308167, 0.12173262983560562, 0.06376470625400543, 0.295636385679245, 0.1576937884092331, 0.18789047002792358, 0.26505976915359497, 0.08052448183298111, 0.08723486214876175, 0.1409178525209427, 0.08387967199087143, 0.12587694823741913, 0.25987499952316284, 0.11369530856609344, 0.23957227170467377, 0.10963476449251175, 0.0730898454785347, 0.0730898454785347, 0.05390666797757149, 0.026953333988785744, 0.026953333988785744, 0.5660200119018555, 0.05390666797757149, 0.18867333233356476, 0.08086000382900238, 0.14325857162475586, 0.23279519379138947, 0.12535125017166138, 0.10296710580587387, 0.22831836342811584, 0.053721968084573746, 0.11192076653242111, 0.06893173605203629, 0.18381796777248383, 0.045954491943120956, 0.045954491943120956, 0.4825221598148346, 0.09190898388624191, 0.09190898388624191, 0.451870322227478, 0.09037405997514725, 0.1807481199502945, 0.09037405997514725, 0.09037405997514725, 0.17772690951824188, 0.1563996821641922, 0.0781998410820961, 0.06398168951272964, 0.1848359853029251, 0.29858121275901794, 0.035545382648706436, 0.14917819201946259, 0.44753459095954895, 0.09945213049650192, 0.04972606524825096, 0.04972606524825096, 0.14917819201946259, 0.04972606524825096, 0.12298049032688141, 0.05739089474081993, 0.1557752937078476, 0.07378829270601273, 0.13117918372154236, 0.040993496775627136, 0.4181336760520935, 0.041005149483680725, 0.06834191083908081, 0.09567867964506149, 0.013668382540345192, 0.36904633045196533, 0.013668382540345192, 0.38271471858024597, 0.05624571442604065, 0.09843000024557114, 0.05624571442604065, 0.028122857213020325, 0.3093514144420624, 0.014061428606510162, 0.43590426445007324, 0.07450167834758759, 0.10057727247476578, 0.14155319333076477, 0.04470100998878479, 0.29055655002593994, 0.24585555493831635, 0.10430235415697098, 0.13878658413887024, 0.09252439439296722, 0.04626219719648361, 0.09252439439296722, 0.3700975775718689, 0.18504878878593445, 0.09252439439296722, 0.09037778526544571, 0.19581854343414307, 0.10544075071811676, 0.12050371617078781, 0.07531482726335526, 0.3163222670555115, 0.09037778526544571, 0.4075300991535187, 0.13584336638450623, 0.06792168319225311, 0.13584336638450623, 0.06792168319225311, 0.13584336638450623, 0.15235823392868042, 0.12608957290649414, 0.2626866102218628, 0.0945671796798706, 0.1313433051109314, 0.1681194305419922, 0.06829851865768433, 0.14360345900058746, 0.24451400339603424, 0.19405873119831085, 0.11255406588315964, 0.065979965031147, 0.15524698793888092, 0.08538583666086197, 0.17645877599716187, 0.4411469101905823, 0.20586855709552765, 0.08822938799858093, 0.02940979413688183, 0.02940979413688183, 0.036566849797964096, 0.10970055311918259, 0.07313369959592819, 0.14626739919185638, 0.18283425271511078, 0.36566850543022156, 0.07313369959592819, 0.16751427948474884, 0.0670057088136673, 0.0670057088136673, 0.40203428268432617, 0.05025428533554077, 0.10050857067108154, 0.1340114176273346, 0.18807533383369446, 0.14105649292469025, 0.2977859377861023, 0.06269177794456482, 0.10187413543462753, 0.10971061140298843, 0.10187413543462753, 0.07530548423528671, 0.07530548423528671, 0.07530548423528671, 0.018826371058821678, 0.24474282562732697, 0.018826371058821678, 0.48948565125465393, 0.09766948223114014, 0.13022597134113312, 0.2875823676586151, 0.054260823875665665, 0.04883474111557007, 0.06511298567056656, 0.3201388716697693, 0.44418400526046753, 0.08076073229312897, 0.16152146458625793, 0.08076073229312897, 0.12114109843969345, 0.12114109843969345, 0.08634064346551895, 0.13343553245067596, 0.30611681938171387, 0.07064234465360641, 0.1255863904953003, 0.05494404584169388, 0.21192702651023865, 0.33372047543525696, 0.19355787336826324, 0.10011614114046097, 0.13348819315433502, 0.10011614114046097, 0.10679055005311966, 0.04004645720124245, 0.1247469112277031, 0.1247469112277031, 0.1247469112277031, 0.43661418557167053, 0.06237345561385155, 0.06237345561385155, 0.06237345561385155, 0.41427499055862427, 0.036553673446178436, 0.06701507419347763, 0.15230697393417358, 0.24369116127490997, 0.048738233745098114, 0.024369116872549057, 0.14001107215881348, 0.42003321647644043, 0.07000553607940674, 0.14001107215881348, 0.14001107215881348, 0.09786072373390198, 0.04893036186695099, 0.14679108560085297, 0.5871643424034119, 0.04893036186695099, 0.09786072373390198, 0.13298039138317108, 0.13727009296417236, 0.14155977964401245, 0.257381409406662, 0.1544288545846939, 0.05147628113627434, 0.1244010180234909, 0.10443275421857834, 0.09398947656154633, 0.09398947656154633, 0.25063860416412354, 0.12009766697883606, 0.10443275421857834, 0.2245304137468338, 0.33568739891052246, 0.1378716081380844, 0.14386603236198425, 0.11389394104480743, 0.06593859940767288, 0.16184929013252258, 0.03596650809049606, 0.14054539799690247, 0.14054539799690247, 0.4216361939907074, 0.07027269899845123, 0.14054539799690247, 0.07027269899845123, 0.07027269899845123, 0.20644548535346985, 0.07811450213193893, 0.2650313675403595, 0.209235280752182, 0.07532469928264618, 0.11438195407390594, 0.05300627276301384, 0.029088372364640236, 0.1018093004822731, 0.05817674472928047, 0.04363255947828293, 0.3781488239765167, 0.014544186182320118, 0.3636046350002289, 0.12498649954795837, 0.16404478251934052, 0.1952914148569107, 0.32808956503868103, 0.04686993733048439, 0.06249324977397919, 0.07030490785837173, 0.24892674386501312, 0.17978042364120483, 0.1290731281042099, 0.05531705543398857, 0.12446337193250656, 0.08297558128833771, 0.17978042364120483, 0.17347979545593262, 0.06939192116260529, 0.09541388601064682, 0.21684974431991577, 0.08673989772796631, 0.2602196931838989, 0.10408787429332733, 0.19904235005378723, 0.08293431252241135, 0.1409883350133896, 0.06634745001792908, 0.14928176999092102, 0.2653898000717163, 0.09122774749994278, 0.19838376343250275, 0.06612792611122131, 0.3967675268650055, 0.03306396305561066, 0.09919188171625137, 0.09919188171625137, 0.06612792611122131, 0.021033013239502907, 0.07361555099487305, 0.05258253589272499, 0.031549520790576935, 0.5258253216743469, 0.010516506619751453, 0.2944622039794922, 0.04348314180970192, 0.13044942915439606, 0.02174157090485096, 0.07609549909830093, 0.4457022249698639, 0.19567415118217468, 0.09783707559108734, 0.11629273742437363, 0.03876424580812454, 0.03876424580812454, 0.03876424580812454, 0.6977564096450806, 0.03876424580812454, 0.05420913174748421, 0.10841826349496841, 0.05420913174748421, 0.10841826349496841, 0.48788216710090637, 0.10841826349496841, 0.06292758882045746, 0.14873793721199036, 0.2688724100589752, 0.14873793721199036, 0.1430172473192215, 0.10869310796260834, 0.12013448774814606, 0.08985038846731186, 0.03993350639939308, 0.07986701279878616, 0.4093184471130371, 0.05990025773644447, 0.04991688206791878, 0.269551157951355, 0.03537113219499588, 0.10611339658498764, 0.1768556535243988, 0.42445358633995056, 0.03537113219499588, 0.10611339658498764, 0.07074226438999176, 0.06120780110359192, 0.17546236515045166, 0.1713818460702896, 0.13873767852783203, 0.22442860901355743, 0.18362340331077576, 0.053046759217977524, 0.09595359861850739, 0.09595359861850739, 0.09595359861850739, 0.47976797819137573, 0.09595359861850739, 0.09595359861850739, 0.0751471295952797, 0.08588243275880814, 0.16102956235408783, 0.4830887019634247, 0.06441182643175125, 0.08588243275880814, 0.05367652326822281, 0.03962012007832527, 0.03962012007832527, 0.11886035650968552, 0.5943017601966858, 0.11886035650968552, 0.03962012007832527, 0.03962012007832527, 0.11445704102516174, 0.17740841209888458, 0.2975882887840271, 0.051505666226148605, 0.10873418301343918, 0.10873418301343918, 0.13162559270858765, 0.11867792904376984, 0.07120675593614578, 0.047471173107624054, 0.5221828818321228, 0.1661490947008133, 0.047471173107624054, 0.023735586553812027, 0.06374039500951767, 0.06374039500951767, 0.6692741513252258, 0.031870197504758835, 0.06374039500951767, 0.0956105962395668, 0.18140153586864471, 0.13605114817619324, 0.09070076793432236, 0.04535038396716118, 0.04535038396716118, 0.4535038471221924, 0.04260661080479622, 0.06390991061925888, 0.02130330540239811, 0.7456156611442566, 0.06390991061925888, 0.02130330540239811, 0.04260661080479622, 0.065655916929245, 0.08754122257232666, 0.11307407915592194, 0.1386069357395172, 0.0693034678697586, 0.062008365988731384, 0.4668865203857422, 0.030316438525915146, 0.09094931185245514, 0.09094931185245514, 0.12126575410366058, 0.12126575410366058, 0.4547465741634369, 0.09094931185245514, 0.02689453959465027, 0.06723634898662567, 0.05378907918930054, 0.02689453959465027, 0.4303126335144043, 0.013447269797325134, 0.3899708092212677, 0.09746373444795609, 0.14994420111179352, 0.32987725734710693, 0.08246931433677673, 0.20242467522621155, 0.044983260333538055, 0.08246931433677673, 0.10988552123308182, 0.3662850856781006, 0.1281997710466385, 0.08241414278745651, 0.10988552123308182, 0.09157127141952515, 0.10072839260101318, 0.22970466315746307, 0.09571027755737305, 0.30148738622665405, 0.11963784694671631, 0.09092476218938828, 0.12442336231470108, 0.03828411176800728, 0.16339664161205292, 0.1028793603181839, 0.12103454768657684, 0.29048290848731995, 0.17550009489059448, 0.1028793603181839, 0.04841381683945656, 0.12566468119621277, 0.14137277007102966, 0.12566468119621277, 0.2565653920173645, 0.1675529032945633, 0.10995659232139587, 0.07330439984798431, 0.08418410271406174, 0.1739804744720459, 0.13469456136226654, 0.17959275841712952, 0.09540864825248718, 0.21326640248298645, 0.11785774677991867, 0.1286902278661728, 0.176102414727211, 0.09482438117265701, 0.3183389902114868, 0.09482438117265701, 0.12191706150770187, 0.06773170083761215, 0.23615829646587372, 0.07514128088951111, 0.12881362438201904, 0.07514128088951111, 0.11807914823293686, 0.04293787106871605, 0.3327684998512268, 0.04599650949239731, 0.09199301898479462, 0.5059615969657898, 0.09199301898479462, 0.13798953592777252, 0.13798953592777252, 0.22630731761455536, 0.13335967063903809, 0.13740086555480957, 0.11315365880727768, 0.24651332199573517, 0.0646592304110527, 0.07678283751010895, 0.10491188615560532, 0.11365454643964767, 0.20982377231121063, 0.10491188615560532, 0.12239720672369003, 0.25353705883026123, 0.07868391275405884, 0.10245490819215775, 0.37139904499053955, 0.14087550342082977, 0.2049098163843155, 0.07684118300676346, 0.06403432041406631, 0.03842059150338173, 0.08136540651321411, 0.4475097358226776, 0.20341351628303528, 0.08136540651321411, 0.040682703256607056, 0.08136540651321411, 0.08136540651321411, 0.03847053647041321, 0.03847053647041321, 0.5001169443130493, 0.11541160941123962, 0.07694107294082642, 0.19235268235206604, 0.03847053647041321, 0.14922568202018738, 0.07461284101009369, 0.44767701625823975, 0.22383850812911987, 0.07461284101009369, 0.07540011405944824, 0.07540011405944824, 0.03770005702972412, 0.7163010835647583, 0.05655008181929588, 0.01885002851486206, 0.01885002851486206, 0.09752751141786575, 0.1645776778459549, 0.2194368988275528, 0.07314563542604446, 0.07924110442399979, 0.2803916037082672, 0.08533657342195511, 0.03616173565387726, 0.14464694261550903, 0.1808086782693863, 0.10848520696163177, 0.39777910709381104, 0.07232347130775452, 0.03616173565387726, 0.23429454863071442, 0.09371781349182129, 0.2447076290845871, 0.09371781349182129, 0.11975054442882538, 0.1353701800107956, 0.07289163768291473, 0.07392999529838562, 0.14785999059677124, 0.07392999529838562, 0.07392999529838562, 0.517509937286377, 0.22178998589515686, 0.22510015964508057, 0.1500667780637741, 0.12242289632558823, 0.09082988649606705, 0.08688076585531235, 0.09477901458740234, 0.22510015964508057, 0.10339894145727158, 0.24520321190357208, 0.18020959198474884, 0.09158192574977875, 0.11226171255111694, 0.12998723983764648, 0.1358957588672638, 0.0716969221830368, 0.1254696249961853, 0.2688634693622589, 0.0716969221830368, 0.3226361572742462, 0.1433938443660736, 0.09493470937013626, 0.04746735468506813, 0.04746735468506813, 0.23733676970005035, 0.09493470937013626, 0.3322714865207672, 0.18986941874027252, 0.05707385763525963, 0.4316210448741913, 0.18549004197120667, 0.07134232670068741, 0.04993962496519089, 0.0856107845902443, 0.11771483719348907, 0.06145428866147995, 0.18436287343502045, 0.1229085773229599, 0.1229085773229599, 0.43018004298210144, 0.06145428866147995, 0.20156458020210266, 0.3191439211368561, 0.120938740670681, 0.08734464645385742, 0.10414169728755951, 0.053750552237033844, 0.11421992629766464, 0.06689824163913727, 0.11707192659378052, 0.15470218658447266, 0.10452850908041, 0.25086840987205505, 0.1881513148546219, 0.12125306576490402, 0.3688551187515259, 0.10487057268619537, 0.10487057268619537, 0.13741661608219147, 0.10848680138587952, 0.10487057268619537, 0.07232452929019928, 0.21094593405723572, 0.08686009049415588, 0.11167725920677185, 0.2978060245513916, 0.17372018098831177, 0.049634337425231934, 0.06824721395969391, 0.08085030317306519, 0.13382118940353394, 0.19515590369701385, 0.12545736134052277, 0.3178253173828125, 0.06691059470176697, 0.07806236296892166, 0.04255933687090874, 0.09930511564016342, 0.05674578249454498, 0.24116957187652588, 0.3972204625606537, 0.14186444878578186, 0.04255933687090874, 0.3084926903247833, 0.08200438320636749, 0.12105409055948257, 0.1249590665102005, 0.07809941470623016, 0.07809941470623016, 0.21477338671684265, 0.06098073348402977, 0.46751895546913147, 0.16261528432369232, 0.06098073348402977, 0.10163455456495285, 0.04065382108092308, 0.12196146696805954, 0.3923831880092621, 0.1921042650938034, 0.15123102068901062, 0.034742262214422226, 0.08174649626016617, 0.07561551034450531, 0.07357184588909149, 0.14564193785190582, 0.174770325422287, 0.17060913145542145, 0.13731953501701355, 0.066579170525074, 0.19141511619091034, 0.10819115489721298, 0.49933212995529175, 0.042799897491931915, 0.014266632497310638, 0.014266632497310638, 0.21399948000907898, 0.014266632497310638, 0.21399948000907898, 0.06255439668893814, 0.12510879337787628, 0.12510879337787628, 0.4378807842731476, 0.12510879337787628, 0.06255439668893814, 0.06255439668893814, 0.1461666077375412, 0.346468985080719, 0.22195670008659363, 0.048722200095653534, 0.043308623135089874, 0.13533945381641388, 0.05954935774207115, 0.15211452543735504, 0.5070484280586243, 0.05070484057068825, 0.1014096811413765, 0.1014096811413765, 0.1014096811413765, 0.2928871214389801, 0.054071467369794846, 0.04055359959602356, 0.2883811593055725, 0.05857742205262184, 0.09011910855770111, 0.17573226988315582, 0.13556501269340515, 0.1161985844373703, 0.23723876476287842, 0.07746572047472, 0.17913947999477386, 0.150089830160141, 0.10651536285877228, 0.2876719832420349, 0.18673445284366608, 0.11607817560434341, 0.05551564693450928, 0.1968282014131546, 0.08075003325939178, 0.08075003325939178, 0.22953514754772186, 0.22953514754772186, 0.15608389675617218, 0.05049773305654526, 0.0826326534152031, 0.07345125079154968, 0.1744467169046402, 0.05422268062829971, 0.05422268062829971, 0.10844536125659943, 0.01807422749698162, 0.27111339569091797, 0.03614845499396324, 0.46992990374565125, 0.49077108502388, 0.049077108502388, 0.012269277125597, 0.024538554251194, 0.196308434009552, 0.012269277125597, 0.2085777074098587, 0.10938726365566254, 0.10938726365566254, 0.05469363182783127, 0.43754905462265015, 0.1640808880329132, 0.10938726365566254, 0.4564741849899292, 0.10143870860338211, 0.050719354301691055, 0.10143870860338211, 0.15215806663036346, 0.15215806663036346, 0.13412435352802277, 0.0766424909234047, 0.38321244716644287, 0.0766424909234047, 0.1532849818468094, 0.0766424909234047, 0.11496373265981674, 0.11842808127403259, 0.08726279437541962, 0.10596197098493576, 0.18075865507125854, 0.14336031675338745, 0.21192394196987152, 0.1558264195919037, 0.04763631522655487, 0.11115140467882156, 0.15878772735595703, 0.09527263045310974, 0.1270301789045334, 0.36521175503730774, 0.07939386367797852, 0.1273091733455658, 0.0254618339240551, 0.3819275200366974, 0.0509236678481102, 0.1018473356962204, 0.2036946713924408, 0.1273091733455658, 0.07772673666477203, 0.1468171626329422, 0.24181650578975677, 0.15545347332954407, 0.04318151995539665, 0.25045281648635864, 0.0863630399107933, 0.07149951905012131, 0.5004966259002686, 0.07149951905012131, 0.14299903810024261, 0.07149951905012131, 0.14299903810024261, 0.07149951905012131, 0.20641423761844635, 0.11467457562685013, 0.06880474835634232, 0.09173966199159622, 0.09173966199159622, 0.344023734331131, 0.09173966199159622, 0.060210563242435455, 0.060210563242435455, 0.48168450593948364, 0.24084225296974182, 0.12042112648487091, 0.060210563242435455, 0.5367130637168884, 0.17890433967113495, 0.08945216983556747, 0.08945216983556747, 0.08945216983556747, 0.17890433967113495, 0.14612683653831482, 0.07654263079166412, 0.13221000134944916, 0.18091893196105957, 0.1182931512594223, 0.2574615776538849, 0.09741789102554321, 0.08023004233837128, 0.14356954395771027, 0.1520148068666458, 0.3251428008079529, 0.0928979367017746, 0.0760074034333229, 0.13512428104877472, 0.20840369164943695, 0.27787157893180847, 0.10916384309530258, 0.07939188182353973, 0.10916384309530258, 0.15878376364707947, 0.0595439113676548, 0.08060852438211441, 0.09852152317762375, 0.12539103627204895, 0.026869507506489754, 0.3851296007633209, 0.1701735407114029, 0.10747803002595901, 0.0586419440805912, 0.1759258359670639, 0.4691355526447296, 0.0586419440805912, 0.1172838881611824, 0.0586419440805912, 0.1172838881611824, 0.04593053087592125, 0.04593053087592125, 0.0918610617518425, 0.13779158890247345, 0.04593053087592125, 0.5970969200134277, 0.04593053087592125, 0.12961290776729584, 0.04320430010557175, 0.0864086002111435, 0.010801075026392937, 0.43204301595687866, 0.021602150052785873, 0.28082796931266785, 0.1368752270936966, 0.07984387874603271, 0.25093790888786316, 0.03421880677342415, 0.045625075697898865, 0.03421880677342415, 0.4220319390296936, 0.40094849467277527, 0.19400733709335327, 0.09053675830364227, 0.07760293036699295, 0.06466910988092422, 0.103470578789711, 0.09053675830364227, 0.3652072250843048, 0.08764973282814026, 0.13877874612808228, 0.04382486641407013, 0.10956217348575592, 0.14608289301395416, 0.10225802659988403, 0.21364982426166534, 0.01780415140092373, 0.03560830280184746, 0.01780415140092373, 0.0890207588672638, 0.0890207588672638, 0.5341245532035828, 0.10730046778917313, 0.09197182953357697, 0.1532863825559616, 0.36788731813430786, 0.1532863825559616, 0.09197182953357697, 0.030657276511192322, 0.50471431016922, 0.028039684519171715, 0.014019842259585857, 0.014019842259585857, 0.19627779722213745, 0.014019842259585857, 0.22431747615337372, 0.06392614543437958, 0.06392614543437958, 0.06392614543437958, 0.06392614543437958, 0.3196307122707367, 0.3196307122707367, 0.06392614543437958, 0.08052060753107071, 0.6441648602485657, 0.032208241522312164, 0.12883296608924866, 0.032208241522312164, 0.016104120761156082, 0.06441648304462433, 0.09518790245056152, 0.47593948245048523, 0.14278185367584229, 0.09518790245056152, 0.04759395122528076, 0.14278185367584229, 0.04759395122528076, 0.10525805503129959, 0.18712542951107025, 0.16373476386070251, 0.08186738193035126, 0.3040788471698761, 0.052629027515649796, 0.10525805503129959, 0.2058093547821045, 0.1225055679678917, 0.06860312074422836, 0.2989135980606079, 0.17640802264213562, 0.08820401132106781, 0.044102005660533905, 0.09226780384778976, 0.061511870473623276, 0.07688983529806137, 0.04613390192389488, 0.2460474818944931, 0.030755935236811638, 0.445961058139801, 0.1489967405796051, 0.07449837028980255, 0.37249183654785156, 0.07449837028980255, 0.1489967405796051, 0.1489967405796051, 0.14841587841510773, 0.18551984429359436, 0.1813971847295761, 0.10718924552202225, 0.11543457210063934, 0.06596261262893677, 0.20201049745082855, 0.09323413670063019, 0.41955360770225525, 0.09323413670063019, 0.09323413670063019, 0.09323413670063019, 0.09323413670063019, 0.09323413670063019, 0.24106143414974213, 0.29815492033958435, 0.06978093832731247, 0.10784327238798141, 0.04440605267882347, 0.17762421071529388, 0.06343721598386765, 0.06225750595331192, 0.09338625520467758, 0.1011684462428093, 0.19455470144748688, 0.32685190439224243, 0.11673282086849213, 0.10895062983036041, 0.0934111624956131, 0.2802335023880005, 0.1868223249912262, 0.0934111624956131, 0.3736446499824524, 0.0934111624956131, 0.054509684443473816, 0.16352905333042145, 0.16352905333042145, 0.10901936888694763, 0.10901936888694763, 0.3270581066608429, 0.054509684443473816, 0.2220602184534073, 0.3400297164916992, 0.13184824585914612, 0.09021196514368057, 0.06245443597435951, 0.0693938210606575, 0.08327258378267288, 0.02082558535039425, 0.0728895515203476, 0.0520639643073082, 0.031238378956913948, 0.4789884686470032, 0.0416511707007885, 0.3227965831756592, 0.09777085483074188, 0.07332814484834671, 0.4888542890548706, 0.04888542741537094, 0.12221357226371765, 0.09777085483074188, 0.07332814484834671, 0.046082042157649994, 0.5069024562835693, 0.13824611902236938, 0.09216408431529999, 0.046082042157649994, 0.09216408431529999, 0.09216408431529999, 0.4341296851634979, 0.059879954904317856, 0.10478992015123367, 0.20957984030246735, 0.029939977452158928, 0.08981993794441223, 0.07484994828701019, 0.34700268507003784, 0.11420341581106186, 0.263546347618103, 0.14055804908275604, 0.039531953632831573, 0.03513951227068901, 0.06149414926767349, 0.07714784890413284, 0.5400349497795105, 0.05786088854074478, 0.13500873744487762, 0.0964348167181015, 0.01928696222603321, 0.05786088854074478, 0.5109139084815979, 0.14459827542304993, 0.03855953738093376, 0.05783930793404579, 0.08675896376371384, 0.1349583864212036, 0.01927976869046688, 0.20985528826713562, 0.2338387370109558, 0.16488629579544067, 0.10192970931529999, 0.10492764413356781, 0.10492764413356781, 0.0779462456703186, 0.27396103739738464, 0.09529079496860504, 0.15484754741191864, 0.08337944746017456, 0.14293619990348816, 0.13102485239505768, 0.12308394908905029, 0.03818407654762268, 0.07636815309524536, 0.09164178371429443, 0.04582089185714722, 0.2520149052143097, 0.06109451875090599, 0.43529844284057617, 0.09959939122200012, 0.19919878244400024, 0.07469954341650009, 0.09959939122200012, 0.12449923902750015, 0.3236980140209198, 0.07469954341650009, 0.21468497812747955, 0.11667661368846893, 0.2846909463405609, 0.13067780435085297, 0.12134367972612381, 0.07934010028839111, 0.05600477755069733, 0.5107555389404297, 0.09965962171554565, 0.14948943257331848, 0.14948943257331848, 0.03737235814332962, 0.024914905428886414, 0.012457452714443207, 0.07810851186513901, 0.11065372079610825, 0.03254521265625954, 0.21479839086532593, 0.33196115493774414, 0.04556329548358917, 0.19527126848697662, 0.0884058028459549, 0.1768116056919098, 0.0884058028459549, 0.04420290142297745, 0.530434787273407, 0.04420290142297745, 0.04420290142297745, 0.18482090532779694, 0.08214262127876282, 0.04107131063938141, 0.14374959468841553, 0.30803483724594116, 0.15744002163410187, 0.07529740780591965, 0.2501737177371979, 0.10721730440855026, 0.09530427306890488, 0.10721730440855026, 0.0833912342786789, 0.28591281175613403, 0.059565167874097824, 0.22803308069705963, 0.18332071602344513, 0.20567689836025238, 0.07153978943824768, 0.12295901030302048, 0.08048225939273834, 0.10730968415737152, 0.052859142422676086, 0.15857742726802826, 0.052859142422676086, 0.19822178781032562, 0.09250349551439285, 0.2907252907752991, 0.14536264538764954, 0.29276174306869507, 0.07121231406927109, 0.09494975209236145, 0.03164991736412048, 0.08703727275133133, 0.25319933891296387, 0.15824958682060242, 0.30602777004241943, 0.05100462958216667, 0.05100462958216667, 0.05100462958216667, 0.15301388502120972, 0.4080370366573334, 0.10567360371351242, 0.15851040184497833, 0.05283680185675621, 0.05283680185675621, 0.5812048316001892, 0.05283680185675621, 0.45957860350608826, 0.20425716042518616, 0.15319287776947021, 0.05106429010629654, 0.10212858021259308, 0.05106429010629654, 0.05106429010629654, 0.27646610140800476, 0.13069306313991547, 0.1910129338502884, 0.08545315265655518, 0.13069306313991547, 0.12063974887132645, 0.06534653156995773, 0.020802054554224014, 0.5616554617881775, 0.12481232732534409, 0.10401027649641037, 0.08320821821689606, 0.06240616366267204, 0.020802054554224014, 0.14881490170955658, 0.07440745085477829, 0.44644472002983093, 0.07440745085477829, 0.22322236001491547, 0.07779291272163391, 0.07779291272163391, 0.07779291272163391, 0.38896456360816956, 0.07779291272163391, 0.15558582544326782], \"Term\": [\"absolute\", \"absolute\", \"absolute\", \"absolute\", \"absolute\", \"absolute\", \"absolute\", \"adb\", \"adb\", \"adb\", \"adb\", \"adb\", \"adb\", \"adb\", \"administrative\", \"administrative\", \"administrative\", \"administrative\", \"administrative\", \"administrative\", \"africa\", \"africa\", \"africa\", \"africa\", \"africa\", \"africa\", \"africa\", \"aid\", \"aid\", \"aid\", \"aid\", \"aid\", \"aid\", \"aid\", \"aka\", \"aka\", \"aka\", \"aka\", \"aka\", \"aka\", \"aka\", \"al\", \"al\", \"al\", \"al\", \"al\", \"al\", \"al\", \"alexander\", \"alexander\", \"alexander\", \"alexander\", \"alexander\", \"alexander\", \"allergic\", \"allergic\", \"allergic\", \"allergic\", \"allergic\", \"allergic\", \"allergic\", \"alomar\", \"alomar\", \"alomar\", \"alomar\", \"alomar\", \"alomar\", \"alomar\", \"amateur\", \"amateur\", \"amateur\", \"amateur\", \"amateur\", \"amateur\", \"amateur\", \"amiga\", \"amiga\", \"amiga\", \"amiga\", \"amiga\", \"amiga\", \"amiga\", \"anderson\", \"anderson\", \"anderson\", \"anderson\", \"anderson\", \"anderson\", \"anderson\", \"antenna\", \"antenna\", \"antenna\", \"antenna\", \"antenna\", \"antenna\", \"april\", \"april\", \"april\", \"april\", \"april\", \"april\", \"april\", \"argv\", \"argv\", \"argv\", \"argv\", \"argv\", \"argv\", \"argv\", \"arrogant\", \"arrogant\", \"arrogant\", \"arrogant\", \"arrogant\", \"arrogant\", \"asynchronous\", \"asynchronous\", \"asynchronous\", \"asynchronous\", \"asynchronous\", \"asynchronous\", \"asynchronous\", \"average\", \"average\", \"average\", \"average\", \"average\", \"average\", \"average\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"b\", \"baerga\", \"baerga\", \"baerga\", \"baerga\", \"bag\", \"bag\", \"bag\", \"bag\", \"bag\", \"bag\", \"baltimore\", \"baltimore\", \"baltimore\", \"baltimore\", \"baltimore\", \"baltimore\", \"baltimore\", \"bank\", \"bank\", \"bank\", \"bank\", \"bank\", \"bank\", \"bank\", \"belief\", \"belief\", \"belief\", \"belief\", \"belief\", \"belief\", \"belief\", \"bible\", \"bible\", \"bible\", \"bible\", \"bible\", \"bible\", \"bible\", \"black\", \"black\", \"black\", \"black\", \"black\", \"black\", \"black\", \"boggs\", \"boggs\", \"boggs\", \"boggs\", \"boggs\", \"boggs\", \"boggs\", \"bolt\", \"bolt\", \"bolt\", \"bolt\", \"bolt\", \"bomb\", \"bomb\", \"bomb\", \"bomb\", \"bomb\", \"bomb\", \"boost\", \"boost\", \"boost\", \"boost\", \"boost\", \"boost\", \"boost\", \"bos\", \"bos\", \"bos\", \"bos\", \"bos\", \"bos\", \"bos\", \"box\", \"box\", \"box\", \"box\", \"box\", \"box\", \"box\", \"buf\", \"buf\", \"buf\", \"buf\", \"buf\", \"buf\", \"buf\", \"burst\", \"burst\", \"burst\", \"burst\", \"burst\", \"burst\", \"burst\", \"bus\", \"bus\", \"bus\", \"bus\", \"bus\", \"bus\", \"bus\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"cache\", \"cache\", \"cache\", \"cache\", \"cache\", \"cache\", \"cache\", \"cal\", \"cal\", \"cal\", \"cal\", \"cal\", \"cal\", \"cal\", \"cancer\", \"cancer\", \"cancer\", \"cancer\", \"cancer\", \"cancer\", \"cancer\", \"cape\", \"cape\", \"cape\", \"cape\", \"cape\", \"cape\", \"cape\", \"cat\", \"cat\", \"cat\", \"cat\", \"cat\", \"cat\", \"cat\", \"center\", \"center\", \"center\", \"center\", \"center\", \"center\", \"center\", \"chamber\", \"chamber\", \"chamber\", \"chamber\", \"chamber\", \"chamber\", \"chamber\", \"char\", \"char\", \"char\", \"char\", \"char\", \"char\", \"char\", \"charter\", \"charter\", \"charter\", \"charter\", \"charter\", \"charter\", \"charter\", \"chastity\", \"chastity\", \"chastity\", \"chastity\", \"chastity\", \"chastity\", \"chastity\", \"chi\", \"chi\", \"chi\", \"chi\", \"chi\", \"chi\", \"chi\", \"chicago\", \"chicago\", \"chicago\", \"chicago\", \"chicago\", \"chicago\", \"chicago\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"chip\", \"chip\", \"chip\", \"chip\", \"chip\", \"chip\", \"chip\", \"chipset\", \"chipset\", \"chipset\", \"chipset\", \"chipset\", \"chipset\", \"church\", \"church\", \"church\", \"church\", \"church\", \"church\", \"church\", \"city\", \"city\", \"city\", \"city\", \"city\", \"city\", \"city\", \"clear\", \"clear\", \"clear\", \"clear\", \"clear\", \"clear\", \"clear\", \"clemen\", \"clemen\", \"clemen\", \"clemen\", \"clemen\", \"clemen\", \"clemen\", \"clement\", \"clement\", \"clement\", \"clement\", \"clement\", \"clement\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"cold\", \"cold\", \"cold\", \"cold\", \"cold\", \"cold\", \"cold\", \"colour\", \"colour\", \"colour\", \"colour\", \"colour\", \"colour\", \"colour\", \"command\", \"command\", \"command\", \"command\", \"command\", \"command\", \"command\", \"commercial\", \"commercial\", \"commercial\", \"commercial\", \"commercial\", \"commercial\", \"commercial\", \"communion\", \"communion\", \"communion\", \"communion\", \"communion\", \"communion\", \"communion\", \"contact\", \"contact\", \"contact\", \"contact\", \"contact\", \"contact\", \"contact\", \"contend\", \"contend\", \"contend\", \"contend\", \"contend\", \"contend\", \"contest\", \"contest\", \"contest\", \"contest\", \"contest\", \"contest\", \"contest\", \"contradiction\", \"contradiction\", \"contradiction\", \"contradiction\", \"contradiction\", \"contradiction\", \"contradiction\", \"contrib\", \"contrib\", \"contrib\", \"contrib\", \"contrib\", \"contrib\", \"contrib\", \"contribution\", \"contribution\", \"contribution\", \"contribution\", \"contribution\", \"contribution\", \"contribution\", \"controller\", \"controller\", \"controller\", \"controller\", \"controller\", \"controller\", \"controller\", \"coprocessor\", \"coprocessor\", \"coprocessor\", \"coprocessor\", \"copy\", \"copy\", \"copy\", \"copy\", \"copy\", \"copy\", \"copy\", \"corn\", \"corn\", \"corn\", \"corn\", \"corn\", \"corn\", \"corn\", \"council\", \"council\", \"council\", \"council\", \"council\", \"council\", \"council\", \"ctrl\", \"ctrl\", \"ctrl\", \"ctrl\", \"ctrl\", \"ctrl\", \"ctrl\", \"cub\", \"cub\", \"cub\", \"cub\", \"cub\", \"cub\", \"cub\", \"cure\", \"cure\", \"cure\", \"cure\", \"cure\", \"cure\", \"cure\", \"cursor\", \"cursor\", \"cursor\", \"cursor\", \"cursor\", \"cursor\", \"cursor\", \"cy\", \"cy\", \"cy\", \"cy\", \"cy\", \"cy\", \"d\", \"d\", \"d\", \"d\", \"d\", \"d\", \"d\", \"date\", \"date\", \"date\", \"date\", \"date\", \"date\", \"date\", \"dd\", \"dd\", \"dd\", \"dd\", \"dd\", \"dd\", \"dd\", \"de\", \"de\", \"de\", \"de\", \"de\", \"de\", \"de\", \"descend\", \"descend\", \"descend\", \"descend\", \"descend\", \"det\", \"det\", \"det\", \"det\", \"det\", \"det\", \"det\", \"devote\", \"devote\", \"devote\", \"devote\", \"devote\", \"devote\", \"diagnose\", \"diagnose\", \"diagnose\", \"diagnose\", \"diagnose\", \"diagnose\", \"diagnose\", \"dialog\", \"dialog\", \"dialog\", \"dialog\", \"dialog\", \"dialog\", \"dialog\", \"die\", \"die\", \"die\", \"die\", \"die\", \"die\", \"die\", \"dimension\", \"dimension\", \"dimension\", \"dimension\", \"dimension\", \"dimension\", \"dimension\", \"disease\", \"disease\", \"disease\", \"disease\", \"disease\", \"disease\", \"disease\", \"division\", \"division\", \"division\", \"division\", \"division\", \"division\", \"division\", \"divorce\", \"divorce\", \"divorce\", \"divorce\", \"divorce\", \"divorce\", \"divorce\", \"dma\", \"dma\", \"dma\", \"dma\", \"dma\", \"dma\", \"dma\", \"doctor\", \"doctor\", \"doctor\", \"doctor\", \"doctor\", \"doctor\", \"doctor\", \"doctrine\", \"doctrine\", \"doctrine\", \"doctrine\", \"doctrine\", \"doctrine\", \"doctrine\", \"doubt\", \"doubt\", \"doubt\", \"doubt\", \"doubt\", \"doubt\", \"doubt\", \"doug\", \"doug\", \"doug\", \"doug\", \"doug\", \"doug\", \"doug\", \"driver\", \"driver\", \"driver\", \"driver\", \"driver\", \"driver\", \"driver\", \"earth\", \"earth\", \"earth\", \"earth\", \"earth\", \"earth\", \"earth\", \"easter\", \"easter\", \"easter\", \"easter\", \"easter\", \"easter\", \"easter\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"edm\", \"edm\", \"edm\", \"edm\", \"edm\", \"edm\", \"edm\", \"entry\", \"entry\", \"entry\", \"entry\", \"entry\", \"entry\", \"entry\", \"era\", \"era\", \"era\", \"era\", \"era\", \"era\", \"era\", \"eric\", \"eric\", \"eric\", \"eric\", \"eric\", \"eric\", \"eric\", \"espn\", \"espn\", \"espn\", \"espn\", \"espn\", \"espn\", \"espn\", \"eve\", \"eve\", \"eve\", \"eve\", \"eve\", \"eve\", \"eve\", \"event\", \"event\", \"event\", \"event\", \"event\", \"event\", \"event\", \"evidence\", \"evidence\", \"evidence\", \"evidence\", \"evidence\", \"evidence\", \"evidence\", \"faith\", \"faith\", \"faith\", \"faith\", \"faith\", \"faith\", \"faith\", \"family\", \"family\", \"family\", \"family\", \"family\", \"family\", \"family\", \"fast\", \"fast\", \"fast\", \"fast\", \"fast\", \"fast\", \"fast\", \"father\", \"father\", \"father\", \"father\", \"father\", \"father\", \"father\", \"fever\", \"fever\", \"fever\", \"fever\", \"fever\", \"fever\", \"fever\", \"field\", \"field\", \"field\", \"field\", \"field\", \"field\", \"field\", \"fielder\", \"fielder\", \"fielder\", \"fielder\", \"fielder\", \"fielder\", \"fielder\", \"filename\", \"filename\", \"filename\", \"filename\", \"filename\", \"filename\", \"filename\", \"final\", \"final\", \"final\", \"final\", \"final\", \"final\", \"final\", \"fix\", \"fix\", \"fix\", \"fix\", \"fix\", \"fix\", \"fix\", \"flame\", \"flame\", \"flame\", \"flame\", \"flame\", \"flame\", \"flame\", \"floppy\", \"floppy\", \"floppy\", \"floppy\", \"floppy\", \"floppy\", \"floppy\", \"flyer\", \"flyer\", \"flyer\", \"flyer\", \"flyer\", \"flyer\", \"flyer\", \"font\", \"font\", \"font\", \"font\", \"font\", \"font\", \"font\", \"food\", \"food\", \"food\", \"food\", \"food\", \"food\", \"food\", \"foolish\", \"foolish\", \"foolish\", \"foolish\", \"foolish\", \"foolish\", \"foolish\", \"format\", \"format\", \"format\", \"format\", \"format\", \"format\", \"format\", \"france\", \"france\", \"france\", \"france\", \"france\", \"france\", \"france\", \"friend\", \"friend\", \"friend\", \"friend\", \"friend\", \"friend\", \"friend\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"gain\", \"gain\", \"gain\", \"gain\", \"gain\", \"gain\", \"gain\", \"gainey\", \"gainey\", \"gainey\", \"gainey\", \"gainey\", \"gainey\", \"gainey\", \"galileo\", \"galileo\", \"galileo\", \"galileo\", \"galileo\", \"galileo\", \"galileo\", \"gas\", \"gas\", \"gas\", \"gas\", \"gas\", \"gas\", \"gas\", \"gc\", \"gc\", \"gc\", \"gc\", \"gc\", \"gc\", \"gc\", \"gilmour\", \"gilmour\", \"gilmour\", \"gilmour\", \"gilmour\", \"gilmour\", \"gilmour\", \"glory\", \"glory\", \"glory\", \"glory\", \"glory\", \"glory\", \"glory\", \"gm\", \"gm\", \"gm\", \"gm\", \"gm\", \"gm\", \"gm\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goddess\", \"goddess\", \"goddess\", \"goddess\", \"goddess\", \"goddess\", \"goddess\", \"gold\", \"gold\", \"gold\", \"gold\", \"gold\", \"gold\", \"gold\", \"gordon\", \"gordon\", \"gordon\", \"gordon\", \"gordon\", \"gordon\", \"gordon\", \"gp\", \"gp\", \"gp\", \"gp\", \"gp\", \"gp\", \"gp\", \"grasp\", \"grasp\", \"grasp\", \"grasp\", \"grasp\", \"grasp\", \"grey\", \"grey\", \"grey\", \"grey\", \"grey\", \"grey\", \"guideline\", \"guideline\", \"guideline\", \"guideline\", \"guideline\", \"guideline\", \"guideline\", \"gun\", \"gun\", \"gun\", \"gun\", \"gun\", \"gun\", \"gun\", \"gxxor\", \"gxxor\", \"gxxor\", \"gxxor\", \"gxxor\", \"gxxor\", \"gxxor\", \"hardware\", \"hardware\", \"hardware\", \"hardware\", \"hardware\", \"hardware\", \"hardware\", \"headache\", \"headache\", \"headache\", \"headache\", \"headache\", \"headache\", \"headache\", \"health\", \"health\", \"health\", \"health\", \"health\", \"health\", \"health\", \"hell\", \"hell\", \"hell\", \"hell\", \"hell\", \"hell\", \"hell\", \"hewlett\", \"hewlett\", \"hewlett\", \"hewlett\", \"hewlett\", \"hewlett\", \"hewlett\", \"hextall\", \"hextall\", \"hextall\", \"hextall\", \"hextall\", \"hextall\", \"hot\", \"hot\", \"hot\", \"hot\", \"hot\", \"hot\", \"hot\", \"hp\", \"hp\", \"hp\", \"hp\", \"hp\", \"hp\", \"hp\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"hypothesis\", \"hypothesis\", \"hypothesis\", \"hypothesis\", \"hypothesis\", \"hypothesis\", \"hypothesis\", \"hz\", \"hz\", \"hz\", \"hz\", \"hz\", \"hz\", \"ice\", \"ice\", \"ice\", \"ice\", \"ice\", \"ice\", \"ice\", \"ide\", \"ide\", \"ide\", \"ide\", \"ide\", \"ide\", \"ide\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"imake\", \"imake\", \"imake\", \"imake\", \"imake\", \"imake\", \"imake\", \"init\", \"init\", \"init\", \"init\", \"init\", \"init\", \"init\", \"inning\", \"inning\", \"inning\", \"inning\", \"inning\", \"inning\", \"inning\", \"innings\", \"innings\", \"innings\", \"innings\", \"innings\", \"innings\", \"innings\", \"int\", \"int\", \"int\", \"int\", \"int\", \"int\", \"int\", \"integration\", \"integration\", \"integration\", \"integration\", \"integration\", \"integration\", \"integration\", \"intellect\", \"intellect\", \"intellect\", \"intellect\", \"intellect\", \"intellect\", \"intellect\", \"intensive\", \"intensive\", \"intensive\", \"intensive\", \"intensive\", \"intensive\", \"intensive\", \"interface\", \"interface\", \"interface\", \"interface\", \"interface\", \"interface\", \"interface\", \"intestine\", \"intestine\", \"intestine\", \"intestine\", \"intestine\", \"intestine\", \"intestine\", \"irq\", \"irq\", \"irq\", \"irq\", \"irq\", \"irq\", \"irq\", \"italy\", \"italy\", \"italy\", \"italy\", \"italy\", \"italy\", \"italy\", \"jagr\", \"jagr\", \"jagr\", \"jagr\", \"jagr\", \"jagr\", \"jagr\", \"jan\", \"jan\", \"jan\", \"jan\", \"jan\", \"jan\", \"jan\", \"japanese\", \"japanese\", \"japanese\", \"japanese\", \"japanese\", \"japanese\", \"japanese\", \"jew\", \"jew\", \"jew\", \"jew\", \"jew\", \"jew\", \"jew\", \"jewish\", \"jewish\", \"jewish\", \"jewish\", \"jewish\", \"jewish\", \"jewish\", \"journey\", \"journey\", \"journey\", \"journey\", \"journey\", \"journey\", \"journey\", \"jsc\", \"jsc\", \"jsc\", \"jsc\", \"jsc\", \"jsc\", \"jsc\", \"key\", \"key\", \"key\", \"key\", \"key\", \"key\", \"key\", \"keyboard\", \"keyboard\", \"keyboard\", \"keyboard\", \"keyboard\", \"keyboard\", \"keyboard\", \"kinda\", \"kinda\", \"kinda\", \"kinda\", \"kinda\", \"kinda\", \"kinda\", \"l\", \"l\", \"l\", \"l\", \"l\", \"l\", \"l\", \"la\", \"la\", \"la\", \"la\", \"la\", \"la\", \"la\", \"laptop\", \"laptop\", \"laptop\", \"laptop\", \"laserwriter\", \"laserwriter\", \"laserwriter\", \"laserwriter\", \"laserwriter\", \"latin\", \"latin\", \"latin\", \"latin\", \"latin\", \"latin\", \"launch\", \"launch\", \"launch\", \"launch\", \"launch\", \"launch\", \"launch\", \"law\", \"law\", \"law\", \"law\", \"law\", \"law\", \"law\", \"le\", \"le\", \"le\", \"le\", \"le\", \"le\", \"le\", \"library\", \"library\", \"library\", \"library\", \"library\", \"library\", \"library\", \"liver\", \"liver\", \"liver\", \"liver\", \"liver\", \"liver\", \"liver\", \"loud\", \"loud\", \"loud\", \"loud\", \"loud\", \"lunar\", \"lunar\", \"lunar\", \"lunar\", \"lunar\", \"lunar\", \"lunar\", \"lyme\", \"lyme\", \"lyme\", \"lyme\", \"lyme\", \"lyme\", \"lyme\", \"m\", \"m\", \"m\", \"m\", \"m\", \"m\", \"m\", \"manager\", \"manager\", \"manager\", \"manager\", \"manager\", \"manager\", \"manager\", \"mark\", \"mark\", \"mark\", \"mark\", \"mark\", \"mark\", \"mark\", \"market\", \"market\", \"market\", \"market\", \"market\", \"market\", \"market\", \"marry\", \"marry\", \"marry\", \"marry\", \"marry\", \"marry\", \"marry\", \"math\", \"math\", \"math\", \"math\", \"math\", \"math\", \"math\", \"mb\", \"mb\", \"mb\", \"mb\", \"mb\", \"mb\", \"mb\", \"meaningful\", \"meaningful\", \"meaningful\", \"meaningful\", \"meaningful\", \"meaningful\", \"meaningful\", \"medical\", \"medical\", \"medical\", \"medical\", \"medical\", \"medical\", \"medical\", \"messy\", \"messy\", \"messy\", \"messy\", \"messy\", \"messy\", \"messy\", \"methodology\", \"methodology\", \"methodology\", \"methodology\", \"methodology\", \"methodology\", \"methodology\", \"migraine\", \"migraine\", \"migraine\", \"migraine\", \"migraine\", \"migraine\", \"min\", \"min\", \"min\", \"min\", \"min\", \"min\", \"min\", \"minute\", \"minute\", \"minute\", \"minute\", \"minute\", \"minute\", \"minute\", \"mission\", \"mission\", \"mission\", \"mission\", \"mission\", \"mission\", \"mission\", \"mode\", \"mode\", \"mode\", \"mode\", \"mode\", \"mode\", \"mode\", \"mon\", \"mon\", \"mon\", \"mon\", \"mon\", \"mon\", \"mon\", \"motif\", \"motif\", \"motif\", \"motif\", \"motif\", \"motif\", \"motif\", \"motion\", \"motion\", \"motion\", \"motion\", \"motion\", \"motion\", \"motion\", \"mouse\", \"mouse\", \"mouse\", \"mouse\", \"mouse\", \"mouse\", \"mouse\", \"move\", \"move\", \"move\", \"move\", \"move\", \"move\", \"move\", \"msg\", \"msg\", \"msg\", \"msg\", \"msg\", \"msg\", \"msg\", \"muslim\", \"muslim\", \"muslim\", \"muslim\", \"muslim\", \"muslim\", \"muslim\", \"mussina\", \"mussina\", \"mussina\", \"mussina\", \"mussina\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"nasa\", \"nasa\", \"nasa\", \"nasa\", \"nasa\", \"nasa\", \"nasa\", \"national\", \"national\", \"national\", \"national\", \"national\", \"national\", \"national\", \"needle\", \"needle\", \"needle\", \"needle\", \"needle\", \"needle\", \"needle\", \"nhl\", \"nhl\", \"nhl\", \"nhl\", \"nhl\", \"nhl\", \"nhl\", \"nl\", \"nl\", \"nl\", \"nl\", \"nl\", \"nl\", \"nl\", \"noring\", \"noring\", \"noring\", \"noring\", \"noring\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"ns\", \"ns\", \"ns\", \"ns\", \"ns\", \"ns\", \"ns\", \"null\", \"null\", \"null\", \"null\", \"null\", \"null\", \"null\", \"nyi\", \"nyi\", \"nyi\", \"nyi\", \"nyi\", \"nyi\", \"nyi\", \"nyr\", \"nyr\", \"nyr\", \"nyr\", \"nyr\", \"nyr\", \"nyr\", \"o\", \"o\", \"o\", \"o\", \"o\", \"o\", \"o\", \"obp\", \"obp\", \"obp\", \"obp\", \"obp\", \"obp\", \"obp\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"openlook\", \"openlook\", \"openlook\", \"openlook\", \"openlook\", \"openlook\", \"option\", \"option\", \"option\", \"option\", \"option\", \"option\", \"option\", \"orbit\", \"orbit\", \"orbit\", \"orbit\", \"orbit\", \"orbit\", \"orbit\", \"orchid\", \"orchid\", \"orchid\", \"orchid\", \"orchid\", \"orchid\", \"oriole\", \"oriole\", \"oriole\", \"oriole\", \"oriole\", \"oriole\", \"oriole\", \"orthodox\", \"orthodox\", \"orthodox\", \"orthodox\", \"orthodox\", \"orthodox\", \"orthodox\", \"os\", \"os\", \"os\", \"os\", \"os\", \"os\", \"os\", \"ott\", \"ott\", \"ott\", \"ott\", \"ott\", \"ott\", \"ott\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"overhead\", \"overhead\", \"overhead\", \"overhead\", \"overhead\", \"overhead\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"package\", \"package\", \"package\", \"package\", \"package\", \"package\", \"package\", \"packard\", \"packard\", \"packard\", \"packard\", \"packard\", \"packard\", \"packard\", \"pain\", \"pain\", \"pain\", \"pain\", \"pain\", \"pain\", \"pain\", \"paris\", \"paris\", \"paris\", \"paris\", \"paris\", \"partition\", \"partition\", \"partition\", \"partition\", \"partition\", \"partition\", \"patient\", \"patient\", \"patient\", \"patient\", \"patient\", \"patient\", \"patient\", \"paul\", \"paul\", \"paul\", \"paul\", \"paul\", \"paul\", \"paul\", \"pay\", \"pay\", \"pay\", \"pay\", \"pay\", \"pay\", \"pay\", \"perceive\", \"perceive\", \"perceive\", \"perceive\", \"perceive\", \"perceive\", \"perceive\", \"period\", \"period\", \"period\", \"period\", \"period\", \"period\", \"period\", \"phi\", \"phi\", \"phi\", \"phi\", \"phi\", \"phi\", \"phi\", \"philadelphia\", \"philadelphia\", \"philadelphia\", \"philadelphia\", \"philadelphia\", \"philadelphia\", \"philadelphia\", \"pick\", \"pick\", \"pick\", \"pick\", \"pick\", \"pick\", \"pick\", \"picture\", \"picture\", \"picture\", \"picture\", \"picture\", \"picture\", \"picture\", \"pin\", \"pin\", \"pin\", \"pin\", \"pin\", \"pin\", \"pin\", \"pipe\", \"pipe\", \"pipe\", \"pipe\", \"pipe\", \"pipe\", \"pipe\", \"pit\", \"pit\", \"pit\", \"pit\", \"pit\", \"pit\", \"pit\", \"pitcher\", \"pitcher\", \"pitcher\", \"pitcher\", \"pitcher\", \"pitcher\", \"pitcher\", \"pitt\", \"pitt\", \"pitt\", \"pitt\", \"pitt\", \"pitt\", \"playing\", \"playing\", \"playing\", \"playing\", \"playing\", \"playing\", \"playoff\", \"playoff\", \"playoff\", \"playoff\", \"playoff\", \"playoff\", \"playoff\", \"pope\", \"pope\", \"pope\", \"pope\", \"pope\", \"pope\", \"pope\", \"popup\", \"popup\", \"popup\", \"popup\", \"popup\", \"popup\", \"popup\", \"port\", \"port\", \"port\", \"port\", \"port\", \"port\", \"port\", \"prescription\", \"prescription\", \"prescription\", \"prescription\", \"prescription\", \"prescription\", \"printer\", \"printer\", \"printer\", \"printer\", \"printer\", \"printer\", \"printer\", \"probert\", \"probert\", \"probert\", \"probert\", \"probert\", \"probert\", \"probert\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"prophecy\", \"prophecy\", \"prophecy\", \"prophecy\", \"prophecy\", \"prophecy\", \"prophecy\", \"protestant\", \"protestant\", \"protestant\", \"protestant\", \"protestant\", \"protestant\", \"proton\", \"proton\", \"proton\", \"proton\", \"proton\", \"proton\", \"providence\", \"providence\", \"providence\", \"providence\", \"providence\", \"providence\", \"providence\", \"pt\", \"pt\", \"pt\", \"pt\", \"pt\", \"pt\", \"pt\", \"quack\", \"quack\", \"quack\", \"quack\", \"quack\", \"quack\", \"quack\", \"que\", \"que\", \"que\", \"que\", \"que\", \"que\", \"que\", \"r\", \"r\", \"r\", \"r\", \"r\", \"r\", \"r\", \"radio\", \"radio\", \"radio\", \"radio\", \"radio\", \"radio\", \"radio\", \"ram\", \"ram\", \"ram\", \"ram\", \"ram\", \"ram\", \"ram\", \"ranger\", \"ranger\", \"ranger\", \"ranger\", \"ranger\", \"ranger\", \"ranger\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"red\", \"red\", \"red\", \"red\", \"red\", \"red\", \"red\", \"religion\", \"religion\", \"religion\", \"religion\", \"religion\", \"religion\", \"religion\", \"remark\", \"remark\", \"remark\", \"remark\", \"remark\", \"remark\", \"remark\", \"republic\", \"republic\", \"republic\", \"republic\", \"republic\", \"republic\", \"resource\", \"resource\", \"resource\", \"resource\", \"resource\", \"resource\", \"resource\", \"respond\", \"respond\", \"respond\", \"respond\", \"respond\", \"respond\", \"respond\", \"resurrection\", \"resurrection\", \"resurrection\", \"resurrection\", \"resurrection\", \"resurrection\", \"resurrection\", \"revenue\", \"revenue\", \"revenue\", \"revenue\", \"revenue\", \"revenue\", \"revenue\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"ribbon\", \"ribbon\", \"ribbon\", \"ribbon\", \"ribbon\", \"rochester\", \"rochester\", \"rochester\", \"rochester\", \"rochester\", \"rochester\", \"rochester\", \"rocket\", \"rocket\", \"rocket\", \"rocket\", \"rocket\", \"rocket\", \"rocket\", \"rod\", \"rod\", \"rod\", \"rod\", \"rod\", \"rod\", \"rod\", \"rom\", \"rom\", \"rom\", \"rom\", \"rom\", \"rom\", \"rom\", \"rubber\", \"rubber\", \"rubber\", \"rubber\", \"rubber\", \"rubber\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"s\", \"s\", \"s\", \"s\", \"s\", \"s\", \"s\", \"sabbath\", \"sabbath\", \"sabbath\", \"sabbath\", \"sabbath\", \"sabbath\", \"sandberg\", \"sandberg\", \"sandberg\", \"sandberg\", \"sandberg\", \"sandberg\", \"sandberg\", \"satellite\", \"satellite\", \"satellite\", \"satellite\", \"satellite\", \"satellite\", \"satellite\", \"sb\", \"sb\", \"sb\", \"sb\", \"sb\", \"sb\", \"science\", \"science\", \"science\", \"science\", \"science\", \"science\", \"science\", \"score\", \"score\", \"score\", \"score\", \"score\", \"score\", \"score\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"scripture\", \"scripture\", \"scripture\", \"scripture\", \"scripture\", \"scripture\", \"scripture\", \"scsi\", \"scsi\", \"scsi\", \"scsi\", \"scsi\", \"scsi\", \"scsi\", \"sec\", \"sec\", \"sec\", \"sec\", \"sec\", \"sec\", \"sec\", \"section\", \"section\", \"section\", \"section\", \"section\", \"section\", \"section\", \"senator\", \"senator\", \"senator\", \"senator\", \"senator\", \"senator\", \"senator\", \"server\", \"server\", \"server\", \"server\", \"server\", \"server\", \"server\", \"service\", \"service\", \"service\", \"service\", \"service\", \"service\", \"service\", \"shameful\", \"shameful\", \"shameful\", \"shameful\", \"shameful\", \"shameful\", \"shameful\", \"shortly\", \"shortly\", \"shortly\", \"shortly\", \"shortly\", \"shortly\", \"shortly\", \"shuttle\", \"shuttle\", \"shuttle\", \"shuttle\", \"shuttle\", \"shuttle\", \"shuttle\", \"simmon\", \"simmon\", \"simmon\", \"simmon\", \"simmon\", \"simmon\", \"sin\", \"sin\", \"sin\", \"sin\", \"sin\", \"sin\", \"sin\", \"single\", \"single\", \"single\", \"single\", \"single\", \"single\", \"single\", \"site\", \"site\", \"site\", \"site\", \"site\", \"site\", \"site\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"sj\", \"sj\", \"sj\", \"sj\", \"sj\", \"sj\", \"sj\", \"skepticism\", \"skepticism\", \"skepticism\", \"skepticism\", \"skepticism\", \"skepticism\", \"skepticism\", \"slg\", \"slg\", \"slg\", \"slg\", \"slg\", \"slg\", \"smiley\", \"smiley\", \"smiley\", \"smiley\", \"smiley\", \"smiley\", \"socket\", \"socket\", \"socket\", \"socket\", \"socket\", \"socket\", \"socket\", \"son\", \"son\", \"son\", \"son\", \"son\", \"son\", \"son\", \"sox\", \"sox\", \"sox\", \"sox\", \"sox\", \"sox\", \"sox\", \"sp\", \"sp\", \"sp\", \"sp\", \"sp\", \"sp\", \"sp\", \"spacecraft\", \"spacecraft\", \"spacecraft\", \"spacecraft\", \"spacecraft\", \"spacecraft\", \"spacecraft\", \"spaceflight\", \"spaceflight\", \"spaceflight\", \"spaceflight\", \"spaceflight\", \"spaceflight\", \"spaceflight\", \"sparc\", \"sparc\", \"sparc\", \"sparc\", \"sparc\", \"sparc\", \"sparc\", \"spare\", \"spare\", \"spare\", \"spare\", \"spare\", \"spare\", \"spelling\", \"spelling\", \"spelling\", \"spelling\", \"spelling\", \"spelling\", \"spirit\", \"spirit\", \"spirit\", \"spirit\", \"spirit\", \"spirit\", \"spirit\", \"st\", \"st\", \"st\", \"st\", \"st\", \"st\", \"st\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"stat\", \"stat\", \"stat\", \"stat\", \"stat\", \"stat\", \"stat\", \"stealth\", \"stealth\", \"stealth\", \"stealth\", \"stealth\", \"stealth\", \"stealth\", \"stereo\", \"stereo\", \"stereo\", \"stereo\", \"stereo\", \"stereo\", \"stereo\", \"stl\", \"stl\", \"stl\", \"stl\", \"stl\", \"stl\", \"stl\", \"stream\", \"stream\", \"stream\", \"stream\", \"stream\", \"stream\", \"stream\", \"street\", \"street\", \"street\", \"street\", \"street\", \"street\", \"street\", \"string\", \"string\", \"string\", \"string\", \"string\", \"string\", \"string\", \"suck\", \"suck\", \"suck\", \"suck\", \"suck\", \"suck\", \"suck\", \"suffer\", \"suffer\", \"suffer\", \"suffer\", \"suffer\", \"suffer\", \"suffer\", \"surrender\", \"surrender\", \"surrender\", \"surrender\", \"surrender\", \"surrender\", \"surrender\", \"swell\", \"swell\", \"swell\", \"swell\", \"swell\", \"swell\", \"swell\", \"symbol\", \"symbol\", \"symbol\", \"symbol\", \"symbol\", \"symbol\", \"symbol\", \"synchronous\", \"synchronous\", \"synchronous\", \"synchronous\", \"synchronous\", \"synchronous\", \"synchronous\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"tape\", \"tape\", \"tape\", \"tape\", \"tape\", \"tape\", \"tape\", \"tb\", \"tb\", \"tb\", \"tb\", \"tb\", \"tb\", \"tb\", \"technician\", \"technician\", \"technician\", \"technician\", \"technician\", \"technician\", \"technology\", \"technology\", \"technology\", \"technology\", \"technology\", \"technology\", \"technology\", \"telnet\", \"telnet\", \"telnet\", \"telnet\", \"telnet\", \"telnet\", \"telnet\", \"theory\", \"theory\", \"theory\", \"theory\", \"theory\", \"theory\", \"theory\", \"throw\", \"throw\", \"throw\", \"throw\", \"throw\", \"throw\", \"throw\", \"tolerance\", \"tolerance\", \"tolerance\", \"tolerance\", \"tolerance\", \"tolerance\", \"tomorrow\", \"tomorrow\", \"tomorrow\", \"tomorrow\", \"tomorrow\", \"tomorrow\", \"tomorrow\", \"tool\", \"tool\", \"tool\", \"tool\", \"tool\", \"tool\", \"tool\", \"tor\", \"tor\", \"tor\", \"tor\", \"tor\", \"tor\", \"tor\", \"tower\", \"tower\", \"tower\", \"tower\", \"tower\", \"tower\", \"tower\", \"tracking\", \"tracking\", \"tracking\", \"tracking\", \"tracking\", \"tracking\", \"tracking\", \"trust\", \"trust\", \"trust\", \"trust\", \"trust\", \"trust\", \"trust\", \"truth\", \"truth\", \"truth\", \"truth\", \"truth\", \"truth\", \"truth\", \"undefined\", \"undefined\", \"undefined\", \"undefined\", \"undefined\", \"undefined\", \"undefined\", \"universe\", \"universe\", \"universe\", \"universe\", \"universe\", \"universe\", \"universe\", \"user\", \"user\", \"user\", \"user\", \"user\", \"user\", \"user\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"van\", \"van\", \"van\", \"van\", \"van\", \"van\", \"van\", \"verse\", \"verse\", \"verse\", \"verse\", \"verse\", \"verse\", \"verse\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"vram\", \"vram\", \"vram\", \"vram\", \"vram\", \"vram\", \"vram\", \"vs\", \"vs\", \"vs\", \"vs\", \"vs\", \"vs\", \"vs\", \"wash\", \"wash\", \"wash\", \"wash\", \"wash\", \"wash\", \"wash\", \"water\", \"water\", \"water\", \"water\", \"water\", \"water\", \"water\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"widget\", \"widget\", \"widget\", \"widget\", \"widget\", \"widget\", \"widget\", \"wife\", \"wife\", \"wife\", \"wife\", \"wife\", \"wife\", \"wife\", \"winner\", \"winner\", \"winner\", \"winner\", \"winner\", \"winner\", \"winner\", \"ximage\", \"ximage\", \"ximage\", \"ximage\", \"ximage\", \"ximage\", \"xputimage\", \"xputimage\", \"xputimage\", \"xputimage\", \"xputimage\", \"xputimage\", \"xsun\", \"xsun\", \"xsun\", \"xsun\", \"xsun\", \"xsun\", \"xsun\", \"xt\", \"xt\", \"xt\", \"xt\", \"xt\", \"xt\", \"xt\", \"yeast\", \"yeast\", \"yeast\", \"yeast\", \"yeast\", \"yeast\", \"yeast\", \"yount\", \"yount\", \"yount\", \"yount\", \"yount\", \"yup\", \"yup\", \"yup\", \"yup\", \"yup\", \"yup\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 1, 3, 6, 4, 5, 7]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el44711399540405504082043278544\", ldavis_el44711399540405504082043278544_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el44711399540405504082043278544\", ldavis_el44711399540405504082043278544_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el44711399540405504082043278544\", ldavis_el44711399540405504082043278544_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "\n",
    "pyLDAvis.display(LDAvis_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. TOPIC2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argmax example:\n",
    "# >>> kkk\n",
    "# array([[1, 2, 3],\n",
    "#       [0, 4, 2]])\n",
    "# >>> np.argmax(kkk, 0)\n",
    "# array([0, 1, 0])\n",
    "# >>> np.argmax(kkk, 1)\n",
    "# array([2, 1])\n",
    "#\n",
    "# this will select the topic with the most word weight for each word in the vocabulary\n",
    "# after this, we can easily lookup the best topic of each vocabulary word by \n",
    "# most_p_topic[word_voca_index] -> word's topic (0 -7 in this case) \n",
    "most_p_topic = np.argmax(per_topic_distr_LDA, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per_topic_distr_LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17197,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_p_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_and_topic = zip(tf_feature_names, most_p_topic)\n",
    "# word2topic_dict = {word : 'topic_' + np.array_str(topic) for word, topic in word_and_topic}\n",
    "word2topic_dict = {word : 'topic_{}'.format(topic) for word, topic in word_and_topic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('disrespectful', 'topic_4'),\n",
       " ('closed', 'topic_4'),\n",
       " ('fraud', 'topic_5'),\n",
       " ('ventura', 'topic_7'),\n",
       " ('powerful', 'topic_1')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the top 5 words and their belonged topics\n",
    "from itertools import islice\n",
    "list(islice(word2topic_dict.items(), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(document):\n",
    "    text = \"\".join([ch for ch in document if ch not in string.punctuation])\n",
    "    text_list = text.split()\n",
    "    normalized_text = [x.lower() for x in text_list]\n",
    "    # Define an empty list\n",
    "    nostopwords_text = []\n",
    "    # Scan the words\n",
    "    for word in normalized_text:\n",
    "        # Determine if the word is contained in the stop words list\n",
    "        if word not in ENGLISH_STOP_WORDS:\n",
    "            # If the word is not contained I append it\n",
    "            nostopwords_text.append(word)\n",
    "    tokenized_text = [word for word in nostopwords_text if re.search('[a-zA-Z]{2,}', word)]\n",
    "            \n",
    "    return tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_doc_to_topic(tokenized_text, prefix, doc_id_number, word2topic_dict):\n",
    "    doc_to_topic_list = [prefix + '_' + str(doc_id_number)]\n",
    "    # print('adding doc_to_topic header element {}'.format(doc_to_topic_list[0]))\n",
    "\n",
    "    for word in tokenized_text:\n",
    "        if word in word2topic_dict.keys():\n",
    "            doc_to_topic_list.append(word2topic_dict[word])\n",
    "        # else:\n",
    "        #    print('{} not found in word2topic_dict.keys'.format(word))\n",
    "\n",
    "    return doc_to_topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.deprecated.doc2vec import LabeledSentence"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, docs_list, word2topic_dict):\n",
    "        self.labels_list = word2topic_dict\n",
    "        self.docs_list = docs_list\n",
    "    def __iter__(self):\n",
    "        for idx, doc in enumerate(self.docs_list):\n",
    "            words_doc=tokenizer(doc)\n",
    "            tags_doc = map_doc_to_topic(words_doc, idx, word2topic_dict)\n",
    "            yield LabeledSentence(words = words_doc,\n",
    "                                                 tags = tags_doc)\n",
    "            \n",
    "    def sentences_perm(self):\n",
    "        shuffle(models.doc2vec.LabeledSentence)\n",
    "        return models.doc2vec.LabeledSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledLineSentence_training(object):\n",
    "    def __init__(self, sources, word2topic_dict):\n",
    "        self.labels_list = word2topic_dict\n",
    "        self.sources = sources\n",
    "        flipped = {}\n",
    "        # make sure that keys are unique\n",
    "        for key, value in sources.items():\n",
    "            if value not in flipped:\n",
    "                flipped[value] = [key]\n",
    "            else:\n",
    "                raise Exception('Non-unique prefix encountered')\n",
    "    \n",
    "    def __iter__(self):\n",
    "        print('len of sources is {}'.format(len(self.sources)))\n",
    "        for source, prefix in self.sources.items():\n",
    "            print(source)\n",
    "            newsgroups_train_cat = fetch_20newsgroups(subset='train',\n",
    "                                                      remove=('headers', 'footers', 'quotes'),\n",
    "                                                      categories=[source])\n",
    "            # print('len of newsgroups_train_cat is {}'.format(len(newsgroups_train_cat)))\n",
    "            # (Pdb) newsgroups_train_cat.keys() -> \n",
    "            # dict_keys(['data', 'filenames', 'target', 'description', 'DESCR', 'target_names'])\n",
    "            # import pdb; pdb.set_trace()\n",
    "            for idx, doc in enumerate(newsgroups_train_cat.data):\n",
    "                words_doc=tokenizer(doc)\n",
    "                tags_doc = map_doc_to_topic(words_doc, prefix, idx, word2topic_dict)\n",
    "                yield LabeledSentence(words = words_doc,\n",
    "                                                     tags = tags_doc)\n",
    "                \n",
    "    def to_array(self):\n",
    "        self.sentences = []\n",
    "        print('len of sources is {}'.format(len(self.sources)))\n",
    "        for source, prefix in self.sources.items():\n",
    "            newsgroups_train_cat = fetch_20newsgroups(subset='train',\n",
    "                                                      remove=('headers', 'footers', 'quotes'),\n",
    "                                                      categories=[source])\n",
    "            # print('len of newsgroups_train_cat is {}'.format(len(newsgroups_train_cat)))\n",
    "            # import pdb; pdb.set_trace()\n",
    "            # (Pdb) type(newsgroups_train_cat) -> <class 'sklearn.utils.Bunch'> => len is 6\n",
    "            # (Pdb) type(newsgroups_train_cat.data) -> <class 'list'>\n",
    "            # (Pdb) len(newsgroups_train_cat.data) -> 593\n",
    "            # (Pdb) newsgroups_train_cat.data[0] -> document 1 strings, with newlines inside\n",
    "            # (Pdb) newsgroups_train_cat.data[1] -> document 2 strings, with newlines inside\n",
    "            # (Pdb) newsgroups_train_cat.target.shape -> (593,)\n",
    "            # (Pdb) newsgroups_train_cat.target.max() -> 0\n",
    "            for idx, doc in enumerate(newsgroups_train_cat.data):\n",
    "                words_doc=tokenizer(doc)\n",
    "                tags_doc = map_doc_to_topic(words_doc, prefix, idx, word2topic_dict)\n",
    "                self.sentences.append(LabeledSentence(words = words_doc,\n",
    "                                                     tags = tags_doc))\n",
    "        return self.sentences\n",
    "            \n",
    "    def sentences_perm(self):\n",
    "        shuffle(self.sentences)\n",
    "        return self.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3.1 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisit parameters before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comp.sys.ibm.pc.hardware': 'comp_sys_ibm_pc_hardware',\n",
       " 'comp.sys.mac.hardware': 'comp_sys_mac_hardware',\n",
       " 'comp.windows.x': 'comp_windows_x',\n",
       " 'rec.sport.baseball': 'rec_sport_baseball',\n",
       " 'rec.sport.hockey': 'rec_sport_hockey',\n",
       " 'sci.med': 'sci_med',\n",
       " 'sci.space': 'sci_space',\n",
       " 'soc.religion.christian': 'soc_religion_christian'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('disrespectful', 'topic_4'),\n",
       " ('closed', 'topic_4'),\n",
       " ('fraud', 'topic_5'),\n",
       " ('ventura', 'topic_7'),\n",
       " ('powerful', 'topic_1')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(islice(word2topic_dict.items(), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all input news group documents\n",
    "#    For all sentences in that document\n",
    "#        Generate gensim.models.deprecated.doc2vec.LabeledSentence\n",
    "#            (words, tags with group name and word's topics)\n",
    "it = LabeledLineSentence_training(categories_source, word2topic_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quote notes about LabeledSentence and TaggedDocument\n",
    "1. LabeledSentence is an older, deprecated name for the same simple object-type to encapsulate a text-example that is now called TaggedDocument. \n",
    "2. Any objects that have words and tags properties, each a list, will do.\n",
    "    - words is always a list of strings\n",
    "    - tags can be a mix of integers and strings, but in the common and most-efficient case, is just a list with a single id integer, starting at 0.)\n",
    "\n",
    "#### [Info about how to use Gensim doc2vec](https://medium.com/@mishra.thedeepak/doc2vec-in-a-simple-way-fa80bfe81104)\n",
    "1. In this example it uses filename and doc label\n",
    "2. And after the training it can print the vector of the file using its name\n",
    "\n",
    "    ```\n",
    "    docvec = d2v_model.docvecs[‘1.txt’] #if string tag used in training\n",
    "    print docvec\n",
    "    ```\n",
    "3. Or to get most similar document with similarity scores using document-index\n",
    "\n",
    "    ```\n",
    "    similar_doc = d2v_model.docvecs.most_similar(14) \n",
    "    print similar_doc\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of sources is 8\n",
      "sci.space\n",
      "<class 'gensim.models.deprecated.doc2vec.LabeledSentence'>\n",
      "LabeledSentence(['lunar', 'satellite', 'needs', 'fuel', 'regular', 'orbit', 'corrections', 'fuel', 'runs', 'crash', 'months', 'orbits', 'apollo', 'motherships', 'changed', 'noticeably', 'lunar', 'missions', 'lasting', 'days', 'possible', 'stable', 'orbits', 'moons', 'gravitational', 'field', 'poorly', 'mapped', 'know', 'perturbations', 'sun', 'earth', 'relatively', 'minor', 'issues', 'low', 'altitudes', 'big', 'problem', 'moons', 'gravitational', 'field', 'quite', 'lumpy', 'irregular', 'distribution', 'mass', 'moon'], ['sci_space_0', 'topic_5', 'topic_5', 'topic_5', 'topic_7', 'topic_5', 'topic_5', 'topic_1', 'topic_5', 'topic_5', 'topic_1', 'topic_1', 'topic_5', 'topic_5', 'topic_1', 'topic_1', 'topic_5', 'topic_5', 'topic_1', 'topic_7', 'topic_1', 'topic_1', 'topic_1', 'topic_5', 'topic_5', 'topic_1', 'topic_5', 'topic_5', 'topic_5', 'topic_5'])\n",
      "30 48\n",
      "['sci_space_0', 'topic_5', 'topic_5', 'topic_5', 'topic_7', 'topic_5', 'topic_5', 'topic_1', 'topic_5', 'topic_5'] ['lunar', 'satellite', 'needs', 'fuel', 'regular', 'orbit', 'corrections', 'fuel', 'runs', 'crash']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:28: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n"
     ]
    }
   ],
   "source": [
    "# print the first new group's item #1\n",
    "inspect_item = next(iter(it))\n",
    "print(type(inspect_item))\n",
    "print(inspect_item)\n",
    "print(len(inspect_item.tags), len(inspect_item.words))\n",
    "print(inspect_item.tags[:10], inspect_item.words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/gensim/models/doc2vec.py:359: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of sources is 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:50: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n"
     ]
    }
   ],
   "source": [
    "# type(models.Doc2Vec)\n",
    "model = models.Doc2Vec(size=100, window=10, min_count=4, dm=1, dbow_words=1,\n",
    "                              workers=50, alpha=0.025, min_alpha=0.025) # use fixed learning rate\n",
    "model.build_vocab(it.to_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [04:39<00:00, 13.99s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for epoch in tqdm(range(20)):\n",
    "    model.train(it.sentences_perm(), total_examples=model.corpus_count, epochs=1)\n",
    "    model.alpha -= 0.002 # decrease the learning rate\n",
    "    model.min_alpha = model.alpha # fix the learning rate, no decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname =  os.getcwd() # Prints the working directory\n",
    "fname = fname + '/topic2vec_20NG_2_ndoc' + str(n_docs) + 'n_topic' + str(n_topics) + '.model'\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results\n",
    "A quick info about [how to use gensim doc2vec model to query words by label vector or vice versa](https://github.com/RaRe-Technologies/gensim/issues/1397)\n",
    "\n",
    "1. search words using word\n",
    "\n",
    "    ```\n",
    "    model.most_similar('word')\n",
    "    # only similar words were returned but not labels\n",
    "    ```\n",
    "2. search label by label\n",
    "    - use model.docvecs.most_similar to search for similar labels using labels\n",
    "3. search words by label\n",
    "\n",
    "    ```\n",
    "    model.docvecs['label']\n",
    "    model.similar_by_vector(label_vec)\n",
    "    # only similar words were returned\n",
    "    ```\n",
    "4. search labels by word\n",
    "\n",
    "    ```\n",
    "    word_vec = model['word']\n",
    "    model.docvecs.most_similar([word_vec])\n",
    "    # returns similar labels\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from /home/aimladmin/notebooks/home/ksong/Topic2Vec/topic2vec_20NG_2_ndoc4744n_topic8.model\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "\n",
    "# load the model back\n",
    "fname = fname if fname is not None else 'topic2vec_20NG_2_ndoc4744n_topic8.model'\n",
    "print('loading model from {}'.format(fname))\n",
    "d2v_model = models.doc2vec.Doc2Vec.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4752 [('comp_sys_ibm_pc_hardware_354', Doctag(offset=2148, word_count=224, doc_count=1)), ('comp_sys_ibm_pc_hardware_326', Doctag(offset=2120, word_count=13, doc_count=1)), ('comp_windows_x_442', Doctag(offset=4601, word_count=72, doc_count=1)), ('soc_religion_christian_326', Doctag(offset=1521, word_count=10, doc_count=1)), ('comp_sys_ibm_pc_hardware_291', Doctag(offset=2085, word_count=58, doc_count=1))]\n"
     ]
    }
   ],
   "source": [
    "# list the top 5 tags in the model\n",
    "from itertools import islice\n",
    "\n",
    "paragraphs_tag = d2v_model.docvecs.doctags\n",
    "type(paragraphs_tag)\n",
    "print(len(paragraphs_tag), list(islice(paragraphs_tag.items(),5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `doctag_syn0` (Attribute will be removed in 4.0.0, use docvecs.vectors_docs instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4752, 100)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragraphs_vector = d2v_model.docvecs.doctag_syn0\n",
    "ragraphs_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rec_sport_baseball_389', 0.35365036129951477),\n",
       " ('rec_sport_baseball_378', 0.34690025448799133),\n",
       " ('comp_sys_ibm_pc_hardware_563', 0.3393045663833618),\n",
       " ('sci_med_524', 0.3304837942123413),\n",
       " ('comp_sys_mac_hardware_518', 0.32284557819366455),\n",
       " ('sci_med_125', 0.3165658116340637),\n",
       " ('rec_sport_hockey_94', 0.28935739398002625),\n",
       " ('comp_sys_mac_hardware_292', 0.289227157831192),\n",
       " ('rec_sport_hockey_203', 0.285552978515625),\n",
       " ('rec_sport_baseball_449', 0.28499162197113037)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_model.docvecs.most_similar(positive = ['sci_space_96'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lords', 0.39834630489349365),\n",
       " ('doesnt', 0.3908179998397827),\n",
       " ('darling', 0.3805291950702667),\n",
       " ('ahola', 0.35309669375419617),\n",
       " ('worry', 0.3530368208885193),\n",
       " ('destroyed', 0.3495197892189026),\n",
       " ('tale', 0.33816206455230713),\n",
       " ('cpus', 0.33736613392829895),\n",
       " ('lzone', 0.325408935546875),\n",
       " ('ears', 0.3231354355812073)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_vec = d2v_model.docvecs['sci_space_96']\n",
    "d2v_model.wv.similar_by_vector(label_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> top 10 relevant words of topic 0\n",
      "[('al', 0.8068424463272095), ('holds', 0.7901829481124878), ('rd3', 0.7826679944992065), ('percentage', 0.7784439921379089), ('behalf', 0.7727761268615723), ('spouse', 0.7723900079727173), ('intensive', 0.7632749080657959), ('crime', 0.7625982165336609), ('molecular', 0.7587553858757019), ('experimental', 0.7542406320571899)]\n",
      ">>> top 10 relevant words of topic 1\n",
      "[('echohostname', 0.922170877456665), ('hank', 0.9113080501556396), ('echo', 0.9076107144355774), ('set', 0.9072037935256958), ('woof', 0.8928797841072083), ('aaron', 0.8849927186965942), ('tail', 0.8846719264984131), ('iivx', 0.8805248141288757), ('finished', 0.8791848421096802), ('cdrom', 0.8782916069030762)]\n",
      ">>> top 10 relevant words of topic 2\n",
      "[('decs', 0.8631792068481445), ('create', 0.8595727682113647), ('exposuremask', 0.8494325876235962), ('waking', 0.8476630449295044), ('spoke', 0.8470355272293091), ('event', 0.8446255922317505), ('program', 0.8435776829719543), ('meditating', 0.8421506881713867), ('restored', 0.8416558504104614), ('icon', 0.8404950499534607)]\n",
      ">>> top 10 relevant words of topic 3\n",
      "[('crap', 0.7798736095428467), ('dram', 0.7096757292747498), ('fluid', 0.6836119890213013), ('cycle', 0.6735010147094727), ('someones', 0.6624869108200073), ('falling', 0.6527544856071472), ('affect', 0.6497668623924255), ('propulsion', 0.6358532309532166), ('minors', 0.6320293545722961), ('single', 0.6275367736816406)]\n",
      ">>> top 10 relevant words of topic 4\n",
      "[('dreams', 0.7711558938026428), ('mu', 0.7572609186172485), ('mean', 0.7414233684539795), ('connection', 0.7377687692642212), ('judge', 0.7367845177650452), ('explosions', 0.7366541624069214), ('ideas', 0.736388623714447), ('choosing', 0.7312091588973999), ('believed', 0.729036808013916), ('reformat', 0.7234945297241211)]\n",
      ">>> top 10 relevant words of topic 5\n",
      "[('icon', 0.8683058023452759), ('set', 0.8650736808776855), ('mechanism', 0.8590324521064758), ('ms', 0.8565715551376343), ('coordinates', 0.8454750776290894), ('blit', 0.8400388360023499), ('save', 0.8353490829467773), ('xclrs', 0.834591269493103), ('en', 0.8300473690032959), ('woof', 0.8297919034957886)]\n",
      ">>> top 10 relevant words of topic 6\n",
      "[('health', 0.845354437828064), ('snuff', 0.7913036346435547), ('tobacco', 0.7913007736206055), ('pray', 0.783969521522522), ('brother', 0.7774941921234131), ('punishment', 0.776374340057373), ('chewing', 0.7514508962631226), ('sisterinlaw', 0.7512537837028503), ('yankees', 0.7459442019462585), ('smokeless', 0.7427297830581665)]\n",
      ">>> top 10 relevant words of topic 7\n",
      "[('receive', 0.8917831778526306), ('warned', 0.8816089630126953), ('expose', 0.8808605074882507), ('drawable', 0.868147611618042), ('mainwinwin', 0.8607932925224304), ('drawing', 0.846565842628479), ('excerpts', 0.832735538482666), ('detailwinwin', 0.8278787136077881), ('decs', 0.827242374420166), ('receives', 0.8075612783432007)]\n"
     ]
    }
   ],
   "source": [
    "for topic_idx in range(8):\n",
    "    print('>>> top 10 relevant words of topic {}'.format(topic_idx))\n",
    "    topic_vec = d2v_model.docvecs['topic_{}'.format(topic_idx)]\n",
    "    print(d2v_model.wv.similar_by_vector(topic_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sci_space_411', 0.6604948043823242),\n",
       " ('comp_sys_mac_hardware_42', 0.6437797546386719),\n",
       " ('soc_religion_christian_278', 0.6072692275047302),\n",
       " ('rec_sport_baseball_549', 0.5811659097671509),\n",
       " ('comp_windows_x_404', 0.5668190717697144),\n",
       " ('rec_sport_hockey_233', 0.5499863028526306),\n",
       " ('soc_religion_christian_28', 0.5372079610824585),\n",
       " ('comp_sys_mac_hardware_476', 0.47990018129348755),\n",
       " ('comp_sys_mac_hardware_125', 0.47634610533714294),\n",
       " ('soc_religion_christian_226', 0.4659426808357239)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vec = d2v_model['nasa']\n",
    "d2v_model.docvecs.most_similar([word_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.644150725372538"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_model.docvecs.n_similarity(['topic_0', 'topic_2'], ['topic_3', 'topic_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3563553612509076"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_model.docvecs.similarity('topic_0', 'topic_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 FastAI",
   "language": "python",
   "name": "fastai-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
