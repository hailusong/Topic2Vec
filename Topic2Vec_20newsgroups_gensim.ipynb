{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic2Vec_20newsgroups on Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyorient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. IMPORTING DOCS FROM 20 NEWSGROUPS DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['comp.sys.ibm.pc.hardware',\n",
    "'comp.sys.mac.hardware',\n",
    "'comp.windows.x',\n",
    "'rec.sport.baseball',\n",
    "'rec.sport.hockey',\n",
    "'sci.med',\n",
    "'sci.space',\n",
    "'soc.religion.christian']\n",
    "\n",
    "n_topics = len(categories)\n",
    "\n",
    "categories_source = {}\n",
    "\n",
    "for cat in categories:\n",
    "    categories_source[cat] = cat.replace('.', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comp.sys.ibm.pc.hardware': 'comp_sys_ibm_pc_hardware',\n",
       " 'comp.sys.mac.hardware': 'comp_sys_mac_hardware',\n",
       " 'comp.windows.x': 'comp_windows_x',\n",
       " 'rec.sport.baseball': 'rec_sport_baseball',\n",
       " 'rec.sport.hockey': 'rec_sport_hockey',\n",
       " 'sci.med': 'sci_med',\n",
       " 'sci.space': 'sci_space',\n",
       " 'soc.religion.christian': 'soc_religion_christian'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      remove=('headers', 'footers', 'quotes'),\n",
    "                                      categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.sys.ibm.pc.hardware comp_sys_ibm_pc_hardware\n",
      "comp.sys.mac.hardware comp_sys_mac_hardware\n",
      "comp.windows.x comp_windows_x\n",
      "rec.sport.baseball rec_sport_baseball\n",
      "rec.sport.hockey rec_sport_hockey\n",
      "sci.med sci_med\n",
      "sci.space sci_space\n",
      "soc.religion.christian soc_religion_christian\n"
     ]
    }
   ],
   "source": [
    "for i,j in categories_source.items():\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOTAL NUMBER OF DOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4744"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_docs = newsgroups_train.filenames.shape[0]\n",
    "n_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(newsgroups_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/home/aimladmin/scikit_learn_data/20news_home/20news-bydate-train/sci.space/61065',\n",
       "       '/home/aimladmin/scikit_learn_data/20news_home/20news-bydate-train/rec.sport.hockey/52618',\n",
       "       '/home/aimladmin/scikit_learn_data/20news_home/20news-bydate-train/comp.windows.x/67032',\n",
       "       ...,\n",
       "       '/home/aimladmin/scikit_learn_data/20news_home/20news-bydate-train/rec.sport.hockey/52576',\n",
       "       '/home/aimladmin/scikit_learn_data/20news_home/20news-bydate-train/soc.religion.christian/20809',\n",
       "       '/home/aimladmin/scikit_learn_data/20news_home/20news-bydate-train/soc.religion.christian/20733'],\n",
       "      dtype='<U96')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4744"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hmmm. I seem to recall that the attraction of solid state record-\\nplayers and radios in the 1960s wasn't better performance but lower\\nper-unit cost than vacuum-tube systems.\\n\\n\\tMind you, my father was a vacuum-tube fan in the 60s (Switched\\nto solid-state in the mid-seventies and then abruptly died; no doubt\\nthere's a lesson in that) and his account could have been biased.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             text          lemma  log_probability  stop?  isalpha?  \\\n",
      "0           Hello          hello            -20.0  False      True   \n",
      "1             the            the            -20.0   True      True   \n",
      "2               >              >            -20.0  False     False   \n",
      "3               <              <            -20.0  False     False   \n",
      "4           wolrd          wolrd            -20.0  False      True   \n",
      "5               !              !            -20.0  False     False   \n",
      "6              \\n             \\n            -20.0  False     False   \n",
      "7           Where          where            -20.0  False      True   \n",
      "8              we         -PRON-            -20.0   True      True   \n",
      "9             Are             be            -20.0  False      True   \n",
      "10            are             be            -20.0   True      True   \n",
      "11             Be             be            -20.0  False      True   \n",
      "12         become         become            -20.0   True      True   \n",
      "13          never          never            -20.0   True      True   \n",
      "14          today          today            -20.0  False      True   \n",
      "15  unfortunately  unfortunately            -20.0  False      True   \n",
      "16              ?              ?            -20.0  False     False   \n",
      "17             \\n             \\n            -20.0  False     False   \n",
      "18           Will           will            -20.0  False      True   \n",
      "19           that           that            -20.0   True      True   \n",
      "20            The            the            -20.0  False      True   \n",
      "21        Walnurs        walnurs            -20.0  False      True   \n",
      "22             or             or            -20.0   True      True   \n",
      "23           they         -PRON-            -20.0   True      True   \n",
      "24             or             or            -20.0   True      True   \n",
      "25             he         -PRON-            -20.0   True      True   \n",
      "26             or             or            -20.0   True      True   \n",
      "27            she         -PRON-            -20.0   True      True   \n",
      "28           join           join            -20.0  False      True   \n",
      "29             us         -PRON-            -20.0   True      True   \n",
      "30             as             as            -20.0   True      True   \n",
      "31              a              a            -20.0   True      True   \n",
      "32         lovely         lovely            -20.0  False      True   \n",
      "33           team           team            -20.0  False      True   \n",
      "34             's             's            -20.0  False     False   \n",
      "35          party          party            -20.0  False      True   \n",
      "\n",
      "    punctuation?  whitespace?  number?  out of vocab.?  \n",
      "0          False        False    False            True  \n",
      "1          False        False    False            True  \n",
      "2          False        False    False            True  \n",
      "3          False        False    False            True  \n",
      "4          False        False    False            True  \n",
      "5           True        False    False            True  \n",
      "6          False         True    False            True  \n",
      "7          False        False    False            True  \n",
      "8          False        False    False            True  \n",
      "9          False        False    False            True  \n",
      "10         False        False    False            True  \n",
      "11         False        False    False            True  \n",
      "12         False        False    False            True  \n",
      "13         False        False    False            True  \n",
      "14         False        False    False            True  \n",
      "15         False        False    False            True  \n",
      "16          True        False    False            True  \n",
      "17         False         True    False            True  \n",
      "18         False        False    False            True  \n",
      "19         False        False    False            True  \n",
      "20         False        False    False            True  \n",
      "21         False        False    False            True  \n",
      "22         False        False    False            True  \n",
      "23         False        False    False            True  \n",
      "24         False        False    False            True  \n",
      "25         False        False    False            True  \n",
      "26         False        False    False            True  \n",
      "27         False        False    False            True  \n",
      "28         False        False    False            True  \n",
      "29         False        False    False            True  \n",
      "30         False        False    False            True  \n",
      "31         False        False    False            True  \n",
      "32         False        False    False            True  \n",
      "33         False        False    False            True  \n",
      "34         False        False    False            True  \n",
      "35         False        False    False            True  \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# for quick reference goes to https://github.com/hailusong/lda2vec/blob/master/lda2vec/preprocess.py\n",
    "# nlp = spacy.load('en')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "if 1 == 1:\n",
    "    parsed_review = nlp('Hello the > < wolrd!\\nWhere we Are are Be become never today unfortunately?\\nWill that The Walnurs or they or he or she join us as a lovely team\\'s party')\n",
    "    token_attributes = [(token.orth_,\n",
    "                     token.lemma_,\n",
    "                     token.prob,\n",
    "                     token.is_stop,\n",
    "                     token.is_alpha,\n",
    "                     token.is_punct,\n",
    "                     token.is_space,\n",
    "                     token.like_num,\n",
    "                     token.is_oov)\n",
    "                    for token in parsed_review]\n",
    "\n",
    "    df = pd.DataFrame(token_attributes,\n",
    "                      columns=['text',\n",
    "                               'lemma',\n",
    "                               'log_probability',\n",
    "                               'stop?',\n",
    "                               'isalpha?',\n",
    "                               'punctuation?',\n",
    "                               'whitespace?',\n",
    "                               'number?',\n",
    "                               'out of vocab.?'])\n",
    "\n",
    "    # df.loc[:, 'stop?':'out of vocab.?'] = (df.loc[:, 'stop?':'out of vocab.?']\n",
    "    #                                       .applymap(lambda x: 'Yes' if x else ''))\n",
    "\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase Modeling\n",
    "Code from [Modern NLP in Python](http://nbviewer.jupyter.org/github/skipgram/modern-nlp-in-python/blob/master/executable/Modern_NLP_in_Python.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_tokens = set()\n",
    "\n",
    "def punct_space(token):\n",
    "    \"\"\"\n",
    "    helper function to eliminate tokens\n",
    "    that are pure punctuation or whitespace\n",
    "    \"\"\"\n",
    "    \n",
    "    result = token.is_punct or token.is_space or token.is_stop or not token.is_alpha\n",
    "    if result:\n",
    "       removed_tokens.add(token.text)\n",
    "\n",
    "    return result\n",
    "\n",
    "def line_review(filename):\n",
    "    \"\"\"\n",
    "    generator function to read in reviews from the file\n",
    "    and un-escape the original line breaks in the text\n",
    "    \"\"\"\n",
    "    \n",
    "    with codecs.open(filename, encoding='utf_8') as f:\n",
    "        for review in f:\n",
    "            yield review.replace('\\\\n', '\\n')\n",
    "\n",
    "def line_sklearn_data(sklearn_data):\n",
    "    \"\"\"\n",
    "    generator function to read in sklearn data from the list\n",
    "    and un-escape the original line breaks in the text\n",
    "    \"\"\"\n",
    "    \n",
    "    for data in sklearn_data:\n",
    "        yield data.replace('\\\\n', '\\n').lower()\n",
    "    \n",
    "def lemmatized_sentence_corpus(sentences):\n",
    "    \"\"\"\n",
    "    generator function to use spaCy to parse reviews,\n",
    "    lemmatize the text, and yield sentences\n",
    "    \"\"\"\n",
    "    \n",
    "    for parsed_review in nlp.pipe(sentences,\n",
    "                                  batch_size=10000, n_threads=4):\n",
    "        \n",
    "        for sent in parsed_review.sents:\n",
    "            yield ' '.join([token.lemma_ for token in sent if not punct_space(token)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_directory = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_sentences_filepath = os.path.join(intermediate_directory,\n",
    "                                          'unigram_sentences_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "16it [00:00, 219.35it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original >>>\n",
      "[\"Well, here it is, NHL in the year 2000.\\nI got these from a very reliable source in a dream some years ago and \\nalthough I initially thought I had just been taking too many too strong \\ndrugs now it seems the realization has really begun...  You can see the \\nleague has already started to move to this direction.\\n\\n   *The Walt Disney Conference*\\nAnaheim Mighty Chipmunks    -Franchise name to be changed after each new \\nLA Kings                      hockey movie         \\nLA Flames                   -We've seen some of that\\nSan Jose Sharks\\nSan Diego Bruins\\nTijuana Red Wings   -Detroit's hockey team will follow its car industry...\\nDallas Stars           \\nHouston Oilers\\nTexas Rangers\\nSeattle Canucks\\n\\n   *The Norm Green Conference*\\nAlabama White Hawks\\nBiloxi Blues\\nTampa Bay Lightning\\nMiami Blades\\nHelsinki Jets        -You've heard them starting getting used to the anthem\\nMontreal Quebecois (sp?)                 -There will be no 'Canada'\\nAtlanta Devils\\nOrlando Penquins\\nKey West Islanders\\nHartford Whalers                        The Whalers will never move, huh?\\nPalm Beach Capitals\\n\\n  Now that the Anahaim team is becomming real I'm really beginning to believe\\nthe rest of the 'message'.  I'm sure the future will turn you into believers \\ntoo.  After 2000 the NHL will abandond ice-rinks.  It's so expensive to cool \\ndown the rinks in the subtropics and the locals hardly know what ice is \\nanyway.  NHL will become a roller skating hockey league.  That way it can \\ncreate more public interest in the game when local supporteres can play the \\ngame in their back yards !\"]\n",
      "New >>>\n",
      "nhl year\n",
      "\n",
      "get reliable source dream year ago initially think take strong drug\n",
      "\n",
      "realization begin\n",
      "\n",
      "league start direction\n",
      "\n",
      "walt disney conference anaheim mighty chipmunk change new la king hockey movie la flame\n",
      "\n",
      "see san jose shark san diego bruin tijuana red wing hockey team follow car industry\n",
      "\n",
      "dalla star houston oiler texas ranger seattle canuck\n",
      "\n",
      "norm green conference alabama white hawk biloxi blue tampa bay lightning miami blade helsinki jet hear start get anthem montreal quebecois sp\n",
      "\n",
      "canada atlanta devil orlando penquin key west islander hartford whaler whaler huh palm beach capital anahaim team becomm real\n",
      "\n",
      "begin believe rest message\n",
      "\n",
      "sure future turn believer\n",
      "\n",
      "nhl abandond ice rink\n",
      "\n",
      "expensive cool rink subtropic local\n",
      "\n",
      "hardly know ice\n",
      "\n",
      "nhl roller skate hockey league\n",
      "\n",
      "way create public interest game local supportere play game yard\n",
      "\n",
      "{' ', 'more', \"'m\", '2000', 'this', 'to', '   ', '...', 'no', 'it', 'each', '\\n\\n   ', 'many', '-franchise', '       ', 'too', '  ', '*', 'very', '.', 'these', 'its', '?', '-there', 'and', ',', 'seems', 'really', 'you', '-detroit', 'i', 'see', ')', 'into', 'become', 'had', 'never', 'back', 'now', 'down', 'move', 'will', 'name', 'from', 'their', \"-we've\", 'some', 'what', 'the', 'been', 'so', 'well', '        \\n', 'of', \"'\", 'after', 'anyway', \"-you've\", '                ', '                       ', \"'s\", '\\n', 'has', 'already', 'a', 'that', 'just', '                     ', '-', '                  ', 'them', 'when', '          \\n', 'in', 'although', 'be', '(', 'here', '\\n\\n  ', '!', 'can', 'used', 'is'}\n",
      "CPU times: user 145 ms, sys: 4 ms, total: 149 ms\n",
      "Wall time: 77.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 1 == 1:\n",
    "    removed_tokens = set()\n",
    "    print('Original >>>')\n",
    "    print(newsgroups_train.data[1:2])\n",
    "\n",
    "    print('New >>>')\n",
    "    for sentence in tqdm(lemmatized_sentence_corpus(line_sklearn_data(newsgroups_train.data[1:2]))):\n",
    "        print(sentence + '\\n')\n",
    "\n",
    "    print(removed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [03:59, 239.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "3808it [03:59, 15.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "7049it [03:59, 29.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "10410it [03:59, 43.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "13490it [03:59, 56.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "16557it [03:59, 69.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "20582it [03:59, 85.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "23888it [04:00, 99.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "27027it [04:00, 112.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "30535it [04:00, 127.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "34237it [04:00, 142.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "37924it [04:00, 157.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "41395it [04:00, 172.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "44794it [04:00, 186.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "48137it [04:00, 199.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "51430it [04:00, 213.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "54673it [04:01, 226.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "58015it [04:01, 240.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "61372it [04:01, 254.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "64936it [04:01, 269.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "68285it [04:01, 282.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "70883it [04:01, 293.46it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 22s, sys: 33 s, total: 6min 55s\n",
      "Wall time: 4min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 1 == 1:\n",
    "    with codecs.open(unigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "        for sentence in tqdm(lemmatized_sentence_corpus(line_sklearn_data(newsgroups_train.data))):\n",
    "            f.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_sentences = LineSentence(unigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "child able read endeavor inculcate child right reading scripture concentrate pleasant reading gloss bad one explain away unexplainable mystery\n",
      "\n",
      "circular argument self evdent fact truth unreason belief fear hell meat religion child eat day\n",
      "\n",
      "doubt course mean wrath sort child learn away brain matter concern god\n",
      "\n",
      "considerable effect child adult superstition teach nearly impossible remove\n",
      "\n",
      "lead ask theist truly objective question god hell heaven angel soul rest\n",
      "\n",
      "moment aside notion god\n",
      "\n",
      "exist look unbiased point view\n",
      "\n",
      "obviously theist somewhat especially present mythical god homeric roman egyptian etc\n",
      "\n",
      "aside assumption god existence question impartially\n",
      "\n",
      "stephen\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print a few example lemmatized sentences\n",
    "for unigram_sentence in it.islice(unigram_sentences, 230, 240):\n",
    "    print(' '.join(unigram_sentence))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_model_filepath = os.path.join(intermediate_directory, 'bigram_model_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.62 s, sys: 27.8 ms, total: 1.65 s\n",
      "Wall time: 1.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute modeling yourself.\n",
    "if 1 == 1:\n",
    "    # gensim Phrases\n",
    "    # automatically detect common phrases – multi-word expressions / word n-grams – from a stream of sentences.\n",
    "    #\n",
    "    # example\n",
    "    # >>> sentences = Text8Corpus(datapath('testcorpus.txt'))     <- load training example data\n",
    "    # >>> phrases = Phrases(sentences, min_count=1, threshold=1)  <- train the Phrases model\n",
    "    # >>> phrases[[u'trees', u'graph', u'minors']]                <- apply trained model to sentence\n",
    "    # [u'trees_graph', u'minors']                                 <- identify phrases 'trees_graph'\n",
    "    #\n",
    "    # >>> phrases.add_vocab([[\"hello\", \"world\"], [\"meow\"]])       <- update model with new sentences\n",
    "    # \n",
    "    # >>> bigram = Phraser(phrases)                               <- construct faster model (this is only an wrapper)\n",
    "    # >>> bigram[[u'trees', u'graph', u'minors']]                 <- apply model to sentence\n",
    "    # [u'trees_graph', u'minors']\n",
    "    #\n",
    "    bigram_model = Phrases(unigram_sentences)\n",
    "    bigram_model.save(bigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the finished model from disk\n",
    "bigram_model = Phrases.load(bigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare to apply the trained Phrases model to the unigram lemmatized sentences\n",
    "bigram_sentences_filepath = os.path.join(intermediate_directory,\n",
    "                                         'bigram_sentences_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A/anaconda/envs/fastai-cpu/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "\n",
      "\n",
      "1955it [00:00, 19420.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "3848it [00:00, 19152.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "5593it [00:00, 18596.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "7311it [00:00, 18221.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "9132it [00:00, 18223.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "10786it [00:00, 17944.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "12556it [00:00, 17908.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "14169it [00:00, 17639.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "16100it [00:00, 17825.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "18280it [00:01, 18223.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "20159it [00:01, 18258.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "22015it [00:01, 17862.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "23884it [00:01, 17924.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "25671it [00:01, 17926.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "27596it [00:01, 18011.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "29617it [00:01, 18147.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "31498it [00:01, 18143.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "33358it [00:01, 18066.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "35187it [00:01, 18078.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "37048it [00:02, 18100.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "38876it [00:02, 18087.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "40709it [00:02, 18101.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "42529it [00:02, 18100.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "44345it [00:02, 18066.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "46138it [00:02, 17954.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "47873it [00:02, 17772.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "49496it [00:02, 17450.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "50974it [00:02, 17345.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "52445it [00:03, 16968.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "53770it [00:03, 16662.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "55236it [00:03, 16601.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "56525it [00:03, 16344.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "57730it [00:03, 15986.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "58810it [00:03, 15658.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "59790it [00:03, 15462.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "60748it [00:04, 15137.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "61612it [00:04, 14938.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.04 s, sys: 57.2 ms, total: 4.1 s\n",
      "Wall time: 4.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 1 == 1:\n",
    "    with codecs.open(bigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "        for unigram_sentence in tqdm(unigram_sentences):\n",
    "            bigram_sentence = ' '.join(bigram_model[unigram_sentence])\n",
    "            f.write(bigram_sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "child able read endeavor inculcate child right reading scripture concentrate pleasant reading gloss bad one explain away unexplainable mystery\n",
      "\n",
      "circular argument self evdent fact truth unreason belief fear hell meat religion child eat day\n",
      "\n",
      "doubt course mean wrath sort child learn away brain matter concern god\n",
      "\n",
      "considerable effect child adult superstition teach nearly impossible remove\n",
      "\n",
      "lead ask theist truly objective question god hell heaven angel soul rest\n",
      "\n",
      "moment aside notion god\n",
      "\n",
      "exist look unbiased point_view\n",
      "\n",
      "obviously theist somewhat especially present mythical god homeric roman egyptian etc\n",
      "\n",
      "aside assumption god existence question impartially\n",
      "\n",
      "stephen\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print out a few examples of bigram on lemmatized sentences.\n",
    "# note that vice_versa, original_question, etc. are now considered as phrases\n",
    "bigram_sentences = LineSentence(bigram_sentences_filepath)\n",
    "\n",
    "for bigram_sentence in it.islice(bigram_sentences, 230, 240):\n",
    "    print(' '.join(bigram_sentence))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_model_filepath = os.path.join(intermediate_directory,\n",
    "                                      'trigram_model_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.66 s, sys: 20.8 ms, total: 1.68 s\n",
      "Wall time: 1.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute modeling yourself.\n",
    "if 1 == 1:\n",
    "    trigram_model = Phrases(bigram_sentences)\n",
    "    trigram_model.save(trigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the finished model from disk\n",
    "trigram_model = Phrases.load(trigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.phrases.Phrases"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trigram_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_sentences_filepath = os.path.join(intermediate_directory,\n",
    "                                          'trigram_sentences_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A/anaconda/envs/fastai-cpu/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "\n",
      "\n",
      "1838it [00:00, 18131.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "3660it [00:00, 18231.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "5447it [00:00, 18094.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "7228it [00:00, 18031.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "9192it [00:00, 18331.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "11099it [00:00, 18472.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "12878it [00:00, 18367.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "14569it [00:00, 17966.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "16323it [00:00, 17919.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "18623it [00:01, 18424.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "20621it [00:01, 18562.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "22526it [00:01, 18536.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "24408it [00:01, 18463.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "26253it [00:01, 18454.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "28248it [00:01, 18552.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "30326it [00:01, 18690.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "32271it [00:01, 18724.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "34212it [00:01, 18661.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "36105it [00:01, 18632.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "38062it [00:02, 18680.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "39955it [00:02, 18660.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "41829it [00:02, 18661.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "43702it [00:02, 18655.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "45700it [00:02, 18709.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "47605it [00:02, 18648.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "49466it [00:02, 18609.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "51291it [00:02, 18558.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "53088it [00:02, 18460.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "54895it [00:02, 18450.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "56656it [00:03, 18412.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "58408it [00:03, 18329.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "60116it [00:03, 18277.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "61612it [00:03, 18248.19it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.34 s, sys: 84.8 ms, total: 3.43 s\n",
      "Wall time: 3.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 1 == 1:\n",
    "    with codecs.open(trigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "        for bigram_sentence in tqdm(bigram_sentences):\n",
    "            trigram_sentence = ' '.join(trigram_model[bigram_sentence])\n",
    "            f.write(trigram_sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_sentences = LineSentence(trigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "child able read endeavor inculcate child right reading scripture concentrate pleasant reading gloss bad one explain away unexplainable mystery\n",
      "\n",
      "circular argument self evdent fact truth unreason belief fear hell meat religion child eat day\n",
      "\n",
      "doubt course mean wrath sort child learn away brain matter concern god\n",
      "\n",
      "considerable effect child adult superstition teach nearly impossible remove\n",
      "\n",
      "lead ask theist truly objective question god hell heaven angel soul rest\n",
      "\n",
      "moment aside notion god\n",
      "\n",
      "exist look unbiased point_view\n",
      "\n",
      "obviously theist somewhat especially present mythical god homeric roman egyptian etc\n",
      "\n",
      "aside assumption god existence question impartially\n",
      "\n",
      "stephen\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print a few trigram examples on lemmatized sentences\n",
    "# note that bigram words are still there but we see a few trigrams now.\n",
    "# like san_jose_sharks, learn_how_to\n",
    "for trigram_sentence in it.islice(trigram_sentences, 230, 240):\n",
    "    print(' '.join(trigram_sentence))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_reviews_filepath = os.path.join(intermediate_directory,\n",
    "                                        'trigram_transformed_reviews_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# NOT NEED TO RUN THIS AS WE HAVE DONE ALL STEPS HERE BEFORE\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 0 == 1:\n",
    "    with codecs.open(trigram_reviews_filepath, 'w', encoding='utf_8') as f:\n",
    "        for parsed_review in nlp.pipe(line_review(review_txt_filepath),\n",
    "                                      batch_size=10000, n_threads=4):\n",
    "            # lemmatize the text, removing punctuation and whitespace\n",
    "            unigram_review = [token.lemma_ for token in parsed_review\n",
    "                              if not punct_space(token)]\n",
    "            \n",
    "            # apply the first-order and second-order phrase models\n",
    "            bigram_review = bigram_model[unigram_review]\n",
    "            trigram_review = trigram_model[bigram_review]\n",
    "            \n",
    "            # remove any remaining stopwords\n",
    "            trigram_review = [term for term in trigram_review\n",
    "                              if term not in spacy.en.STOPWORDS]\n",
    "            \n",
    "            # write the transformed review as a line in the new file\n",
    "            trigram_review = u' '.join(trigram_review)\n",
    "            f.write(trigram_review + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "\n",
      "Transformed:\n",
      "\n",
      "norm green conference alabama white hawk biloxi blue tampa_bay_lightning miami blade helsinki jet hear start get anthem montreal quebecois sp\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print('Original:' + u'\\n')\n",
    "#\n",
    "# for review in it.islice(line_review(review_txt_filepath), 11, 12):\n",
    "#    print(review)\n",
    "trigram_reviews_filepath = trigram_sentences_filepath\n",
    "\n",
    "print('----' + u'\\n')\n",
    "print('Transformed:' + u'\\n')\n",
    "\n",
    "with codecs.open(trigram_reviews_filepath, encoding='utf_8') as f:\n",
    "    for review in it.islice(f, 11, 12):\n",
    "        print(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LDA to find the topic most-associated with each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_dictionary_filepath = os.path.join(intermediate_directory,\n",
    "                                           'trigram_dict_all.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "4671it [00:00, 46096.13it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ./trigram_sentences_all.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "8946it [00:00, 44515.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "12994it [00:00, 43165.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "17221it [00:00, 42632.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "21418it [00:00, 42762.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "25709it [00:00, 42794.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "30181it [00:00, 43063.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "34660it [00:00, 43254.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "39398it [00:00, 43739.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "44234it [00:01, 44192.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "49083it [00:01, 44564.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "53788it [00:01, 44782.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "58405it [00:01, 44546.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "61612it [00:01, 44482.13it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.46 s, sys: 13.1 ms, total: 1.48 s\n",
      "Wall time: 1.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to learn the dictionary yourself.\n",
    "if 1 == 1:\n",
    "    print('loading data from {}'.format(trigram_reviews_filepath))\n",
    "    trigram_reviews = LineSentence(trigram_reviews_filepath)\n",
    "\n",
    "    # learn the dictionary by iterating over all of the reviews\n",
    "    trigram_dictionary = Dictionary(tqdm(trigram_reviews))\n",
    "    \n",
    "    # filter tokens that are very rare or too common from\n",
    "    # the dictionary (filter_extremes) and reassign integer ids (compactify)\n",
    "    trigram_dictionary.filter_extremes(no_below=10, no_above=0.4)\n",
    "    trigram_dictionary.compactify()\n",
    "\n",
    "    trigram_dictionary.save(trigram_dictionary_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the finished dictionary from disk\n",
    "trigram_dictionary = Dictionary.load(trigram_dictionary_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.corpora.dictionary.Dictionary'> 348201 61612 364908\n"
     ]
    }
   ],
   "source": [
    "# This module implements the concept of a Dictionary – a mapping between words and their integer ids.\n",
    "# ops supported: \n",
    "# - doc2bow\n",
    "# - doc2idx\n",
    "# - filter_extremes\n",
    "# - filter_n_most_frequent\n",
    "# - compactify\n",
    "#\n",
    "# compactify: Assign new word ids to all words, shrinking any gaps.\n",
    "print(type(trigram_dictionary), trigram_dictionary.num_nnz, trigram_dictionary.num_docs, trigram_dictionary.num_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_bow_filepath = os.path.join(intermediate_directory,\n",
    "                                    'trigram_bow_corpus_all.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigram_bow_generator(filepath):\n",
    "    \"\"\"\n",
    "    generator function to read reviews from a file\n",
    "    and yield a bag-of-words representation\n",
    "    \"\"\"\n",
    "    \n",
    "    for review in LineSentence(filepath):\n",
    "        yield trigram_dictionary.doc2bow(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.24 s, sys: 58.9 ms, total: 2.3 s\n",
      "Wall time: 2.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to build the bag-of-words corpus yourself.\n",
    "if 1 == 1:\n",
    "    # generate bag-of-words representations for\n",
    "    # all reviews and save them as a matrix\n",
    "    MmCorpus.serialize(trigram_bow_filepath,\n",
    "                       trigram_bow_generator(trigram_reviews_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the finished bag-of-words corpus from disk\n",
    "trigram_bow_corpus = MmCorpus(trigram_bow_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.corpora.mmcorpus.MmCorpus'>\n"
     ]
    }
   ],
   "source": [
    "# Corpus in the Matrix Market format.\n",
    "print(type(trigram_bow_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hmmm']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_index = 0\n",
    "[trigram_dictionary[id] for (id, bow_count) in trigram_bow_corpus[document_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cost',\n",
       " 'good',\n",
       " 'low',\n",
       " 'performance',\n",
       " 'player',\n",
       " 'radio',\n",
       " 'recall',\n",
       " 'system',\n",
       " 'tube',\n",
       " 'unit',\n",
       " 'vacuum']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_index = 1\n",
    "[trigram_dictionary.id2token[id] for (id, bow_count) in trigram_bow_corpus[document_index]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 LDA implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_filepath = os.path.join(intermediate_directory, 'lda_model_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.9 s, sys: 734 ms, total: 16.7 s\n",
      "Wall time: 20.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to train the LDA model yourself.\n",
    "if 1 == 1:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "\n",
    "        # workers => sets the parallelism, and should be\n",
    "        # set to your number of physical cores minus one\n",
    "        lda = LdaMulticore(trigram_bow_corpus,\n",
    "                           num_topics=7,\n",
    "                           id2word=trigram_dictionary,\n",
    "                           workers=3)\n",
    "\n",
    "    lda.save(lda_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the finished LDA model from disk\n",
    "lda = LdaMulticore.load(lda_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nasa id is 1827, topics is []\n",
      "space id is 172, topics is []\n",
      "good id is 2, topics is [(5, 0.012163425)]\n"
     ]
    }
   ],
   "source": [
    "# find out topics by word\n",
    "for test_word in ['nasa', 'space', 'good', 'go']:\n",
    "    test_id = trigram_dictionary.token2id[test_word]\n",
    "    test_topics = lda.get_term_topics(test_id)\n",
    "    print('{} id is {}, topics is {}'.format(trigram_dictionary[test_id], test_id, test_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_topic(topic_number, topn=25):\n",
    "    \"\"\"\n",
    "    accept a user-supplied topic number and\n",
    "    print out a formatted list of the top terms\n",
    "    \"\"\"\n",
    "        \n",
    "    print('{:20} {}'.format('term', 'frequency') + '\\n')\n",
    "\n",
    "    for term, frequency in lda.show_topic(topic_number, topn=50):\n",
    "        print('{:20} {:.3f}'.format(term, round(frequency, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term                 frequency\n",
      "\n",
      "go                   0.011\n",
      "file                 0.009\n",
      "new                  0.008\n",
      "say                  0.007\n",
      "work                 0.007\n",
      "god                  0.007\n",
      "run                  0.006\n",
      "like                 0.006\n",
      "question             0.005\n",
      "help                 0.005\n",
      "john                 0.005\n",
      "good                 0.005\n",
      "people               0.004\n",
      "great                0.004\n",
      "send                 0.004\n",
      "lead                 0.004\n",
      "time                 0.004\n",
      "man                  0.004\n",
      "x                    0.004\n",
      "subject              0.004\n",
      "right                0.004\n",
      "start                0.004\n",
      "use                  0.004\n",
      "mac                  0.004\n",
      "appear               0.004\n",
      "keyboard             0.003\n",
      "able                 0.003\n",
      "look                 0.003\n",
      "line                 0.003\n",
      "try                  0.003\n",
      "come                 0.003\n",
      "change               0.003\n",
      "post                 0.003\n",
      "couple               0.003\n",
      "know                 0.003\n",
      "application          0.003\n",
      "agree                0.003\n",
      "version              0.003\n",
      "find                 0.003\n",
      "build                0.003\n",
      "give                 0.003\n",
      "maybe                0.003\n",
      "reference            0.003\n",
      "drive                0.003\n",
      "need                 0.003\n",
      "long                 0.003\n",
      "lot                  0.003\n",
      "take                 0.002\n",
      "end                  0.002\n",
      "earth                0.002\n"
     ]
    }
   ],
   "source": [
    "explore_topic(6, topn=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 pyLDAVis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDAvis_data_filepath = os.path.join(intermediate_directory, 'ldavis_prepared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 s, sys: 181 ms, total: 20.2 s\n",
      "Wall time: 22.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/fastai-cpu/lib/python3.6/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pickle\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim.prepare(lda, trigram_bow_corpus,\n",
    "                                              trigram_dictionary)\n",
    "\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el802711402767692085046047230137\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el802711402767692085046047230137_data = {\"mdsDat\": {\"x\": [0.011625802214157282, -0.01360316116890131, 0.1078276089842428, -0.16885212241718928, 0.021488426103509123, 0.08991846063553864, -0.04840501435135702], \"y\": [-0.0019363868190479024, 0.0011440810535315532, -0.04889459151030435, -0.08716965393760184, -0.0522826140853832, 0.0062913116248574505, 0.1828478536739483], \"topics\": [1, 2, 3, 4, 5, 6, 7], \"cluster\": [1, 1, 1, 1, 1, 1, 1], \"Freq\": [16.090303421020508, 15.463953018188477, 14.710365295410156, 14.364107131958008, 13.55023193359375, 13.053533554077148, 12.767511367797852]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\"], \"Freq\": [2251.0, 1032.0, 527.0, 1241.0, 788.0, 642.0, 1653.0, 278.0, 869.0, 564.0, 1284.0, 523.0, 804.0, 275.0, 871.0, 362.0, 273.0, 1753.0, 344.0, 598.0, 1550.0, 498.0, 962.0, 1438.0, 229.0, 520.0, 482.0, 719.0, 415.0, 1111.0, 102.79486083984375, 42.507728576660156, 41.953941345214844, 38.47986602783203, 52.304115295410156, 32.45267105102539, 30.058000564575195, 28.88666343688965, 28.82674789428711, 28.737224578857422, 27.23642921447754, 27.0731143951416, 49.29448318481445, 24.199222564697266, 22.922788619995117, 22.925838470458984, 21.816999435424805, 21.535423278808594, 21.402952194213867, 21.358745574951172, 20.512252807617188, 58.88859176635742, 20.03680992126465, 19.89143180847168, 20.70347023010254, 18.665529251098633, 18.58565330505371, 18.130287170410156, 17.922574996948242, 16.80278205871582, 34.73223114013672, 27.261730194091797, 81.87873077392578, 48.35542297363281, 39.13849639892578, 169.33023071289062, 59.408206939697266, 28.614824295043945, 29.43657875061035, 64.84425354003906, 59.755409240722656, 762.0687866210938, 328.4663391113281, 381.4069519042969, 489.7079162597656, 149.2404327392578, 38.366416931152344, 315.05706787109375, 400.9650573730469, 153.48602294921875, 327.8230285644531, 314.49755859375, 95.01918029785156, 119.74267578125, 47.20615768432617, 191.8732147216797, 134.3274383544922, 180.1108856201172, 189.9952392578125, 507.76361083984375, 183.29318237304688, 319.8497009277344, 187.3640594482422, 362.06842041015625, 157.93505859375, 406.62164306640625, 109.82559967041016, 111.388916015625, 277.2760009765625, 268.06353759765625, 149.77117919921875, 239.14927673339844, 235.11557006835938, 121.18669891357422, 151.25830078125, 183.04379272460938, 155.2023162841797, 166.03623962402344, 174.337646484375, 157.7375030517578, 154.11656188964844, 28.19133758544922, 27.81936264038086, 27.633312225341797, 27.046977996826172, 25.244253158569336, 36.436893463134766, 24.23285484313965, 23.79633140563965, 23.714763641357422, 33.008609771728516, 22.882469177246094, 22.017208099365234, 21.736753463745117, 21.549531936645508, 20.951078414916992, 23.00213623046875, 20.51433563232422, 20.026227951049805, 19.521944046020508, 19.11247444152832, 18.864503860473633, 18.655630111694336, 18.505783081054688, 19.201618194580078, 17.33338737487793, 16.99925422668457, 16.691762924194336, 16.75567626953125, 16.276269912719727, 15.522522926330566, 31.136350631713867, 43.41533279418945, 38.26659393310547, 49.067359924316406, 63.21154022216797, 27.858604431152344, 274.0482482910156, 74.77548217773438, 35.80358123779297, 546.2246704101562, 58.71402359008789, 32.132938385009766, 108.64936065673828, 57.24350357055664, 552.8772583007812, 89.69720458984375, 65.19377136230469, 32.3170280456543, 38.187217712402344, 46.562110900878906, 46.955257415771484, 40.067047119140625, 71.85521697998047, 193.7280731201172, 141.9523162841797, 604.0046997070312, 57.10607147216797, 78.1051254272461, 158.00633239746094, 154.6708526611328, 368.67059326171875, 72.6659927368164, 106.14238739013672, 174.61875915527344, 169.423828125, 329.86328125, 352.9066162109375, 336.17828369140625, 124.89889526367188, 195.79905700683594, 423.5530090332031, 169.0924530029297, 85.11739349365234, 92.39460754394531, 185.26268005371094, 146.7849578857422, 294.3597106933594, 135.18307495117188, 267.1471252441406, 105.00642395019531, 97.10269165039062, 139.21047973632812, 177.5435028076172, 162.81533813476562, 202.14898681640625, 143.80117797851562, 143.05613708496094, 141.8213348388672, 125.5418701171875, 66.49605560302734, 63.087158203125, 103.56632232666016, 30.613744735717773, 29.642452239990234, 29.034778594970703, 26.226274490356445, 25.289583206176758, 23.498695373535156, 33.21112060546875, 22.56315040588379, 22.193628311157227, 21.959430694580078, 21.635662078857422, 21.48904037475586, 21.104707717895508, 20.822059631347656, 20.711267471313477, 142.45260620117188, 28.53980255126953, 18.73748016357422, 18.68044090270996, 17.73784065246582, 27.225187301635742, 16.922758102416992, 16.94171905517578, 16.27818489074707, 16.071950912475586, 15.778717041015625, 15.272499084472656, 23.02560806274414, 32.512386322021484, 84.4665756225586, 86.2144775390625, 29.10024642944336, 38.19927978515625, 47.72690200805664, 77.03634643554688, 50.41120147705078, 131.4713592529297, 1501.3363037109375, 279.28387451171875, 49.94272232055664, 147.99903869628906, 35.73117446899414, 92.38885498046875, 54.90127182006836, 56.63018798828125, 48.302120208740234, 771.589599609375, 70.05760955810547, 60.07804489135742, 182.5690155029297, 141.81875610351562, 90.89739990234375, 242.684814453125, 65.62928771972656, 77.26107025146484, 168.89100646972656, 121.8607406616211, 280.3668212890625, 161.9403533935547, 116.57180786132812, 309.81597900390625, 190.73538208007812, 183.20477294921875, 99.3644027709961, 291.65484619140625, 94.38465881347656, 207.36944580078125, 309.82525634765625, 146.6116180419922, 339.0914306640625, 334.22601318359375, 167.72393798828125, 187.21299743652344, 113.168212890625, 164.01551818847656, 152.0625, 120.11566925048828, 135.77406311035156, 129.19068908691406, 153.000244140625, 132.15383911132812, 145.52980041503906, 132.3462677001953, 35.90390396118164, 28.452041625976562, 43.27525329589844, 25.80445098876953, 33.388092041015625, 24.333209991455078, 23.15875244140625, 23.031923294067383, 21.63387107849121, 21.70796012878418, 20.780702590942383, 47.13059616088867, 19.264678955078125, 17.809782028198242, 17.63444709777832, 16.4166259765625, 16.182205200195312, 16.014249801635742, 35.10030746459961, 15.315118789672852, 14.499905586242676, 18.230731964111328, 14.156805992126465, 21.730371475219727, 23.50502586364746, 13.480352401733398, 14.24163818359375, 42.16997146606445, 29.044687271118164, 12.300385475158691, 82.36837768554688, 53.02549362182617, 60.05751419067383, 72.11933898925781, 32.39083480834961, 73.211669921875, 65.14490509033203, 80.13349151611328, 31.735898971557617, 82.16332244873047, 87.5301742553711, 679.5896606445312, 152.23397827148438, 78.83399200439453, 34.10612106323242, 136.7788543701172, 45.333152770996094, 40.93149185180664, 268.1461486816406, 88.65839385986328, 62.138729095458984, 127.33841705322266, 195.09414672851562, 43.77116394042969, 106.83455657958984, 49.91069030761719, 117.90084838867188, 174.6925811767578, 498.5782775878906, 89.62117767333984, 538.89794921875, 171.5790252685547, 85.83973693847656, 119.25713348388672, 116.69854736328125, 72.07598114013672, 170.92811584472656, 142.17759704589844, 149.51776123046875, 251.13052368164062, 275.70147705078125, 118.71731567382812, 112.44673156738281, 137.16221618652344, 235.17591857910156, 225.50778198242188, 122.95488739013672, 167.81698608398438, 155.42984008789062, 100.1232681274414, 108.52088165283203, 152.68186950683594, 139.0915069580078, 130.8799285888672, 114.28226470947266, 116.61577606201172, 90.23590850830078, 57.231502532958984, 40.24365997314453, 36.9232063293457, 28.616817474365234, 28.180538177490234, 29.219032287597656, 23.732486724853516, 21.574947357177734, 21.306644439697266, 33.09072494506836, 20.5642032623291, 20.591516494750977, 20.332069396972656, 20.25324821472168, 19.60745620727539, 19.029760360717773, 18.58269500732422, 18.536401748657227, 18.4544734954834, 18.389925003051758, 36.82806396484375, 16.549304962158203, 16.363845825195312, 41.84062576293945, 15.01449966430664, 22.017019271850586, 43.781314849853516, 13.163047790527344, 22.340171813964844, 39.74881362915039, 54.131683349609375, 74.55472564697266, 37.91020584106445, 61.206485748291016, 32.94488525390625, 187.79339599609375, 31.432558059692383, 78.0045394897461, 69.63265991210938, 365.6067810058594, 40.779720306396484, 74.87963104248047, 121.78430938720703, 119.3039779663086, 42.15192794799805, 443.1862487792969, 66.58343505859375, 144.6927947998047, 47.41929244995117, 59.84080123901367, 138.11544799804688, 64.19913482666016, 166.60560607910156, 156.3628692626953, 322.35137939453125, 161.1772003173828, 84.1030044555664, 87.5257797241211, 188.23428344726562, 277.9908447265625, 106.46748352050781, 176.40792846679688, 267.94525146484375, 168.10360717773438, 136.405029296875, 190.4705810546875, 254.8609619140625, 148.02731323242188, 277.1294250488281, 248.88723754882812, 150.7625732421875, 156.25469970703125, 177.45669555664062, 130.01824951171875, 186.73403930664062, 119.20204162597656, 126.89547729492188, 163.02276611328125, 159.69729614257812, 148.64111328125, 132.37657165527344, 129.7135009765625, 51.029029846191406, 38.9386100769043, 34.75127410888672, 31.126543045043945, 32.08235549926758, 28.369844436645508, 43.3175048828125, 28.291841506958008, 26.791336059570312, 23.655969619750977, 23.1208553314209, 22.226655960083008, 21.371641159057617, 21.00287628173828, 20.552730560302734, 20.5567626953125, 29.601234436035156, 19.762868881225586, 19.36245346069336, 19.31680679321289, 18.451393127441406, 17.66130256652832, 16.765338897705078, 35.551414489746094, 30.484764099121094, 16.15056800842285, 15.955556869506836, 15.604286193847656, 15.149571418762207, 22.94905662536621, 46.930419921875, 27.679443359375, 40.40348434448242, 39.62784194946289, 23.735427856445312, 28.25389862060547, 48.27560806274414, 220.8112030029297, 33.0735969543457, 102.88799285888672, 33.80624008178711, 104.06937408447266, 32.15306854248047, 123.10541534423828, 113.9519271850586, 408.5200500488281, 67.71646881103516, 327.72076416015625, 191.16732788085938, 144.96421813964844, 110.45274353027344, 40.75039291381836, 224.94900512695312, 81.72288513183594, 264.8728332519531, 115.29888153076172, 243.20494079589844, 98.34768676757812, 38.288177490234375, 117.66971588134766, 197.2660675048828, 180.68978881835938, 106.98149108886719, 294.29681396484375, 59.7841796875, 83.47059631347656, 262.09356689453125, 239.194091796875, 96.2998046875, 91.2555923461914, 85.51800537109375, 162.87440490722656, 257.09490966796875, 154.4016571044922, 112.2313003540039, 214.3861541748047, 171.89779663085938, 115.34609985351562, 153.34632873535156, 151.2016143798828, 156.36822509765625, 123.4471206665039, 156.5544891357422, 135.848876953125, 133.13504028320312, 117.72210693359375, 127.55310821533203, 64.3149185180664, 31.556110382080078, 30.67633056640625, 24.82801628112793, 24.66287612915039, 24.583314895629883, 22.84556770324707, 102.34322357177734, 19.742963790893555, 266.9149475097656, 18.97437286376953, 18.92343521118164, 37.86714172363281, 106.09587097167969, 25.002941131591797, 21.268901824951172, 16.74404525756836, 16.53249168395996, 37.60837173461914, 16.25137710571289, 38.20893096923828, 15.496152877807617, 15.389998435974121, 15.397997856140137, 62.76813888549805, 13.997804641723633, 13.444570541381836, 26.517539978027344, 13.290512084960938, 13.115328788757324, 20.27210235595703, 15.011807441711426, 55.23963165283203, 56.45731735229492, 28.035921096801758, 229.11032104492188, 424.7391052246094, 34.18278884887695, 30.461240768432617, 49.42185592651367, 55.036033630371094, 113.0695571899414, 41.40657043457031, 43.166568756103516, 58.56412124633789, 128.50392150878906, 115.69297790527344, 67.95523834228516, 38.204856872558594, 150.70936584472656, 60.186580657958984, 115.00491333007812, 134.79876708984375, 40.97121810913086, 158.78855895996094, 74.04496002197266, 95.84295654296875, 97.12842559814453, 73.32687377929688, 173.64093017578125, 467.6905517578125, 197.01177978515625, 72.05868530273438, 172.40708923339844, 297.4096984863281, 167.70555114746094, 139.71484375, 160.60467529296875, 135.73635864257812, 103.0394058227539, 124.89289855957031, 184.6514892578125, 115.32394409179688, 152.36268615722656, 144.61097717285156, 146.27735900878906, 165.8628692626953, 148.15440368652344, 132.22715759277344, 126.62590789794922, 113.14493560791016], \"Term\": [\"x\", \"need\", \"thank\", \"year\", \"window\", \"drive\", \"know\", \"pt\", \"game\", \"file\", \"work\", \"sure\", \"want\", \"adaptec\", \"go\", \"true\", \"yes\", \"good\", \"color\", \"read\", \"like\", \"see\", \"run\", \"time\", \"john\", \"write\", \"win\", \"believe\", \"idea\", \"problem\", \"skepticism_chastity_intellect\", \"factory\", \"mariner\", \"oriole\", \"cheer\", \"cdc\", \"gr\", \"muslim\", \"micro\", \"particle\", \"technical_support\", \"initially\", \"long_time\", \"original_poster\", \"voting\", \"congress\", \"gun\", \"reardon\", \"accuse\", \"packet\", \"sci\", \"tape_backup\", \"up\", \"sincerely\", \"get_rid\", \"administrator\", \"melrose\", \"bsd\", \"judgment\", \"assistance\", \"transfer_datum\", \"staff\", \"chi\", \"channel\", \"confirm\", \"deal\", \"resurrection\", \"royal\", \"absolute_truth\", \"raise\", \"buf\", \"year\", \"see\", \"read\", \"want\", \"hell\", \"expose\", \"write\", \"believe\", \"mention\", \"point\", \"information\", \"flame\", \"hi\", \"echo\", \"jesus\", \"bible\", \"book\", \"ask\", \"think\", \"end\", \"try\", \"different\", \"problem\", \"talk\", \"good\", \"hard\", \"instead\", \"get\", \"find\", \"place\", \"like\", \"know\", \"offer\", \"question\", \"people\", \"follow\", \"new\", \"time\", \"team\", \"need\", \"heal\", \"plastic\", \"afternoon\", \"accelerate\", \"distinguish\", \"hmmm\", \"gc\", \"mydisplay\", \"crater\", \"hm\", \"strict\", \"bellow\", \"keenan\", \"organ\", \"desert\", \"desk\", \"growth\", \"gainey\", \"xpert\", \"xremote\", \"rash\", \"county\", \"separation\", \"sander\", \"technician\", \"viking\", \"interleave\", \"sect\", \"permission\", \"macinnis\", \"jupiter\", \"starter\", \"red_sox\", \"extreme\", \"pointer\", \"invoke\", \"color\", \"pit\", \"hypothesis\", \"window\", \"nl\", \"shop\", \"chicago\", \"fpu\", \"game\", \"al\", \"factor\", \"maxtor\", \"dan\", \"louis\", \"success\", \"galaxy\", \"difficult\", \"let\", \"address\", \"time\", \"app\", \"city\", \"experience\", \"sun\", \"run\", \"dma\", \"free\", \"display\", \"add\", \"system\", \"get\", \"find\", \"nasa\", \"base\", \"use\", \"card\", \"fix\", \"window_manager\", \"set\", \"example\", \"think\", \"machine\", \"like\", \"position\", \"net\", \"post\", \"people\", \"way\", \"x\", \"team\", \"include\", \"try\", \"thing\", \"candida\", \"smartdrive\", \"shameful_surrender_soon\", \"oct\", \"vitamin\", \"speculation\", \"nubus_card\", \"florida\", \"danger\", \"xmu\", \"violate\", \"surveillance\", \"kovalev\", \"man_page\", \"mediocre\", \"motif_application\", \"gps\", \"balance\", \"thank_advance\", \"seagate\", \"loose\", \"balloon\", \"quiet\", \"ramsey\", \"mary_shafer_nasa_ame\", \"nov\", \"acceptance\", \"canon_law\", \"ah\", \"inflammatory\", \"preferably\", \"cf\", \"det\", \"son\", \"measurement\", \"sh\", \"allen\", \"buffalo\", \"lib\", \"dr\", \"x\", \"true\", \"babylon\", \"la\", \"tar\", \"character\", \"community\", \"x_x_x\", \"spin\", \"know\", \"manual\", \"wire\", \"wrong\", \"c\", \"font\", \"player\", \"obvious\", \"title\", \"church\", \"love\", \"team\", \"word\", \"child\", \"program\", \"note\", \"course\", \"pass\", \"way\", \"xt\", \"give\", \"people\", \"list\", \"use\", \"good\", \"case\", \"god\", \"value\", \"look\", \"right\", \"lose\", \"set\", \"x_x\", \"time\", \"follow\", \"like\", \"say\", \"timing\", \"harddisk\", \"architecture\", \"dram\", \"mitchell\", \"mcsorley\", \"minimize\", \"tuesday\", \"esdi\", \"influenza\", \"access_time\", \"noonan\", \"neuron\", \"jeremy\", \"auto\", \"help_greatly_appreciate\", \"barrier\", \"rebuild\", \"consideration\", \"beg\", \"single_drive\", \"iron\", \"hash\", \"tippett\", \"accelerated\", \"square\", \"qi\", \"prize\", \"employee\", \"applelink\", \"billion\", \"yeah\", \"phi\", \"video_card\", \"emphasize\", \"recommend\", \"min\", \"dc\", \"turbo\", \"faster\", \"hiv\", \"need\", \"mb\", \"quadra\", \"rating\", \"scsi\", \"floppy_drive\", \"trial\", \"win\", \"ide\", \"phone\", \"university\", \"require\", \"united_state\", \"cheap\", \"h\", \"major\", \"buy\", \"work\", \"controller\", \"like\", \"monitor\", \"bus\", \"answer\", \"general\", \"e\", \"support\", \"high\", \"christian\", \"people\", \"use\", \"article\", \"board\", \"reason\", \"think\", \"know\", \"allow\", \"get\", \"system\", \"science\", \"entry\", \"time\", \"program\", \"thing\", \"set\", \"say\", \"ld\", \"darren\", \"transmit\", \"lewi\", \"sacred\", \"invent\", \"iici\", \"sinus\", \"sens\", \"uart\", \"jon\", \"benchmark\", \"open_window\", \"ac\", \"supplement\", \"london\", \"icccm\", \"wright\", \"trinity\", \"tech_support\", \"last\", \"lindro\", \"sudden\", \"flip\", \"matthew\", \"email_response\", \"crystal\", \"symbol\", \"kinda\", \"reichel\", \"lucky\", \"mr\", \"tor\", \"thank_help\", \"msdo\", \"ref\", \"john\", \"fleury\", \"l\", \"definitely\", \"file\", \"bunch\", \"external\", \"couple\", \"agree\", \"responsible\", \"go\", \"okay\", \"appear\", \"doug\", \"teaching\", \"keyboard\", \"store\", \"lead\", \"subject\", \"new\", \"man\", \"david\", \"xterm\", \"help\", \"say\", \"reference\", \"great\", \"god\", \"send\", \"able\", \"question\", \"run\", \"mac\", \"work\", \"like\", \"start\", \"right\", \"people\", \"line\", \"good\", \"version\", \"change\", \"time\", \"x\", \"use\", \"look\", \"try\", \"lssu\", \"billboard\", \"mtl\", \"cy_young\", \"wrist\", \"france\", \"help_appreciate\", \"reston\", \"gut\", \"luther\", \"highlight\", \"makefile\", \"ivy_league_champ\", \"thruster\", \"american_league\", \"larson\", \"rev\", \"hack\", \"scholar\", \"know_truth\", \"infect\", \"repeatedly\", \"decnet\", \"hull\", \"consortium\", \"iivx\", \"tolerate\", \"austin\", \"bread\", \"float\", \"vaccine\", \"infallible\", \"imake\", \"practical\", \"xtpointer\", \"nope\", \"far_know\", \"yes\", \"usage\", \"patch\", \"william\", \"oh\", \"arrogance\", \"tape\", \"w\", \"drive\", \"letter\", \"sure\", \"widget\", \"paul\", \"cable\", \"shark\", \"idea\", \"publish\", \"mean\", \"mission\", \"play\", \"t\", \"sp\", \"s\", \"x_x\", \"little\", \"certain\", \"come\", \"plug\", \"ibm\", \"thing\", \"include\", \"guy\", \"mind\", \"minute\", \"case\", \"think\", \"day\", \"power\", \"good\", \"year\", \"happen\", \"way\", \"program\", \"time\", \"space\", \"use\", \"work\", \"problem\", \"old\", \"x\", \"apostle\", \"holy_spirit\", \"candida_albican\", \"fortunately\", \"pill\", \"profit\", \"thank_lot\", \"gordon_bank\", \"phenylalanine\", \"pt\", \"xvt\", \"tract\", \"hope_help\", \"power_play_scorer_g\", \"consecration\", \"virginia\", \"draw_line\", \"crack\", \"nubus\", \"persuade\", \"neely\", \"etc_etc\", \"neurologist\", \"manson\", \"nj\", \"linden\", \"tablet\", \"johansson\", \"ronn\", \"fiber\", \"gonorrhea\", \"hewlett_packard\", \"proton\", \"jeff\", \"offend\", \"adaptec\", \"thank\", \"fujitsu\", \"scanner\", \"tb\", \"km\", \"os\", \"edm\", \"adjust\", \"suffer\", \"appreciate\", \"chance\", \"rom\", \"juneau\", \"live\", \"sound_like\", \"e_mail\", \"goal\", \"macintosh\", \"week\", \"van\", \"video\", \"score\", \"share\", \"bit\", \"good\", \"line\", \"brown\", \"driver\", \"problem\", \"probably\", \"software\", \"tell\", \"hear\", \"speed\", \"available\", \"work\", \"old\", \"program\", \"god\", \"system\", \"use\", \"know\", \"run\", \"get\", \"come\"], \"Total\": [2251.0, 1032.0, 527.0, 1241.0, 788.0, 642.0, 1653.0, 278.0, 869.0, 564.0, 1284.0, 523.0, 804.0, 275.0, 871.0, 362.0, 273.0, 1753.0, 344.0, 598.0, 1550.0, 498.0, 962.0, 1438.0, 229.0, 520.0, 482.0, 719.0, 415.0, 1111.0, 104.04635620117188, 43.363441467285156, 42.81138229370117, 39.330440521240234, 53.584293365478516, 33.30571746826172, 30.921049118041992, 29.73824119567871, 29.681598663330078, 29.59156608581543, 28.09522247314453, 27.92890739440918, 51.00196838378906, 25.050302505493164, 23.773515701293945, 23.77734375, 22.674962997436523, 22.389446258544922, 22.25478744506836, 22.216259002685547, 21.36386489868164, 61.336883544921875, 20.89139175415039, 20.742778778076172, 21.589710235595703, 19.518136978149414, 19.447111129760742, 18.98302459716797, 18.772899627685547, 17.65333366394043, 36.62409973144531, 28.777889251708984, 88.75450134277344, 52.35395050048828, 42.31414794921875, 197.91635131835938, 67.34676361083984, 30.683927536010742, 31.665849685668945, 75.46965026855469, 69.48886108398438, 1241.060791015625, 498.0023193359375, 598.7059326171875, 804.5040893554688, 210.8299102783203, 43.21343994140625, 520.5303344726562, 719.8009033203125, 232.65870666503906, 611.643798828125, 595.5419311523438, 136.5379180908203, 184.179443359375, 56.136112213134766, 350.6672058105469, 226.14370727539062, 340.167724609375, 374.3651428222656, 1538.7633056640625, 380.2142333984375, 873.6576538085938, 401.4302673339844, 1111.6435546875, 350.09710693359375, 1753.0081787109375, 191.92999267578125, 201.2089385986328, 1047.2132568359375, 1006.8943481445312, 401.79949951171875, 1550.2843017578125, 1653.965087890625, 254.4667205810547, 540.9266357421875, 1176.1287841796875, 603.0439453125, 841.4739379882812, 1438.4771728515625, 734.3861083984375, 1032.569580078125, 29.036970138549805, 28.665109634399414, 28.479045867919922, 27.901079177856445, 26.089717864990234, 37.693904876708984, 25.076961517333984, 24.641088485717773, 24.5625057220459, 34.223941802978516, 23.733434677124023, 22.86174774169922, 22.583566665649414, 22.397985458374023, 21.798545837402344, 23.932844161987305, 21.35802459716797, 20.871320724487305, 20.366138458251953, 19.958118438720703, 19.70791244506836, 19.500638961791992, 19.350317001342773, 20.128578186035156, 18.177345275878906, 17.8441104888916, 17.535608291625977, 17.611019134521484, 17.120952606201172, 16.366966247558594, 33.03635787963867, 46.52201843261719, 40.91755294799805, 53.06999969482422, 70.30075073242188, 29.944049835205078, 344.7176208496094, 86.2142333984375, 39.15924835205078, 788.7284545898438, 68.30248260498047, 35.35284423828125, 136.93939208984375, 67.26900482177734, 869.6427612304688, 116.76477813720703, 81.47985076904297, 35.815406799316406, 43.725948333740234, 55.5163688659668, 56.50800704956055, 46.67624282836914, 96.39151000976562, 330.5855712890625, 224.6680450439453, 1438.4771728515625, 72.89488220214844, 111.8645248413086, 282.6982421875, 279.52850341796875, 962.069091796875, 105.47769165039062, 178.86578369140625, 357.751220703125, 359.4478759765625, 934.9146728515625, 1047.2132568359375, 1006.8943481445312, 234.9643096923828, 465.95831298828125, 1608.3258056640625, 391.5466613769531, 135.5345001220703, 158.10995483398438, 553.3704223632812, 390.1359558105469, 1538.7633056640625, 356.5176086425781, 1550.2843017578125, 215.35955810546875, 193.60276794433594, 556.5752563476562, 1176.1287841796875, 920.3099365234375, 2251.4072265625, 734.3861083984375, 767.9385986328125, 873.6576538085938, 878.91845703125, 67.35179138183594, 63.956382751464844, 105.5674057006836, 31.468795776367188, 30.491662979125977, 29.882720947265625, 27.080595016479492, 26.15389060974121, 24.347145080566406, 34.437931060791016, 23.412553787231445, 23.044118881225586, 22.8083553314209, 22.486650466918945, 22.337871551513672, 21.962875366210938, 21.67167091369629, 21.55990219116211, 148.57357788085938, 29.79509735107422, 19.588661193847656, 19.52965545654297, 18.58568572998047, 28.553781509399414, 17.772397994995117, 17.79254150390625, 17.12886619567871, 16.925180435180664, 16.628990173339844, 16.122554779052734, 24.379905700683594, 34.63039779663086, 92.05233001708984, 94.66458892822266, 31.024995803833008, 41.419281005859375, 52.729312896728516, 88.64795684814453, 56.339839935302734, 158.47061157226562, 2251.4072265625, 362.83648681640625, 56.01040267944336, 182.9851531982422, 39.35401916503906, 115.27902221679688, 65.2745361328125, 67.81815338134766, 56.50050354003906, 1653.965087890625, 92.39411926269531, 76.44789123535156, 306.9361572265625, 224.1206817626953, 128.40798950195312, 473.47076416015625, 86.38394927978516, 109.57418823242188, 323.0787658691406, 218.9917449951172, 734.3861083984375, 337.10748291015625, 208.87754821777344, 954.7769775390625, 449.7193298339844, 434.9742431640625, 165.00393676757812, 920.3099365234375, 154.33370971679688, 559.3673706054688, 1176.1287841796875, 341.5718688964844, 1608.3258056640625, 1753.0081787109375, 549.497314453125, 860.3223876953125, 231.65008544921875, 705.4756469726562, 586.6298828125, 306.97418212890625, 553.3704223632812, 446.3839416503906, 1438.4771728515625, 603.0439453125, 1550.2843017578125, 830.6052856445312, 36.75306701660156, 29.297958374023438, 44.68229675292969, 26.651735305786133, 34.53984069824219, 25.203245162963867, 24.00891876220703, 23.88018798828125, 22.4794979095459, 22.565282821655273, 21.627103805541992, 49.11201095581055, 20.11174964904785, 18.655559539794922, 18.484455108642578, 17.263402938842773, 17.03046989440918, 16.8642635345459, 37.010841369628906, 16.16222381591797, 15.3580322265625, 19.316274642944336, 15.004875183105469, 23.0479679107666, 24.943056106567383, 14.327247619628906, 15.157444953918457, 44.96778106689453, 31.011127471923828, 13.147221565246582, 88.20109558105469, 57.11134719848633, 64.93032836914062, 79.04071044921875, 35.11835479736328, 81.8914794921875, 72.99642944335938, 92.42059326171875, 34.99390411376953, 98.18595123291016, 106.05332946777344, 1032.569580078125, 206.65687561035156, 98.48433685302734, 38.45069885253906, 196.33935546875, 54.64228820800781, 48.4737434387207, 482.775146484375, 125.75305938720703, 81.1415023803711, 202.77154541015625, 348.8653259277344, 52.68804931640625, 167.2098388671875, 62.556819915771484, 191.51234436035156, 322.348388671875, 1284.4337158203125, 136.38165283203125, 1550.2843017578125, 358.3719177246094, 134.64170837402344, 224.6189422607422, 234.61573791503906, 108.92875671386719, 525.8468627929688, 381.4251708984375, 423.2244873046875, 1176.1287841796875, 1608.3258056640625, 274.70391845703125, 247.8227996826172, 401.2198486328125, 1538.7633056640625, 1653.965087890625, 348.9709167480469, 1047.2132568359375, 934.9146728515625, 202.80494689941406, 300.0168762207031, 1438.4771728515625, 954.7769775390625, 878.91845703125, 553.3704223632812, 830.6052856445312, 91.08869934082031, 58.0810546875, 41.090518951416016, 37.77126693725586, 29.46417999267578, 29.025375366210938, 30.14482307434082, 24.581518173217773, 22.421833038330078, 22.1532039642334, 34.421630859375, 21.409332275390625, 21.438005447387695, 21.177581787109375, 21.098756790161133, 20.45281219482422, 19.876068115234375, 19.429662704467773, 19.381372451782227, 19.29899787902832, 19.237016677856445, 38.61855697631836, 17.395387649536133, 17.210268020629883, 44.10005187988281, 15.859705924987793, 23.272459030151367, 46.46621322631836, 14.009451866149902, 23.781478881835938, 42.476356506347656, 58.27103042602539, 81.81277465820312, 41.00416564941406, 68.19353485107422, 35.7128791809082, 229.01414489746094, 34.025917053222656, 95.85057830810547, 85.74170684814453, 564.8953247070312, 47.21855545043945, 96.53544616699219, 175.77647399902344, 172.79835510253906, 50.51412582397461, 871.69970703125, 88.35118865966797, 237.56195068359375, 58.61885452270508, 78.72056579589844, 235.03585815429688, 86.82797241210938, 324.0599060058594, 307.62518310546875, 841.4739379882812, 323.5331726074219, 130.6627655029297, 139.23272705078125, 443.19122314453125, 830.6052856445312, 191.95071411132812, 424.1199645996094, 860.3223876953125, 432.1679992675781, 308.7804260253906, 540.9266357421875, 962.069091796875, 381.16925048828125, 1284.4337158203125, 1550.2843017578125, 529.80712890625, 586.6298828125, 1176.1287841796875, 489.8997802734375, 1753.0081787109375, 395.4730224609375, 505.62664794921875, 1438.4771728515625, 2251.4072265625, 1608.3258056640625, 705.4756469726562, 873.6576538085938, 51.8897705078125, 39.78567886352539, 35.60234832763672, 31.994468688964844, 33.03093338012695, 29.217205047607422, 44.630470275878906, 29.15010643005371, 27.637924194335938, 24.505374908447266, 23.96868324279785, 23.072128295898438, 22.222801208496094, 21.849971771240234, 21.400978088378906, 21.405920028686523, 30.838420867919922, 20.608543395996094, 20.20948600769043, 20.163135528564453, 19.30242156982422, 18.512802124023438, 17.614961624145508, 37.36505126953125, 32.085330963134766, 16.99913787841797, 16.80105972290039, 16.452804565429688, 15.995304107666016, 24.233911514282227, 49.78446960449219, 29.285688400268555, 42.93661117553711, 42.132144927978516, 25.186965942382812, 30.208566665649414, 53.53875732421875, 273.3454284667969, 35.924949645996094, 125.1355209350586, 37.08616256713867, 127.72560119628906, 35.18043518066406, 159.26544189453125, 147.84368896484375, 642.2308349609375, 83.06004333496094, 523.0302124023438, 284.60198974609375, 206.58657836914062, 153.0924072265625, 47.0512580871582, 415.75982666015625, 114.96466827392578, 535.337158203125, 184.99220275878906, 497.289794921875, 155.36782836914062, 43.86979675292969, 209.44871520996094, 446.3839416503906, 410.2731628417969, 191.70150756835938, 947.0426025390625, 82.43840026855469, 139.26223754882812, 878.91845703125, 767.9385986328125, 178.00149536132812, 166.21568298339844, 156.89442443847656, 549.497314453125, 1538.7633056640625, 550.9346313476562, 303.599609375, 1753.0081787109375, 1241.060791015625, 355.8179626464844, 920.3099365234375, 954.7769775390625, 1438.4771728515625, 477.178955078125, 1608.3258056640625, 1284.4337158203125, 1111.6435546875, 402.478759765625, 2251.4072265625, 65.17529296875, 32.41089630126953, 31.535198211669922, 25.683372497558594, 25.518064498901367, 25.440473556518555, 23.701990127563477, 106.66055297851562, 20.597490310668945, 278.9561767578125, 19.831256866455078, 19.778362274169922, 39.58674240112305, 110.97073364257812, 26.212879180908203, 22.33517074584961, 17.602453231811523, 17.386972427368164, 39.58341598510742, 17.10675048828125, 40.227909088134766, 16.350109100341797, 16.245193481445312, 16.257299423217773, 66.3092041015625, 14.850909233093262, 14.299697875976562, 28.22511100769043, 14.147504806518555, 13.96960163116455, 21.641271591186523, 15.990865707397461, 59.71651840209961, 61.57194137573242, 30.431236267089844, 275.4073181152344, 527.469970703125, 37.48625564575195, 33.22159194946289, 56.38636779785156, 63.319557189941406, 138.34756469726562, 46.858768463134766, 49.22336959838867, 69.26130676269531, 167.92333984375, 150.94644165039062, 84.2081527709961, 43.221290588378906, 219.82321166992188, 74.57337188720703, 166.12315368652344, 211.29417419433594, 48.04625701904297, 267.85614013671875, 102.16177368164062, 143.98602294921875, 155.07876586914062, 107.01516723632812, 371.52197265625, 1753.0081787109375, 489.8997802734375, 107.06704711914062, 446.5550537109375, 1111.6435546875, 438.20220947265625, 390.0279541015625, 546.4987182617188, 446.8692321777344, 239.54855346679688, 451.2801513671875, 1284.4337158203125, 402.478759765625, 954.7769775390625, 860.3223876953125, 934.9146728515625, 1608.3258056640625, 1653.965087890625, 962.069091796875, 1047.2132568359375, 947.0426025390625], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.8149000406265259, 1.8070000410079956, 1.8066999912261963, 1.8050999641418457, 1.8028000593185425, 1.8009999990463257, 1.7985999584197998, 1.7978999614715576, 1.797700047492981, 1.797700047492981, 1.7958999872207642, 1.795799970626831, 1.7928999662399292, 1.7924000024795532, 1.7905000448226929, 1.7905000448226929, 1.7884000539779663, 1.788100004196167, 1.7878999710083008, 1.787600040435791, 1.7862999439239502, 1.7862000465393066, 1.7851999998092651, 1.784999966621399, 1.784999966621399, 1.7822999954223633, 1.781599998474121, 1.781000018119812, 1.7805999517440796, 1.7776000499725342, 1.773900032043457, 1.7727999687194824, 1.7462999820709229, 1.747499942779541, 1.748900055885315, 1.6710000038146973, 1.7015000581741333, 1.757099986076355, 1.753999948501587, 1.6751999855041504, 1.6759999990463257, 1.3393000364303589, 1.4107999801635742, 1.3760000467300415, 1.3305000066757202, 1.4815000295639038, 1.7079999446868896, 1.3249000310897827, 1.2418999671936035, 1.4110000133514404, 1.2032999992370605, 1.1885000467300415, 1.464400053024292, 1.396399974822998, 1.6536999940872192, 1.2239999771118164, 1.3061000108718872, 1.191100001335144, 1.1486999988555908, 0.7182000279426575, 1.0973000526428223, 0.8220999836921692, 1.065000057220459, 0.7052000164985657, 1.030900001525879, 0.36570000648498535, 1.2687000036239624, 1.2355999946594238, 0.49810001254081726, 0.503600001335144, 0.8400999903678894, -0.0421999990940094, -0.12389999628067017, 1.0851000547409058, 0.5526999831199646, -0.0333000011742115, 0.46970000863075256, 0.20399999618530273, -0.2833999991416931, 0.2888999879360199, -0.07509999722242355, 1.8371000289916992, 1.8366999626159668, 1.8365000486373901, 1.8356000185012817, 1.8336999416351318, 1.8327000141143799, 1.8323999643325806, 1.8317999839782715, 1.8315000534057617, 1.8305000066757202, 1.8301000595092773, 1.8289999961853027, 1.8284000158309937, 1.8279999494552612, 1.8270000219345093, 1.8270000219345093, 1.8264000415802002, 1.8252999782562256, 1.8243000507354736, 1.8234000205993652, 1.8229000568389893, 1.8223999738693237, 1.8220000267028809, 1.8194999694824219, 1.819100022315979, 1.8181999921798706, 1.8172999620437622, 1.8169000148773193, 1.816100001335144, 1.8136999607086182, 1.8073999881744385, 1.7975000143051147, 1.7997000217437744, 1.7882000207901, 1.7604000568389893, 1.7944999933242798, 1.6371999979019165, 1.7243000268936157, 1.7770999670028687, 1.4993000030517578, 1.715399980545044, 1.7711999416351318, 1.635200023651123, 1.705299973487854, 1.413699984550476, 1.6029000282287598, 1.6437000036239624, 1.7639000415802002, 1.7311999797821045, 1.6907999515533447, 1.68149995803833, 1.7139999866485596, 1.5729000568389893, 1.332200050354004, 1.4075000286102295, 0.9988999962806702, 1.6225999593734741, 1.5074000358581543, 1.2848999500274658, 1.274899959564209, 0.9075000286102295, 1.49399995803833, 1.3447999954223633, 1.149399995803833, 1.1145000457763672, 0.8248999714851379, 0.7789999842643738, 0.7696999907493591, 1.2346999645233154, 0.9997000098228455, 0.5324000120162964, 1.0269999504089355, 1.4014999866485596, 1.3293999433517456, 0.7724000215530396, 0.8891000151634216, 0.2126999944448471, 0.8968999981880188, 0.10830000042915344, 1.1483999490737915, 1.1765999794006348, 0.48080000281333923, -0.02410000003874302, 0.13459999859333038, -0.5436000227928162, 0.2361000031232834, 0.18619999289512634, 0.048500001430511475, -0.07940000295639038, 1.9038000106811523, 1.902899980545044, 1.8975000381469727, 1.8890999555587769, 1.8883999586105347, 1.8877999782562256, 1.884600043296814, 1.8830000162124634, 1.881100058555603, 1.8803000450134277, 1.879699945449829, 1.878999948501587, 1.8787000179290771, 1.878000020980835, 1.8779000043869019, 1.8767999410629272, 1.8766000270843506, 1.8765000104904175, 1.874500036239624, 1.8736000061035156, 1.8722000122070312, 1.8722000122070312, 1.8698999881744385, 1.86899995803833, 1.8675999641418457, 1.8675999641418457, 1.8657000064849854, 1.86489999294281, 1.8640999794006348, 1.8624999523162842, 1.8595000505447388, 1.8535000085830688, 1.8306000232696533, 1.823099970817566, 1.8525999784469604, 1.8357000350952148, 1.8169000148773193, 1.7762000560760498, 1.805400013923645, 1.7297999858856201, 1.5113999843597412, 1.6548999547958374, 1.8020000457763672, 1.7043999433517456, 1.8200000524520874, 1.6952999830245972, 1.7436000108718872, 1.736299991607666, 1.7597999572753906, 1.154099941253662, 1.6398999691009521, 1.6756999492645264, 1.3970999717712402, 1.4589999914169312, 1.5710999965667725, 1.2482999563217163, 1.641800045967102, 1.567199945449829, 1.2680000066757202, 1.3305000066757202, 0.9537000060081482, 1.18340003490448, 1.333400011062622, 0.791100025177002, 1.058899998664856, 1.051900029182434, 1.4093999862670898, 0.7674999833106995, 1.4249000549316406, 0.9243000149726868, 0.5825999975204468, 1.0707999467849731, 0.35989999771118164, 0.25929999351501465, 0.7299000024795532, 0.39160001277923584, 1.2002999782562256, 0.4577000141143799, 0.5665000081062317, 0.9782999753952026, 0.5116000175476074, 0.6766999959945679, -0.32429999113082886, 0.3986000120639801, -0.44920000433921814, 0.07989999651908875, 1.917099952697754, 1.9111000299453735, 1.908400058746338, 1.9081000089645386, 1.906499981880188, 1.9053000211715698, 1.9043999910354614, 1.9042999744415283, 1.9020999670028687, 1.9017000198364258, 1.9005000591278076, 1.8992999792099, 1.8974000215530396, 1.8940000534057617, 1.893399953842163, 1.8901000022888184, 1.889299988746643, 1.888700008392334, 1.8874000310897827, 1.8866000175476074, 1.8828999996185303, 1.882599949836731, 1.8823000192642212, 1.881600022315979, 1.881100058555603, 1.8795000314712524, 1.878100037574768, 1.8761999607086182, 1.874899983406067, 1.873900055885315, 1.871999979019165, 1.8661999702453613, 1.8624000549316406, 1.8487999439239502, 1.8595999479293823, 1.8284000158309937, 1.8265999555587769, 1.7977999448776245, 1.8427000045776367, 1.7623000144958496, 1.7484999895095825, 1.5220999717712402, 1.6347999572753906, 1.717900037765503, 1.8205000162124634, 1.5789999961853027, 1.7537000179290771, 1.771299958229065, 1.3523999452590942, 1.59089994430542, 1.6735999584197998, 1.4752000570297241, 1.3592000007629395, 1.7549999952316284, 1.4924999475479126, 1.7145999670028687, 1.455299973487854, 1.3278000354766846, 0.9940999746322632, 1.5205999612808228, 0.8838000297546387, 1.2038999795913696, 1.4903000593185425, 1.3072999715805054, 1.2421000003814697, 1.527500033378601, 0.8166999816894531, 0.9535999894142151, 0.8999999761581421, 0.39640000462532043, 0.17679999768733978, 1.1015000343322754, 1.1502000093460083, 0.8671000003814697, 0.06199999898672104, -0.05209999904036522, 0.8973000049591064, 0.10939999669790268, 0.1462000012397766, 1.2345999479293823, 0.9235000014305115, -0.30250000953674316, 0.014100000262260437, 0.035999998450279236, 0.36309999227523804, -0.02280000038444996, 1.989400029182434, 1.9839999675750732, 1.9779000282287598, 1.976099967956543, 1.969599962234497, 1.9692000150680542, 1.9675999879837036, 1.9636000394821167, 1.9602999687194824, 1.9598000049591064, 1.9593000411987305, 1.9585000276565552, 1.9585000276565552, 1.9579999446868896, 1.957900047302246, 1.9565999507904053, 1.955299973487854, 1.954200029373169, 1.954200029373169, 1.9539999961853027, 1.9536999464035034, 1.951300024986267, 1.9488999843597412, 1.9483000040054321, 1.9462000131607056, 1.944000005722046, 1.9433000087738037, 1.9392000436782837, 1.936400055885315, 1.9362000226974487, 1.9323999881744385, 1.9250999689102173, 1.905900001525879, 1.920300006866455, 1.8906999826431274, 1.9180999994277954, 1.8003000020980835, 1.9194999933242798, 1.7927000522613525, 1.7906999588012695, 1.5636999607086182, 1.8522000312805176, 1.7446999549865723, 1.6318000555038452, 1.6282999515533447, 1.8178000450134277, 1.3222999572753906, 1.71589994430542, 1.503000020980835, 1.7867000102996826, 1.7244999408721924, 1.4671000242233276, 1.6967999935150146, 1.3335000276565552, 1.322100043296814, 1.0392999649047852, 1.3020000457763672, 1.5582000017166138, 1.534600019454956, 1.1425000429153442, 0.90420001745224, 1.4093999862670898, 1.121500015258789, 0.8321999907493591, 1.0544999837875366, 1.1818000078201294, 0.9549999833106995, 0.6704000234603882, 1.052899956703186, 0.4652000069618225, 0.1695999950170517, 0.7419999837875366, 0.6758999824523926, 0.10750000178813934, 0.6722000241279602, -0.24060000479221344, 0.7994999885559082, 0.6162999868392944, -0.17870000004768372, -0.6473000049591064, -0.38260000944137573, 0.3255000114440918, 0.09139999747276306, 2.019399881362915, 2.0146000385284424, 2.011899948120117, 2.0085999965667725, 2.006999969482422, 2.006700038909912, 2.0062999725341797, 2.006200075149536, 2.005000114440918, 2.0007998943328857, 2.0000998973846436, 1.9988000392913818, 1.9970999956130981, 1.9966000318527222, 1.9957000017166138, 1.9955999851226807, 1.9952000379562378, 1.9941999912261963, 1.993299961090088, 1.9931999444961548, 1.9910000562667847, 1.9889999628067017, 1.9867000579833984, 1.9864000082015991, 1.9848999977111816, 1.9848999977111816, 1.9845000505447388, 1.983199954032898, 1.9817999601364136, 1.981600046157837, 1.9771000146865845, 1.979699969291687, 1.9752999544143677, 1.9747999906539917, 1.9767999649047852, 1.9692000150680542, 1.9326000213623047, 1.822700023651123, 1.9534000158309937, 1.840399980545044, 1.94350004196167, 1.8313000202178955, 1.9460999965667725, 1.7785999774932861, 1.7756999731063843, 1.5836999416351318, 1.8319000005722046, 1.568600058555603, 1.638200044631958, 1.6819000244140625, 1.7096999883651733, 1.892300009727478, 1.4219000339508057, 1.6948000192642212, 1.3324999809265137, 1.5633000135421753, 1.3207999467849731, 1.5787999629974365, 1.899999976158142, 1.4594999551773071, 1.219499945640564, 1.2160999774932861, 1.4528000354766846, 0.8673999905586243, 1.7148000001907349, 1.5241999626159668, 0.8260999917984009, 0.869700014591217, 1.4218000173568726, 1.4364999532699585, 1.4292999505996704, 0.8201000094413757, 0.2468000054359436, 0.7641000151634216, 1.0410000085830688, -0.06520000100135803, 0.059300001710653305, 0.909600019454956, 0.24410000443458557, 0.1932000070810318, -0.18299999833106995, 0.6840000152587891, -0.29339998960494995, -0.21040000021457672, -0.08609999716281891, 0.8068000078201294, -0.8346999883651733, 2.0450000762939453, 2.0315001010894775, 2.0306999683380127, 2.024399995803833, 2.024199962615967, 2.0239999294281006, 2.0215001106262207, 2.016900062561035, 2.015899896621704, 2.0141000747680664, 2.0141000747680664, 2.0141000747680664, 2.0139000415802, 2.0132999420166016, 2.010999917984009, 2.0092999935150146, 2.0083000659942627, 2.0078999996185303, 2.0071001052856445, 2.006999969482422, 2.0067999362945557, 2.0046000480651855, 2.004199981689453, 2.003999948501587, 2.0034000873565674, 1.9990999698638916, 1.9966000318527222, 1.99590003490448, 1.9958000183105469, 1.9952000379562378, 1.992900013923645, 1.9951000213623047, 1.980299949645996, 1.971500039100647, 1.9763000011444092, 1.8741999864578247, 1.841599941253662, 1.965999960899353, 1.971500039100647, 1.9263999462127686, 1.9180999994277954, 1.8565000295639038, 1.9345999956130981, 1.9270000457763672, 1.8904999494552612, 1.7906999588012695, 1.7922999858856201, 1.8437999486923218, 1.9349000453948975, 1.680799961090088, 1.8438999652862549, 1.690500020980835, 1.6088000535964966, 1.8990000486373901, 1.5354000329971313, 1.7364000082015991, 1.6512999534606934, 1.590399980545044, 1.6801999807357788, 1.2976000308990479, 0.7369999885559082, 1.1473000049591064, 1.6622999906539917, 1.106600046157837, 0.739799976348877, 1.0978000164031982, 1.0317000150680542, 0.8337000012397766, 0.8666999936103821, 1.2145999670028687, 0.7735999822616577, 0.11869999766349792, 0.8083999752998352, 0.22310000658035278, 0.2750000059604645, 0.20329999923706055, -0.2134999930858612, -0.35440000891685486, 0.07370000332593918, -0.0544000007212162, -0.06639999896287918], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.154699802398682, -7.037700176239014, -7.05079984664917, -7.13730001449585, -6.8302998542785645, -7.307600021362305, -7.384300231933594, -7.423999786376953, -7.42609977722168, -7.429200172424316, -7.482900142669678, -7.488900184631348, -6.889599800109863, -7.601099967956543, -7.655300140380859, -7.655200004577637, -7.704699993133545, -7.717700004577637, -7.723899841308594, -7.72599983215332, -7.76639986038208, -6.7118000984191895, -7.78980016708374, -7.797100067138672, -7.7571001052856445, -7.8607001304626465, -7.864999771118164, -7.889800071716309, -7.901400089263916, -7.96589994430542, -7.239799976348877, -7.481900215148926, -6.382199764251709, -6.90880012512207, -7.120299816131592, -5.655600070953369, -6.703000068664551, -7.433499813079834, -7.405200004577637, -6.6153998374938965, -6.697199821472168, -4.151400089263916, -4.993000030517578, -4.843599796295166, -4.593599796295166, -5.781899929046631, -7.140200138092041, -5.0346999168396, -4.793499946594238, -5.753799915313721, -4.994900226593018, -5.036399841308594, -6.23330020904541, -6.002099990844727, -6.9328999519348145, -5.530600070953369, -5.8871002197265625, -5.593800067901611, -5.54040002822876, -4.557400226593018, -5.576300144195557, -5.019599914550781, -5.5543999671936035, -4.895599842071533, -5.725200176239014, -4.7795000076293945, -6.088500022888184, -6.074399948120117, -5.162399768829346, -5.196199893951416, -5.778299808502197, -5.310299873352051, -5.327300071716309, -5.990099906921387, -5.768400192260742, -5.577700138092041, -5.742700099945068, -5.67519998550415, -5.626399993896484, -5.726500034332275, -5.74970006942749, -7.408699989318848, -7.421999931335449, -7.428699970245361, -7.450099945068359, -7.519100189208984, -7.152100086212158, -7.559999942779541, -7.578199863433838, -7.581600189208984, -7.250899791717529, -7.617300033569336, -7.655900001525879, -7.668700218200684, -7.6774001121521, -7.70550012588501, -7.612100124359131, -7.726600170135498, -7.750699996948242, -7.776199817657471, -7.797399997711182, -7.810400009155273, -7.821599960327148, -7.829599857330322, -7.792699813842773, -7.895100116729736, -7.9145002365112305, -7.932799816131592, -7.928999900817871, -7.958000183105469, -8.005399703979492, -7.309299945831299, -6.976900100708008, -7.103099822998047, -6.854499816894531, -6.601200103759766, -7.420599937438965, -5.134399890899658, -6.433199882507324, -7.1697001457214355, -4.444699764251709, -6.675000190734863, -7.2778000831604, -6.059599876403809, -6.700399875640869, -4.432600021362305, -6.251299858093262, -6.570400238037109, -7.27209997177124, -7.105199813842773, -6.906899929046631, -6.898499965667725, -7.057199954986572, -6.473100185394287, -5.481299877166748, -5.792200088500977, -4.344099998474121, -6.7027997970581055, -6.389699935913086, -5.685100078582764, -5.706399917602539, -4.837800025939941, -6.4618000984191895, -6.082900047302246, -5.585100173950195, -5.615300178527832, -4.948999881744385, -4.881499767303467, -4.930099964141846, -5.920199871063232, -5.470600128173828, -4.698999881744385, -5.617300033569336, -6.303699970245361, -6.22160005569458, -5.525899887084961, -5.758699893951416, -5.062900066375732, -5.841100215911865, -5.159900188446045, -6.093699932098389, -6.171899795532227, -5.811699867248535, -5.56850004196167, -5.655099868774414, -5.438700199127197, -5.779300212860107, -5.7845001220703125, -5.793099880218506, -5.91510009765625, -6.5005998611450195, -6.553199768066406, -6.057499885559082, -7.276299953460693, -7.308499813079834, -7.3292999267578125, -7.431000232696533, -7.467400074005127, -7.540800094604492, -7.194900035858154, -7.581399917602539, -7.5980000495910645, -7.60860013961792, -7.6234002113342285, -7.630199909210205, -7.6483001708984375, -7.6616997718811035, -7.667099952697754, -5.738699913024902, -7.346499919891357, -7.767199993133545, -7.770299911499023, -7.8221001625061035, -7.393599987030029, -7.869100093841553, -7.868000030517578, -7.907899856567383, -7.9207000732421875, -7.9390997886657715, -7.971700191497803, -7.561100006103516, -7.216100215911865, -6.26140022277832, -6.240900039672852, -7.327000141143799, -7.054900169372559, -6.832300186157227, -6.353499889373779, -6.777500152587891, -5.818999767303467, -3.3835999965667725, -5.065499782562256, -6.786900043487549, -5.7006001472473145, -7.121699810028076, -6.1717000007629395, -6.692200183868408, -6.661200046539307, -6.820300102233887, -4.049300193786621, -6.448400020599365, -6.602099895477295, -5.490600109100342, -5.743199825286865, -6.188000202178955, -5.205999851226807, -6.513700008392334, -6.350599765777588, -5.56850004196167, -5.894899845123291, -5.061699867248535, -5.610499858856201, -5.939199924468994, -4.9618000984191895, -5.446899890899658, -5.487199783325195, -6.098999977111816, -5.022200107574463, -6.150400161743164, -5.36329984664917, -4.961699962615967, -5.710000038146973, -4.871500015258789, -4.885900020599365, -5.575399875640869, -5.4654998779296875, -5.968900203704834, -5.597799777984619, -5.673500061035156, -5.909299850463867, -5.786799907684326, -5.83650016784668, -5.667300224304199, -5.813799858093262, -5.717400074005127, -5.812300205230713, -7.093100070953369, -7.325699806213379, -6.906400203704834, -7.423399925231934, -7.1656999588012695, -7.482100009918213, -7.531599998474121, -7.537099838256836, -7.599699974060059, -7.59630012512207, -7.639900207519531, -6.821000099182129, -7.715700149536133, -7.7941999435424805, -7.804100036621094, -7.8755998611450195, -7.889999866485596, -7.9004998207092285, -7.115699768066406, -7.945099830627441, -7.999800205230713, -7.7708001136779785, -8.023699760437012, -7.595200061798096, -7.51669979095459, -8.072699546813965, -8.017800331115723, -6.932199954986572, -7.305099964141846, -8.164299964904785, -6.262700080871582, -6.703199863433838, -6.57859992980957, -6.395599842071533, -7.196100234985352, -6.3805999755859375, -6.497300148010254, -6.290200233459473, -7.2164998054504395, -6.265200138092041, -6.202000141143799, -4.152400016784668, -5.648499965667725, -6.306600093841553, -7.144499778747559, -5.7555999755859375, -6.859899997711182, -6.961999893188477, -5.082399845123291, -6.1890997886657715, -6.544600009918213, -5.827099800109863, -5.4004998207092285, -6.894999980926514, -6.002699851989746, -6.763700008392334, -5.904099941253662, -5.510900020599365, -4.462200164794922, -6.178299903869629, -4.384399890899658, -5.528900146484375, -6.221499919891357, -5.8927001953125, -5.914299964904785, -6.396200180053711, -5.532700061798096, -5.716899871826172, -5.666500091552734, -5.1479997634887695, -5.054599761962891, -5.897200107574463, -5.951499938964844, -5.752799987792969, -5.213600158691406, -5.2555999755859375, -5.862100124359131, -5.55109977722168, -5.627699851989746, -6.067500114440918, -5.986999988555908, -5.645599842071533, -5.738800048828125, -5.799699783325195, -5.935299873352051, -5.91510009765625, -6.1132001876831055, -6.56850004196167, -6.9207000732421875, -7.006800174713135, -7.261600017547607, -7.2769999504089355, -7.240799903869629, -7.448800086975098, -7.544099807739258, -7.556600093841553, -7.116399765014648, -7.592100143432617, -7.590700149536133, -7.603400230407715, -7.6072998046875, -7.639699935913086, -7.669600009918213, -7.693399906158447, -7.695899963378906, -7.700300216674805, -7.703800201416016, -7.009300231933594, -7.809299945831299, -7.820499897003174, -6.881700038909912, -7.906599998474121, -7.523799896240234, -6.836400032043457, -8.038200378417969, -7.509200096130371, -6.933000087738037, -6.624199867248535, -6.304100036621094, -6.980400085449219, -6.501399993896484, -7.120800018310547, -5.380300045013428, -7.167799949645996, -6.258800029754639, -6.372399806976318, -4.714000225067139, -6.907400131225586, -6.299699783325195, -5.813399791717529, -5.833899974822998, -6.874300003051758, -4.521599769592285, -6.417200088500977, -5.640999794006348, -6.7565999031066895, -6.523900032043457, -5.6875, -6.45359992980957, -5.5, -5.563399791717529, -4.840000152587891, -5.533100128173828, -6.183599948883057, -6.143700122833252, -5.377900123596191, -4.98799991607666, -5.947800159454346, -5.442800045013428, -5.024799823760986, -5.491000175476074, -5.699999809265137, -5.366099834442139, -5.074900150299072, -5.618199825286865, -4.991099834442139, -5.098599910736084, -5.599899768829346, -5.5640997886657715, -5.4369001388549805, -5.747900009155273, -5.385900020599365, -5.834799766540527, -5.772200107574463, -5.521699905395508, -5.542300224304199, -5.614099979400635, -5.730000019073486, -5.75029993057251, -6.645899772644043, -6.916299819946289, -7.03000020980835, -7.140200138092041, -7.110000133514404, -7.232900142669678, -6.809700012207031, -7.2357001304626465, -7.290200233459473, -7.414599895477295, -7.4375, -7.4770002365112305, -7.516200065612793, -7.533599853515625, -7.555300235748291, -7.555099964141846, -7.190400123596191, -7.5945000648498535, -7.6149001121521, -7.617300033569336, -7.663099765777588, -7.706900119781494, -7.758900165557861, -7.007299900054932, -7.160999774932861, -7.796299934387207, -7.808499813079834, -7.830699920654297, -7.860300064086914, -7.445000171661377, -6.729599952697754, -7.257599830627441, -6.879300117492676, -6.89870023727417, -7.411300182342529, -7.236999988555908, -6.701300144195557, -5.181000232696533, -7.079500198364258, -5.9446001052856445, -7.057600021362305, -5.933199882507324, -7.107800006866455, -5.765200138092041, -5.84250020980835, -4.565700054168701, -6.3628997802734375, -4.786099910736084, -5.325099945068359, -5.601799964904785, -5.873700141906738, -6.870800018310547, -5.162399768829346, -6.174900054931641, -4.999000072479248, -5.830699920654297, -5.084400177001953, -5.989799976348877, -6.93310022354126, -5.810400009155273, -5.293700218200684, -5.381499767303467, -5.905600070953369, -4.893700122833252, -6.487500190734863, -6.153800010681152, -5.0096001625061035, -5.10099983215332, -6.010799884796143, -6.064599990844727, -6.129499912261963, -5.485300064086914, -5.028800010681152, -5.538700103759766, -5.857699871063232, -5.2104997634887695, -5.431399822235107, -5.8302998542785645, -5.545599937438965, -5.559599876403809, -5.526000022888184, -5.762400150299072, -5.524899959564209, -5.6666998863220215, -5.6869001388549805, -5.809899806976318, -5.729700088500977, -6.392300128936768, -7.104300022125244, -7.132599830627441, -7.344099998474121, -7.350800037384033, -7.354000091552734, -7.4274001121521, -5.927800178527832, -7.573299884796143, -4.969200134277344, -7.61299991607666, -7.615699768066406, -6.921999931335449, -5.8917999267578125, -7.337100028991699, -7.498899936676025, -7.738100051879883, -7.750800132751465, -6.928899765014648, -7.767899990081787, -6.913000106811523, -7.815499782562256, -7.822400093078613, -7.821899890899658, -6.4166998863220215, -7.917200088500977, -7.957499980926514, -7.278299808502197, -7.969099998474121, -7.9822998046875, -7.546899795532227, -7.847300052642822, -6.544400215148926, -6.522600173950195, -7.222599983215332, -5.1219000816345215, -4.5046000480651855, -7.024400234222412, -7.139699935913086, -6.655700206756592, -6.548099994659424, -5.828100204467773, -6.832699775695801, -6.790999889373779, -6.486000061035156, -5.700099945068359, -5.805200099945068, -6.337299823760986, -6.913099765777588, -5.540800094604492, -6.458700180053711, -5.811100006103516, -5.652299880981445, -6.843200206756592, -5.488500118255615, -6.251399993896484, -5.9934000968933105, -5.980100154876709, -6.261199951171875, -5.399099826812744, -4.408299922943115, -5.272799968719482, -6.278600215911865, -5.406199932098389, -4.861000061035156, -5.433899879455566, -5.616499900817871, -5.477200031280518, -5.645400047302246, -5.921000003814697, -5.728700160980225, -5.337600231170654, -5.8084001541137695, -5.529799938201904, -5.582099914550781, -5.5706000328063965, -5.444900035858154, -5.5578999519348145, -5.671599864959717, -5.714900016784668, -5.827400207519531]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 6, 7, 1, 2, 4, 5, 2, 4, 5, 3, 4, 1, 1, 2, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 5, 7, 1, 2, 2, 3, 4, 5, 6, 7, 3, 1, 2, 3, 6, 7, 1, 2, 3, 7, 1, 2, 3, 4, 5, 6, 7, 6, 1, 2, 3, 4, 5, 6, 7, 7, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 4, 1, 2, 3, 4, 5, 7, 3, 4, 2, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 6, 4, 1, 2, 3, 4, 5, 6, 7, 2, 3, 3, 3, 4, 1, 2, 3, 4, 5, 6, 7, 4, 1, 2, 3, 4, 5, 6, 7, 2, 5, 1, 2, 3, 4, 5, 6, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 6, 1, 2, 3, 4, 5, 7, 1, 1, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 3, 7, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 1, 2, 3, 5, 6, 7, 3, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 6, 1, 2, 3, 5, 6, 7, 1, 2, 3, 4, 6, 1, 7, 1, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4, 6, 7, 1, 2, 1, 7, 2, 4, 3, 6, 1, 2, 3, 4, 5, 6, 7, 2, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 7, 2, 4, 5, 6, 2, 3, 5, 6, 3, 5, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 4, 6, 1, 2, 3, 4, 5, 6, 7, 6, 2, 3, 4, 5, 6, 7, 2, 2, 2, 3, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 5, 7, 1, 2, 3, 4, 5, 6, 7, 2, 1, 2, 5, 6, 7, 1, 2, 5, 6, 7, 1, 2, 3, 5, 6, 7, 4, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 4, 5, 7, 1, 2, 4, 5, 6, 7, 1, 2, 5, 7, 1, 3, 4, 6, 7, 5, 4, 6, 1, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 4, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 3, 5, 6, 1, 2, 3, 5, 6, 2, 3, 6, 7, 1, 2, 4, 7, 1, 1, 2, 6, 7, 1, 2, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 3, 4, 5, 6, 7, 1, 5, 5, 6, 7, 1, 2, 4, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 5, 6, 7, 7, 1, 2, 3, 5, 7, 6, 1, 2, 3, 4, 5, 6, 7, 2, 7, 2, 1, 2, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 2, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 4, 7, 1, 2, 3, 4, 5, 6, 7, 1, 6, 7, 3, 1, 1, 2, 3, 4, 5, 6, 7, 2, 1, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 6, 7, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 4, 4, 2, 1, 2, 3, 4, 5, 6, 7, 1, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 5, 6, 4, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 6, 1, 4, 6, 1, 2, 2, 5, 7, 2, 7, 1, 6, 2, 3, 6, 1, 2, 3, 4, 5, 6, 7, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 5, 6, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 6, 6, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 1, 2, 3, 4, 5, 6, 7, 2, 5, 1, 2, 4, 4, 6, 3, 4, 7, 4, 1, 2, 3, 4, 5, 6, 7, 6, 7, 1, 2, 3, 4, 5, 7, 1, 5, 1, 1, 4, 7, 2, 3, 2, 1, 2, 3, 4, 5, 7, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 6, 3, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 7, 6, 5, 5, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 3, 5, 6, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 7, 3, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 5, 6, 7, 5, 1, 2, 1, 2, 3, 4, 5, 6, 7, 3, 1, 2, 3, 4, 5, 7, 1, 2, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 6, 1, 5, 7, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 6, 1, 2, 3, 4, 5, 6, 7, 3, 7, 1, 2, 3, 4, 5, 6, 1, 3, 2, 5, 2, 4, 2, 3, 4, 5, 6, 7, 4, 1, 2, 3, 4, 5, 6, 7, 3, 3, 1, 1, 2, 3, 4, 5, 6, 7, 1, 1, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 4, 1, 2, 3, 4, 5, 7, 3, 1, 3, 5, 7, 1, 5, 6, 7, 6, 1, 2, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 7, 1, 2, 3, 4, 5, 6, 7, 7, 4, 1, 2, 3, 4, 5, 6, 7, 1, 3, 4, 6, 7, 1, 2, 3, 4, 6, 1, 4, 5, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 3, 6, 7, 3, 2, 3, 4, 5, 6, 7, 3, 4, 7, 1, 2, 3, 4, 5, 6, 7, 3, 4, 5, 6, 7, 1, 4, 5, 6, 1, 2, 3, 4, 6, 7, 5, 2, 1, 1, 1, 3, 4, 5, 6, 7, 1, 1, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 2, 7, 7, 2, 3, 4, 5, 6, 7, 1, 3, 4, 6, 7, 7, 2, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 2, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 2, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 4, 5, 6, 7, 2, 6, 7, 3, 5, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 7, 1, 2, 3, 4, 5, 6, 7, 2, 7, 1, 4, 5, 6, 7, 1, 2, 3, 5, 6, 7, 4, 1, 2, 4, 7, 1, 2, 3, 4, 5, 6, 7, 3, 1, 2, 5, 7, 2, 3, 2, 4, 6, 1, 2, 3, 4, 5, 6, 7, 1, 1, 2, 3, 4, 5, 6, 7, 4, 1, 2, 4, 6, 2, 5, 7, 3, 5, 1, 2, 3, 4, 5, 6, 7, 1, 5, 6, 1, 2, 3, 4, 5, 6, 7, 2, 5, 6, 7, 6, 1, 3, 4, 7, 2, 6, 1, 2, 3, 4, 5, 6, 7, 2, 3, 6, 7, 7, 1, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 6, 7, 5, 2, 1, 2, 3, 4, 5, 6, 7, 1, 6, 7, 6, 1, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 3, 2, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 5, 2, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 7, 1, 3, 6, 1, 2, 3, 5, 7, 1, 2, 3, 6, 1, 2, 5, 1, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 4, 5, 6, 7, 1, 3, 5, 6, 1, 2, 3, 4, 5, 6, 7, 3, 1, 2, 3, 4, 5, 6, 7, 1, 3, 4, 1, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 6, 2, 5, 6, 7, 2, 1, 2, 3, 4, 5, 6, 7, 2, 5, 6, 7, 5, 2, 4, 7, 1, 2, 3, 4, 5, 6, 7, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 3, 3, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 7, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 7, 1, 2, 5, 3, 7, 1, 3, 4, 5, 6, 7, 1, 2, 5, 1, 2, 3, 4, 5, 6, 7, 5, 1, 2, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 3, 4, 5, 6, 3, 5, 7, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 6, 1, 2, 3, 4, 5, 6, 7, 4, 2, 4, 1, 2, 3, 4, 5, 6, 7, 6, 3, 4, 5, 6, 7, 1, 2, 5, 4, 5, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 4, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 3, 4, 6, 7, 2, 3, 7, 3, 1, 1, 2, 3, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 3, 7, 2, 2, 1, 3, 5, 7, 1, 2, 3, 4, 5, 6, 7, 6, 7, 7, 1, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7], \"Freq\": [0.07124803960323334, 0.19431284070014954, 0.00647709472104907, 0.03562401980161667, 0.44044241309165955, 0.09067932516336441, 0.1554502695798874, 0.9158130884170532, 0.03157976269721985, 0.03157976269721985, 0.9443948864936829, 0.9677044749259949, 0.962191641330719, 0.040091317147016525, 0.9340956807136536, 0.9710038304328918, 0.9436171650886536, 0.021785913035273552, 0.0181549284607172, 0.130715474486351, 0.8314957022666931, 0.19196107983589172, 0.47016552090644836, 0.058422934263944626, 0.019474312663078308, 0.07511520385742188, 0.08346133679151535, 0.1001536026597023, 0.16913843154907227, 0.6320436000823975, 0.10237325727939606, 0.022255055606365204, 0.008902022615075111, 0.017804045230150223, 0.04896112531423569, 0.04063110798597336, 0.04063110798597336, 0.04063110798597336, 0.8735687732696533, 0.9734535813331604, 0.9831790328025818, 0.011574184522032738, 0.1331031173467636, 0.06365801393985748, 0.6886639595031738, 0.017361275851726532, 0.08101928979158401, 0.9621750712394714, 0.03425690531730652, 0.7707803845405579, 0.03425690531730652, 0.03425690531730652, 0.13702762126922607, 0.01896478421986103, 0.01896478421986103, 0.9103096127510071, 0.05689435079693794, 0.0859670490026474, 0.15474069118499756, 0.1289505809545517, 0.3524649143218994, 0.12321943789720535, 0.06304249912500381, 0.09169818460941315, 0.9812635779380798, 0.16472341120243073, 0.031163889914751053, 0.017807936295866966, 0.5297861099243164, 0.013355952687561512, 0.19588731229305267, 0.04451984167098999, 0.9819672107696533, 0.781947910785675, 0.027436768636107445, 0.06859192252159119, 0.013718384318053722, 0.027436768636107445, 0.06859192252159119, 0.029465997591614723, 0.24835626780986786, 0.09260742366313934, 0.00420942809432745, 0.6103671193122864, 0.0084188561886549, 0.0084188561886549, 0.9127403497695923, 0.08932647854089737, 0.03573058918118477, 0.011910196393728256, 0.005955098196864128, 0.08932647854089737, 0.7682076692581177, 0.022380229085683823, 0.9623498320579529, 0.056849781423807144, 0.9095965027809143, 0.1929350048303604, 0.007280565798282623, 0.11284877359867096, 0.4331936836242676, 0.1274099051952362, 0.08008622378110886, 0.05096396058797836, 0.5075258612632751, 0.02938307821750641, 0.032054267823696136, 0.08814923465251923, 0.13890181481838226, 0.20568154752254486, 0.962990939617157, 0.9724785685539246, 0.973791241645813, 0.08642081916332245, 0.13295510411262512, 0.10858000069856644, 0.1617620438337326, 0.10636408627033234, 0.12630735337734222, 0.27698978781700134, 0.08926913142204285, 0.8926913142204285, 0.9740303754806519, 0.9728794097900391, 0.9394925832748413, 0.22319592535495758, 0.4206385016441345, 0.08369847387075424, 0.053652867674827576, 0.07082178443670273, 0.03648395091295242, 0.11159796267747879, 0.9280900955200195, 0.5570985078811646, 0.07224220037460327, 0.08335638046264648, 0.044456738978624344, 0.11114184558391571, 0.08891347795724869, 0.044456738978624344, 0.9623061418533325, 0.9808806777000427, 0.5925435423851013, 0.026531802490353584, 0.1282370388507843, 0.008843934163451195, 0.11497113853693008, 0.12381507456302643, 0.980252206325531, 0.02267545461654663, 0.034013181924819946, 0.011337727308273315, 0.9296936392784119, 0.01614978536963463, 0.16688111424446106, 0.05921587720513344, 0.183030903339386, 0.06459914147853851, 0.04306609183549881, 0.4683437645435333, 0.004035141319036484, 0.0766676813364029, 0.024210847914218903, 0.4519358277320862, 0.04438655450940132, 0.15737050771713257, 0.23807333409786224, 0.5291507244110107, 0.08231233805418015, 0.058794524520635605, 0.14698632061481476, 0.07937260717153549, 0.07937260717153549, 0.023517809808254242, 0.9377752542495728, 0.15877901017665863, 0.04669971019029617, 0.08405947685241699, 0.01867988333106041, 0.01867988333106041, 0.6724758148193359, 0.9482156038284302, 0.8634477257728577, 0.0575631819665432, 0.07195397466421127, 0.011280575767159462, 0.06768345832824707, 0.8686043620109558, 0.022561151534318924, 0.022561151534318924, 0.011280575767159462, 0.021178115159273148, 0.042356230318546295, 0.021178115159273148, 0.021178115159273148, 0.8683027029037476, 0.042356230318546295, 0.1485423743724823, 0.08912543207406998, 0.02970847673714161, 0.6387322545051575, 0.02970847673714161, 0.05941695347428322, 0.007427119184285402, 0.09927147626876831, 0.07755584269762039, 0.055840205401182175, 0.5428909063339233, 0.043431270867586136, 0.1458049714565277, 0.03412456810474396, 0.031233172863721848, 0.01784752681851387, 0.6335872411727905, 0.04908069968223572, 0.20078468322753906, 0.031233172863721848, 0.031233172863721848, 0.03266001120209694, 0.03266001120209694, 0.06532002240419388, 0.03266001120209694, 0.01306400541216135, 0.7185202836990356, 0.11104404181241989, 0.9799293875694275, 0.9830285310745239, 0.9453370571136475, 0.08938909322023392, 0.43162161111831665, 0.020431792363524437, 0.17111626267433167, 0.1634543389081955, 0.03575563803315163, 0.09194306284189224, 0.08007318526506424, 0.03821674734354019, 0.30573397874832153, 0.12010977417230606, 0.009099225513637066, 0.2966347634792328, 0.15286698937416077, 0.9607959985733032, 0.09911242127418518, 0.03651510179042816, 0.046947985887527466, 0.06259731948375702, 0.5581594109535217, 0.19822484254837036, 0.9529200196266174, 0.02887636423110962, 0.13249732553958893, 0.006624866276979446, 0.046374063938856125, 0.013249732553958893, 0.026499465107917786, 0.013249732553958893, 0.7684844732284546, 0.1779969483613968, 0.18195243179798126, 0.06328780204057693, 0.08306524157524109, 0.2511734664440155, 0.10679817199707031, 0.13646432757377625, 0.9168362617492676, 0.01910075545310974, 0.01910075545310974, 0.01910075545310974, 0.008674604818224907, 0.08674605190753937, 0.7980636954307556, 0.008674604818224907, 0.008674604818224907, 0.08674605190753937, 0.12559069693088531, 0.09568814933300018, 0.07176610827445984, 0.6399145126342773, 0.07176610827445984, 0.9704336524009705, 0.018662184476852417, 0.9238967895507812, 0.056335169821977615, 0.011267034336924553, 0.036512501537799835, 0.7959725856781006, 0.007302500773221254, 0.10223501175642014, 0.007302500773221254, 0.029210003092885017, 0.02190750278532505, 0.14362481236457825, 0.09096238762140274, 0.5601367950439453, 0.01436248142272234, 0.10532486438751221, 0.08617489039897919, 0.33079370856285095, 0.10160093009471893, 0.021265309303998947, 0.35442182421684265, 0.06379593163728714, 0.05670749396085739, 0.07324717938899994, 0.22595109045505524, 0.00928566139191389, 0.5230922698974609, 0.05880918726325035, 0.14857058227062225, 0.024761764332652092, 0.00928566139191389, 0.06257569044828415, 0.697272002696991, 0.09833323210477829, 0.026818154379725456, 0.01787876896560192, 0.09833323210477829, 0.07542405277490616, 0.7948534488677979, 0.002900924999266863, 0.03771202638745308, 0.020306475460529327, 0.005801849998533726, 0.06382035464048386, 0.15310820937156677, 0.06018736585974693, 0.10242411494255066, 0.1182628944516182, 0.13515760004520416, 0.3104400932788849, 0.11931881308555603, 0.015319909900426865, 0.8425950407981873, 0.015319909900426865, 0.06127963960170746, 0.045959729701280594, 0.9216775298118591, 0.047265514731407166, 0.9673073887825012, 0.9537296295166016, 0.027019109576940536, 0.9456688761711121, 0.031166890636086464, 0.9350067377090454, 0.05132655054330826, 0.02199709415435791, 0.029329458251595497, 0.6599128246307373, 0.11731783300638199, 0.014664729125797749, 0.10265310108661652, 0.974327027797699, 0.022756174206733704, 0.011378087103366852, 0.02844521775841713, 0.011378087103366852, 0.6940633058547974, 0.1308480054140091, 0.10240278393030167, 0.17012502253055573, 0.09885642677545547, 0.4207145571708679, 0.18621791899204254, 0.04368074610829353, 0.06896959990262985, 0.009195947088301182, 0.9777435660362244, 0.9770990014076233, 0.042969245463609695, 0.9453234076499939, 0.9689174890518188, 0.8690491914749146, 0.04573943093419075, 0.022869715467095375, 0.04573943093419075, 0.9446693062782288, 0.9813871383666992, 0.030613159760832787, 0.11479934304952621, 0.13010592758655548, 0.6428763270378113, 0.007653289940208197, 0.07653290033340454, 0.18877013027668, 0.17787954211235046, 0.18877013027668, 0.050822727382183075, 0.04900762811303139, 0.2795249819755554, 0.06534350663423538, 0.04328039661049843, 0.04328039661049843, 0.8656079173088074, 0.04328039661049843, 0.8538960814476013, 0.015157918445765972, 0.07073695212602615, 0.02021055854856968, 0.02021055854856968, 0.01010527927428484, 0.00505263963714242, 0.9650886654853821, 0.011662935838103294, 0.1282922923564911, 0.02332587167620659, 0.8164054751396179, 0.011662935838103294, 0.02332587167620659, 0.9633669853210449, 0.9610224366188049, 0.01086338609457016, 0.912524402141571, 0.0543169304728508, 0.01086338609457016, 0.01086338609457016, 0.4658343195915222, 0.07473278045654297, 0.1370100975036621, 0.08469714969396591, 0.12704572081565857, 0.06476841121912003, 0.04483966901898384, 0.17636407911777496, 0.7469537258148193, 0.020748715847730637, 0.05187178775668144, 0.011180954053997993, 0.4891667366027832, 0.27113813161849976, 0.019566670060157776, 0.1565333604812622, 0.022361908107995987, 0.03354286402463913, 0.9582319259643555, 0.03792271018028259, 0.6920894980430603, 0.009480677545070648, 0.20857490599155426, 0.05688406527042389, 0.017059357836842537, 0.06823743134737015, 0.8017898201942444, 0.08529678732156754, 0.017059357836842537, 0.037861909717321396, 0.018930954858660698, 0.8266516923904419, 0.0063103181309998035, 0.04417222738265991, 0.05679286643862724, 0.9755462408065796, 0.9657744765281677, 0.03269852325320244, 0.015570725314319134, 0.012456580065190792, 0.0965384989976883, 0.1650496870279312, 0.636842668056488, 0.043598029762506485, 0.04702667519450188, 0.15451622009277344, 0.013436193577945232, 0.05374477431178093, 0.09629271924495697, 0.2485695779323578, 0.3851708769798279, 0.04590156301856041, 0.018360624089837074, 0.6609824895858765, 0.1468849927186966, 0.11934405565261841, 0.18660853803157806, 0.012039260938763618, 0.012039260938763618, 0.08427482843399048, 0.012039260938763618, 0.6922575235366821, 0.8372507095336914, 0.017813844606280327, 0.12469691783189774, 0.017813844606280327, 0.02134072221815586, 0.06402216851711273, 0.02134072221815586, 0.02134072221815586, 0.8749696612358093, 0.945793092250824, 0.9112043976783752, 0.05695027485489845, 0.03224648907780647, 0.9351481795310974, 0.48130759596824646, 0.013150480575859547, 0.01841067336499691, 0.08679317682981491, 0.25248923897743225, 0.06049221381545067, 0.08679317682981491, 0.2033218890428543, 0.0033331457525491714, 0.1399921178817749, 0.36331290006637573, 0.07666235417127609, 0.13665898144245148, 0.07666235417127609, 0.9786695241928101, 0.9174250960350037, 0.05895380675792694, 0.37679171562194824, 0.13585007190704346, 0.16148217022418976, 0.17686142027378082, 0.010252836160361767, 0.07945948094129562, 0.038910746574401855, 0.5588998198509216, 0.02476138435304165, 0.0035373407881706953, 0.007074681576341391, 0.04598543047904968, 0.31836065649986267, 0.8793560266494751, 0.04628189653158188, 0.02314094826579094, 0.02314094826579094, 0.0932300016283989, 0.01035888958722353, 0.031076667830348015, 0.7769166827201843, 0.0932300016283989, 0.9233088493347168, 0.037686076015233994, 0.018843038007616997, 0.018843038007616997, 0.012272972613573074, 0.7977432608604431, 0.02454594522714615, 0.15954864025115967, 0.9916186928749084, 0.018678057938814163, 0.018678057938814163, 0.8965467810630798, 0.05603417381644249, 0.02036951296031475, 0.1222170740365982, 0.8351500034332275, 0.010184756480157375, 0.010184756480157375, 0.9305920600891113, 0.1734834611415863, 0.03717502951622009, 0.031864311546087265, 0.04956670477986336, 0.6479076743125916, 0.04425598680973053, 0.017702395096421242, 0.26616495847702026, 0.3336993455886841, 0.04568503051996231, 0.04369872435927391, 0.11719203740358353, 0.09137006103992462, 0.10130158811807632, 0.08116015046834946, 0.6271466016769409, 0.029512781649827957, 0.1475639045238495, 0.014756390824913979, 0.08853834122419357, 0.014756390824913979, 0.695777416229248, 0.11718356609344482, 0.014647945761680603, 0.03661986440420151, 0.11718356609344482, 0.014647945761680603, 0.05877872556447983, 0.9110702276229858, 0.9296775460243225, 0.9490832686424255, 0.04126448929309845, 0.018300844356417656, 0.12810590863227844, 0.8235380053520203, 0.9558807015419006, 0.25702935457229614, 0.14758460223674774, 0.218889519572258, 0.10115349292755127, 0.1459263414144516, 0.05306412652134895, 0.07462142407894135, 0.04672606289386749, 0.031150709837675095, 0.708678662776947, 0.21026729047298431, 0.007787677459418774, 0.007787677459418774, 0.9733924269676208, 0.08919412642717361, 0.847344160079956, 0.029731374233961105, 0.014865687116980553, 0.014865687116980553, 0.9583394527435303, 0.13417881727218628, 0.5926231145858765, 0.027953920885920525, 0.08945254981517792, 0.027953920885920525, 0.08945254981517792, 0.039135489612817764, 0.08002933114767075, 0.9069991111755371, 0.9582527279853821, 0.021424174308776855, 0.856967031955719, 0.06427252292633057, 0.04284834861755371, 0.021424174308776855, 0.11383984982967377, 0.6358932852745056, 0.03679671883583069, 0.029897334054112434, 0.06669405102729797, 0.058644771575927734, 0.0574948713183403, 0.9570537209510803, 0.1236063688993454, 0.1193440854549408, 0.4986877739429474, 0.1704915463924408, 0.01704915426671505, 0.0681966170668602, 0.2645115554332733, 0.33708512783050537, 0.024827798828482628, 0.16042578220367432, 0.05156542733311653, 0.04106136038899422, 0.12127424776554108, 0.9726855754852295, 0.14659418165683746, 0.08402349054813385, 0.37006092071533203, 0.12156590074300766, 0.19843846559524536, 0.06078295037150383, 0.01787733845412731, 0.1078353002667427, 0.11357121914625168, 0.08374443650245667, 0.02409086562693119, 0.5082025527954102, 0.05621201917529106, 0.10668811947107315, 0.009465476498007774, 0.052060119807720184, 0.056792858988046646, 0.033129166811704636, 0.19404226541519165, 0.014198214747011662, 0.6389196515083313, 0.06741658598184586, 0.06044245883822441, 0.21736037731170654, 0.06044245883822441, 0.3115111291408539, 0.11507314443588257, 0.16854147613048553, 0.04620800539851189, 0.9241601228713989, 0.23217234015464783, 0.036508671939373016, 0.19052962958812714, 0.04563583806157112, 0.10667377710342407, 0.1220758706331253, 0.2669696509838104, 0.009375537745654583, 0.028126612305641174, 0.9563047885894775, 0.9690069556236267, 0.9702128767967224, 0.07073470205068588, 0.11317552626132965, 0.2570027709007263, 0.011789117008447647, 0.41497692465782166, 0.07309252768754959, 0.056587763130664825, 0.9832370281219482, 0.970233142375946, 0.9769185185432434, 0.08988688886165619, 0.2134813517332077, 0.005617930553853512, 0.044943444430828094, 0.05056137219071388, 0.5393213033676147, 0.05056137219071388, 0.03197093307971954, 0.01598546653985977, 0.03197093307971954, 0.7992733716964722, 0.047956403344869614, 0.07992734014987946, 0.9704713225364685, 0.2164027839899063, 0.05901894345879555, 0.05339809134602547, 0.016862554475665092, 0.16300469636917114, 0.32319897413253784, 0.16862554848194122, 0.5731256604194641, 0.0989944264292717, 0.015630699694156647, 0.04689209908246994, 0.14588652551174164, 0.11983536183834076, 0.9556980133056641, 0.9330300688743591, 0.9642879366874695, 0.17678549885749817, 0.1118895560503006, 0.02237791195511818, 0.1678343266248703, 0.11636513471603394, 0.09846281260251999, 0.30433958768844604, 0.706730842590332, 0.009486320428550243, 0.04268844053149223, 0.1754969209432602, 0.06166107952594757, 0.15117627382278442, 0.027076348662376404, 0.09251085668802261, 0.14666356146335602, 0.42419612407684326, 0.13312537968158722, 0.024819986894726753, 0.022406216710805893, 0.9634672999382019, 0.9268161058425903, 0.9380355477333069, 0.6515384912490845, 0.038006413727998734, 0.021717950701713562, 0.13030770421028137, 0.15745514631271362, 0.0054294876754283905, 0.04719143360853195, 0.07078714668750763, 0.24906589090824127, 0.37228795886039734, 0.036704447120428085, 0.1258438229560852, 0.09700460731983185, 0.9595854878425598, 0.07543374598026276, 0.8297712206840515, 0.09429218620061874, 0.029219310730695724, 0.9642372727394104, 0.9550615549087524, 0.02652948722243309, 0.9873222708702087, 0.025260983034968376, 0.9599173069000244, 0.026762977242469788, 0.9634671807289124, 0.9193230867385864, 0.051073502749204636, 0.025536751374602318, 0.17233674228191376, 0.02154209278523922, 0.02154209278523922, 0.03590348735451698, 0.028722789138555527, 0.5959978699684143, 0.12207185477018356, 0.9559234976768494, 0.03180837258696556, 0.05566465109586716, 0.01590418629348278, 0.7077362537384033, 0.1828981339931488, 0.00795209314674139, 0.08899369090795517, 0.026457583531737328, 0.17798738181591034, 0.09380415827035904, 0.009620939381420612, 0.5411778092384338, 0.06253610551357269, 0.9620225429534912, 0.941224217414856, 0.046580296009778976, 0.931605875492096, 0.06771374493837357, 0.18621280789375305, 0.14584499597549438, 0.11849905550479889, 0.07422468066215515, 0.31122279167175293, 0.09636186808347702, 0.034146372228860855, 0.9560983777046204, 0.9325254559516907, 0.9303736686706543, 0.9749490022659302, 0.5272508859634399, 0.1611977219581604, 0.04197857156395912, 0.09739028662443161, 0.011754000559449196, 0.05373257398605347, 0.10578600317239761, 0.9667403101921082, 0.5516653656959534, 0.13418887555599213, 0.03478970751166344, 0.059639498591423035, 0.0745493695139885, 0.08945924788713455, 0.049699582159519196, 0.9694559574127197, 0.9646731615066528, 0.033395618200302124, 0.9350772500038147, 0.033395618200302124, 0.9318566918373108, 0.9449753761291504, 0.064964659512043, 0.01624116487801075, 0.9095051884651184, 0.9648598432540894, 0.5475276708602905, 0.03136877343058586, 0.11977168172597885, 0.037072185426950455, 0.14258533716201782, 0.04562730714678764, 0.0769960805773735, 0.035429444164037704, 0.9565950036048889, 0.02183271199464798, 0.05239851027727127, 0.08733084797859192, 0.013099627569317818, 0.8209099769592285, 0.008733085356652737, 0.02905149944126606, 0.9586994647979736, 0.9588289856910706, 0.06941023468971252, 0.023136746138334274, 0.8791963458061218, 0.9383600950241089, 0.030269680544734, 0.9741596579551697, 0.12338542938232422, 0.059565380215644836, 0.017018679529428482, 0.008509339764714241, 0.5871444344520569, 0.19996948540210724, 0.9279449582099915, 0.1263432651758194, 0.8686099648475647, 0.1420828104019165, 0.058042336255311966, 0.4667571187019348, 0.13664133846759796, 0.07376213371753693, 0.033858031034469604, 0.08948193490505219, 0.9423137307167053, 0.9645587801933289, 0.02086581103503704, 0.06259743124246597, 0.02086581103503704, 0.06259743124246597, 0.813766598701477, 0.01043290551751852, 0.010929848067462444, 0.01639477349817753, 0.8088088035583496, 0.147552952170372, 0.01639477349817753, 0.9810370206832886, 0.935696005821228, 0.9880478978157043, 0.188236802816391, 0.030858492478728294, 0.1388632208108902, 0.515336811542511, 0.08331792801618576, 0.04628773778676987, 0.09074806421995163, 0.5868374705314636, 0.105872742831707, 0.08167325705289841, 0.039324160665273666, 0.03629922494292259, 0.06049870699644089, 0.024078967049717903, 0.03611845150589943, 0.12039483338594437, 0.8186848759651184, 0.9795805811882019, 0.017749428749084473, 0.017749428749084473, 0.8874714374542236, 0.05324828624725342, 0.017749428749084473, 0.15416526794433594, 0.17222647368907928, 0.0941762775182724, 0.34767815470695496, 0.1606156975030899, 0.019351288676261902, 0.052248481661081314, 0.9427032470703125, 0.02589428797364235, 0.9580886363983154, 0.16942240297794342, 0.06123701483011246, 0.06736071407794952, 0.016329871490597725, 0.26536038517951965, 0.018371105194091797, 0.4021230638027191, 0.17565849423408508, 0.1112503781914711, 0.4303632974624634, 0.08197396248579025, 0.040986981242895126, 0.09661217033863068, 0.06148047372698784, 0.1486814320087433, 0.041435807943344116, 0.08774641901254654, 0.23399044573307037, 0.026811406016349792, 0.44116947054862976, 0.01949920319020748, 0.01819644123315811, 0.10008042305707932, 0.027294659987092018, 0.06368754059076309, 0.10008042305707932, 0.6869156360626221, 0.9778606295585632, 0.960747241973877, 0.01960708573460579, 0.1289909929037094, 0.16726303100585938, 0.23246727883815765, 0.1417483389377594, 0.18710780143737793, 0.04677695035934448, 0.09497138857841492, 0.9699488878250122, 0.06515205651521683, 0.16613775491714478, 0.39091235399246216, 0.1693953573703766, 0.07492487132549286, 0.13356171548366547, 0.03602541238069534, 0.8465971350669861, 0.01801270619034767, 0.01801270619034767, 0.09006352722644806, 0.022831911221146584, 0.16438975930213928, 0.5570986270904541, 0.0684957355260849, 0.12329231947660446, 0.013699146918952465, 0.05479658767580986, 0.9828526973724365, 0.023542508482933044, 0.9417003393173218, 0.04708501696586609, 0.9793769717216492, 0.07608168572187424, 0.1941394805908203, 0.0052470131777226925, 0.0524701289832592, 0.3882789611816406, 0.05771714448928833, 0.2256215512752533, 0.10097678005695343, 0.37866291403770447, 0.05609821155667305, 0.10097678005695343, 0.10658659785985947, 0.08414731919765472, 0.16829463839530945, 0.9775788187980652, 0.04162655025720596, 0.02081327512860298, 0.04162655025720596, 0.04162655025720596, 0.8533443212509155, 0.11487510055303574, 0.12009669840335846, 0.09398871660232544, 0.6161482930183411, 0.02610797807574272, 0.031329572200775146, 0.9535314440727234, 0.25036072731018066, 0.04636309668421745, 0.0432722233235836, 0.0432722233235836, 0.4976305663585663, 0.01854523830115795, 0.0989079400897026, 0.978358268737793, 0.9226624965667725, 0.010823199525475502, 0.032469600439071655, 0.7576239705085754, 0.021646399050951004, 0.15152479708194733, 0.032469600439071655, 0.981047511100769, 0.9565394520759583, 0.022675709798932076, 0.9523798227310181, 0.8934702277183533, 0.08376283198595047, 0.19355756044387817, 0.009677877649664879, 0.7355186939239502, 0.004838938824832439, 0.02419469505548477, 0.029033632948994637, 0.9522583484649658, 0.10834293812513351, 0.052303485572338104, 0.1457025706768036, 0.11581486463546753, 0.037359632551670074, 0.49501514434814453, 0.04669954255223274, 0.9347301721572876, 0.9401074647903442, 0.9770088791847229, 0.657615602016449, 0.01719256490468979, 0.08596282452344894, 0.008596282452344894, 0.025788847357034683, 0.08596282452344894, 0.12034795433282852, 0.9770362973213196, 0.013699300587177277, 0.8904545307159424, 0.013699300587177277, 0.08219580352306366, 0.03609767556190491, 0.06016279384493828, 0.2045534998178482, 0.006016279570758343, 0.12032558768987656, 0.5474814176559448, 0.02406511828303337, 0.9579773545265198, 0.012747425585985184, 0.09560569375753403, 0.025494851171970367, 0.03824227675795555, 0.21033252775669098, 0.5481392741203308, 0.0764845535159111, 0.06486760079860687, 0.10270702838897705, 0.010811266489326954, 0.10811266303062439, 0.07027323544025421, 0.621647834777832, 0.016216900199651718, 0.9554184079170227, 0.025113575160503387, 0.23997415602207184, 0.09487350285053253, 0.4799483120441437, 0.11161588877439499, 0.050227150321006775, 0.9561589360237122, 0.03432237356901169, 0.017161186784505844, 0.9267040491104126, 0.017161186784505844, 0.014664147049188614, 0.894512951374054, 0.029328294098377228, 0.04399244114756584, 0.9830812215805054, 0.9751753807067871, 0.9739829301834106, 0.038303688168525696, 0.5319957137107849, 0.2425900399684906, 0.017023861408233643, 0.10639914125204086, 0.029791759327054024, 0.038303688168525696, 0.14914248883724213, 0.024211443960666656, 0.05132826045155525, 0.6585512757301331, 0.10168806463479996, 0.006779204122722149, 0.007747661788016558, 0.02485836297273636, 0.9446178078651428, 0.2169390469789505, 0.501025915145874, 0.06714779883623123, 0.030991291627287865, 0.08264344930648804, 0.05165215581655502, 0.05165215581655502, 0.9233500361442566, 0.9447214007377625, 0.1972728967666626, 0.10576679557561874, 0.045158855617046356, 0.08794093132019043, 0.3826618790626526, 0.09744805842638016, 0.08199897408485413, 0.015080862678587437, 0.015080862678587437, 0.015080862678587437, 0.015080862678587437, 0.9500943422317505, 0.043922267854213715, 0.8638046383857727, 0.043922267854213715, 0.014640755951404572, 0.029281511902809143, 0.02036161720752716, 0.9569960236549377, 0.02036161720752716, 0.03310319408774376, 0.9268894195556641, 0.03310319408774376, 0.13786377012729645, 0.0667082741856575, 0.42470934987068176, 0.06448466330766678, 0.12896932661533356, 0.09116797149181366, 0.08672075718641281, 0.955456554889679, 0.02526310458779335, 0.9599980115890503, 0.960097074508667, 0.02315245009958744, 0.7640308141708374, 0.06945734471082687, 0.11576224863529205, 0.02315245009958744, 0.01157622504979372, 0.9851028323173523, 0.06572194397449493, 0.9201071858406067, 0.47550421953201294, 0.15719148516654968, 0.12182339280843735, 0.08252552896738052, 0.01964893564581871, 0.05894680321216583, 0.0864553153514862, 0.01565856859087944, 0.00782928429543972, 0.06263427436351776, 0.8142455220222473, 0.09395140409469604, 0.033955398947000504, 0.13582159578800201, 0.7583372592926025, 0.07922926545143127, 0.18882983922958374, 0.062115080654621124, 0.06708428263664246, 0.10186872631311417, 0.29318317770957947, 0.28572937846183777, 0.9795687198638916, 0.9822311997413635, 0.9580722451210022, 0.9661727547645569, 0.05059720575809479, 0.007228171918541193, 0.0650535449385643, 0.007228171918541193, 0.05059720575809479, 0.8167834281921387, 0.9452536702156067, 0.9800089597702026, 0.024241846054792404, 0.16969291865825653, 0.599985659122467, 0.08484645932912827, 0.012120923027396202, 0.04242322966456413, 0.06060461327433586, 0.023974008858203888, 0.11987004429101944, 0.023974008858203888, 0.8231076002120972, 0.007991336286067963, 0.014521756209433079, 0.00968117080628872, 0.07260878384113312, 0.111333467066288, 0.01936234161257744, 0.701884925365448, 0.07260878384113312, 0.15559519827365875, 0.15134397149085999, 0.26357656717300415, 0.21341200172901154, 0.15049372613430023, 0.02125617489218712, 0.04421284422278404, 0.9345274567604065, 0.935303270816803, 0.9709920883178711, 0.015401123091578484, 0.015401123091578484, 0.9240673780441284, 0.015401123091578484, 0.030802246183156967, 0.015401123091578484, 0.1109173446893692, 0.02464829944074154, 0.764097273349762, 0.08626904338598251, 0.01232414972037077, 0.979698121547699, 0.8699259757995605, 0.023198025301098824, 0.011599012650549412, 0.011599012650549412, 0.08119308948516846, 0.3733205199241638, 0.2513691484928131, 0.0323544442653656, 0.1294177770614624, 0.08710812032222748, 0.0647088885307312, 0.0647088885307312, 0.9767972230911255, 0.13674119114875793, 0.17695918679237366, 0.1005449965596199, 0.0522833988070488, 0.01608719862997532, 0.4886486828327179, 0.0261416994035244, 0.21543040871620178, 0.08659457415342331, 0.5132312774658203, 0.008448251523077488, 0.05913775786757469, 0.09504282474517822, 0.021120628342032433, 0.08491188287734985, 0.012130269780755043, 0.04852107912302017, 0.7278161644935608, 0.12130269408226013, 0.5362598299980164, 0.10627100616693497, 0.07193729281425476, 0.021254200488328934, 0.1160806342959404, 0.05068309232592583, 0.09973125159740448, 0.896149754524231, 0.04267379641532898, 0.05689839646220207, 0.15787550806999207, 0.48755672574043274, 0.16251890361309052, 0.05572076886892319, 0.03250377997756004, 0.06500755995512009, 0.04179057478904724, 0.21380756795406342, 0.24974161386489868, 0.13115926086902618, 0.0323406383395195, 0.2263844758272171, 0.06108787655830383, 0.08444500714540482, 0.032938119024038315, 0.19104108214378357, 0.08234529942274094, 0.11857722699642181, 0.161396786570549, 0.3689069449901581, 0.0428195558488369, 0.027034154161810875, 0.009011385031044483, 0.009011385031044483, 0.009011385031044483, 0.9552068114280701, 0.023734847083687782, 0.9493938684463501, 0.023734847083687782, 0.9433998465538025, 0.04101738706231117, 0.022238144651055336, 0.9340020418167114, 0.16887180507183075, 0.13464103639125824, 0.1118205189704895, 0.13007692992687225, 0.04107692837715149, 0.031948719173669815, 0.383384644985199, 0.32564395666122437, 0.09265559911727905, 0.10255085676908493, 0.06207025423645973, 0.029685774818062782, 0.11964266747236252, 0.2671719789505005, 0.9826861023902893, 0.06179453432559967, 0.09112075716257095, 0.32468315958976746, 0.14558373391628265, 0.05865244194865227, 0.15815211832523346, 0.15919947624206543, 0.06698314100503922, 0.9210181832313538, 0.021508755162358284, 0.003584792371839285, 0.003584792371839285, 0.01433916948735714, 0.9571396112442017, 0.034793298691511154, 0.008698324672877789, 0.017396649345755577, 0.008698324672877789, 0.7132626175880432, 0.20875978469848633, 0.9236385226249695, 0.01015389896929264, 0.13200068473815918, 0.802157998085022, 0.050769492983818054, 0.2791506052017212, 0.06100642308592796, 0.08503925800323486, 0.00924339797347784, 0.351249098777771, 0.05361170694231987, 0.15713776648044586, 0.9684872627258301, 0.8612733483314514, 0.013250359334051609, 0.053001437336206436, 0.06625179946422577, 0.03502162918448448, 0.9455840587615967, 0.9640797972679138, 0.884249210357666, 0.10402932018041611, 0.6363725066184998, 0.03674592077732086, 0.055118877440690994, 0.1319512575864792, 0.05678914859890938, 0.07850264757871628, 0.005010807421058416, 0.9826058149337769, 0.14206674695014954, 0.16449834406375885, 0.19191473722457886, 0.34145867824554443, 0.1021883636713028, 0.017446793615818024, 0.042370785027742386, 0.9487517476081848, 0.04884513095021248, 0.036633849143981934, 0.8914236426353455, 0.02442256547510624, 0.9286968111991882, 0.024439388886094093, 0.024439388886094093, 0.05600220710039139, 0.9240363836288452, 0.07293538749217987, 0.1510804444551468, 0.02604835294187069, 0.04167736694216728, 0.5522251129150391, 0.06251604855060577, 0.08856440335512161, 0.042049530893564224, 0.9250896573066711, 0.972300112247467, 0.017198612913489342, 0.057328712195158005, 0.0945923775434494, 0.5589549541473389, 0.057328712195158005, 0.1891847550868988, 0.022931484505534172, 0.09898221492767334, 0.8314505815505981, 0.01979644224047661, 0.03959288448095322, 0.9605453610420227, 0.8760628700256348, 0.08909114450216293, 0.014848523773252964, 0.014848523773252964, 0.03242708370089531, 0.9728124737739563, 0.10739310085773468, 0.022160479798913002, 0.25910714268684387, 0.0750047042965889, 0.2659257650375366, 0.15853266417980194, 0.11080240458250046, 0.1187533438205719, 0.01187533512711525, 0.047501340508461, 0.8075227737426758, 0.9188899397850037, 0.9451202154159546, 0.032590351998806, 0.04781361296772957, 0.3835483491420746, 0.02494623325765133, 0.08003583550453186, 0.26505371928215027, 0.0623655840754509, 0.13720428943634033, 0.01432331558316946, 0.0525188222527504, 0.16710534691810608, 0.11936096101999283, 0.5633837580680847, 0.09071432799100876, 0.9842459559440613, 0.943931519985199, 0.0409340038895607, 0.09992712736129761, 0.15892024338245392, 0.1408611238002777, 0.3346956670284271, 0.09751924127340317, 0.12641383707523346, 0.030100906267762184, 0.030100906267762184, 0.9030271768569946, 0.9401525855064392, 0.9829682111740112, 0.13313284516334534, 0.15778708457946777, 0.02958507649600506, 0.4930846095085144, 0.09861692041158676, 0.02958507649600506, 0.05917015299201012, 0.025793343782424927, 0.12896671891212463, 0.019345007836818695, 0.058035023510456085, 0.019345007836818695, 0.1225183829665184, 0.6254885792732239, 0.14770345389842987, 0.01527966745197773, 0.010186444967985153, 0.6977714896202087, 0.03055933490395546, 0.04074577987194061, 0.06111866980791092, 0.033562567085027695, 0.9733144640922546, 0.9653047323226929, 0.658631443977356, 0.07630486786365509, 0.05421661585569382, 0.026104295626282692, 0.09839311242103577, 0.08433695882558823, 0.2244497537612915, 0.03470872342586517, 0.15271839499473572, 0.0069417450577020645, 0.3887377083301544, 0.1388348937034607, 0.05322004482150078, 0.9811865091323853, 0.9818960428237915, 0.034335047006607056, 0.3343149423599243, 0.24576665461063385, 0.20601028203964233, 0.09216249734163284, 0.05240612477064133, 0.034335047006607056, 0.024143345654010773, 0.024143345654010773, 0.9174470901489258, 0.024143345654010773, 0.00947262067347765, 0.985152542591095, 0.00947262067347765, 0.1308225840330124, 0.009344469755887985, 0.01868893951177597, 0.15885598957538605, 0.6821463108062744, 0.021253416314721107, 0.08501366525888443, 0.021253416314721107, 0.8713901042938232, 0.028286267071962357, 0.9051605463027954, 0.028286267071962357, 0.9641909599304199, 0.9115751385688782, 0.9763432741165161, 0.9899433851242065, 0.009611100889742374, 0.9850463271141052, 0.07178972661495209, 0.10512067377567291, 0.04102269932627678, 0.2640836238861084, 0.0589701309800148, 0.09999283403158188, 0.35894861817359924, 0.04225444793701172, 0.01056361198425293, 0.908470630645752, 0.01056361198425293, 0.01056361198425293, 0.01056361198425293, 0.026819223538041115, 0.04022883623838425, 0.04022883623838425, 0.09386728703975677, 0.8045767545700073, 0.022794725373387337, 0.06838417798280716, 0.022794725373387337, 0.8661996126174927, 0.22423453629016876, 0.18022587895393372, 0.06915644556283951, 0.09849554300308228, 0.06915644556283951, 0.25776493549346924, 0.09639989584684372, 0.9704604744911194, 0.016698075458407402, 0.1210610494017601, 0.1210610494017601, 0.21707499027252197, 0.050094228237867355, 0.04591970890760422, 0.4299754500389099, 0.12389270216226578, 0.8495499491691589, 0.9073619842529297, 0.9382203221321106, 0.034748900681734085, 0.16798566281795502, 0.164210706949234, 0.13023607432842255, 0.03774958476424217, 0.28500938415527344, 0.1509983390569687, 0.06228681653738022, 0.02149519883096218, 0.9242935180664062, 0.04299039766192436, 0.03455107659101486, 0.7370896339416504, 0.19578944146633148, 0.023034051060676575, 0.9690969586372375, 0.16578616201877594, 0.019504254683852196, 0.15603403747081757, 0.03575780242681503, 0.5071106553077698, 0.05201134830713272, 0.06501418352127075, 0.8317405581474304, 0.03539321571588516, 0.10617963969707489, 0.01769660785794258, 0.9772705435752869, 0.028876151889562607, 0.12994268536567688, 0.85184645652771, 0.03577452525496483, 0.5545051693916321, 0.04292943328619003, 0.032197073101997375, 0.04292943328619003, 0.26830896735191345, 0.02504216879606247, 0.9479231238365173, 0.06846099346876144, 0.17495587468147278, 0.22820332646369934, 0.3251897394657135, 0.14643046259880066, 0.04564066231250763, 0.011410165578126907, 0.02485516108572483, 0.06500580161809921, 0.09750870615243912, 0.12809967994689941, 0.053534191101789474, 0.6271148324012756, 0.0038238707929849625, 0.9546904563903809, 0.043042026460170746, 0.9469245672225952, 0.11230971664190292, 0.35297340154647827, 0.04706311970949173, 0.16579052805900574, 0.09840470552444458, 0.06631620973348618, 0.1561639904975891, 0.11585409939289093, 0.006436339113861322, 0.019309015944600105, 0.10298142582178116, 0.11585409939289093, 0.6307612061500549, 0.006436339113861322, 0.9091101288795471, 0.4513033628463745, 0.008569051511585712, 0.014281751587986946, 0.2342207282781601, 0.13996116816997528, 0.11139766126871109, 0.04284525662660599, 0.012557651847600937, 0.08790356665849686, 0.03767295554280281, 0.018836477771401405, 0.7722955942153931, 0.06906708329916, 0.9619008302688599, 0.016303403303027153, 0.016303403303027153, 0.914773166179657, 0.07623109221458435, 0.01773478277027607, 0.01773478277027607, 0.01773478277027607, 0.01773478277027607, 0.05320435017347336, 0.8690043687820435, 0.20325057208538055, 0.02540632151067257, 0.7621896266937256, 0.21514567732810974, 0.19608214497566223, 0.3812708258628845, 0.017701860517263412, 0.04221212863922119, 0.08987098187208176, 0.05855230614542961, 0.9326909184455872, 0.9610174894332886, 0.9352300763130188, 0.21592000126838684, 0.10613016784191132, 0.04940542206168175, 0.07868271321058273, 0.14638642966747284, 0.10796000063419342, 0.2946026921272278, 0.005687527358531952, 0.10806302726268768, 0.0018958424916490912, 0.024645952507853508, 0.017062582075595856, 0.03602100908756256, 0.8057330846786499, 0.006730671972036362, 0.9557554125785828, 0.006730671972036362, 0.013461343944072723, 0.006730671972036362, 0.048775531351566315, 0.9267351031303406, 0.024387765675783157, 0.9703826308250427, 0.13653144240379333, 0.1433580070734024, 0.10922514647245407, 0.14904682338237762, 0.07736781239509583, 0.29809364676475525, 0.08646991103887558, 0.3301352560520172, 0.19106252491474152, 0.05783865600824356, 0.15272004902362823, 0.05069005861878395, 0.16701723635196686, 0.05004018545150757, 0.9610996246337891, 0.1209612488746643, 0.4198884963989258, 0.1063624769449234, 0.1063624769449234, 0.11331427842378616, 0.10844802111387253, 0.024331286549568176, 0.9795100688934326, 0.043387774378061295, 0.9545310139656067, 0.018252473324537277, 0.07300989329814911, 0.7027202248573303, 0.027378709986805916, 0.0821361318230629, 0.07300989329814911, 0.018252473324537277, 0.9523208737373352, 0.01222303044050932, 0.01222303044050932, 0.9167272448539734, 0.06111514940857887, 0.9606457948684692, 0.9556549191474915, 0.027304425835609436, 0.9734605550765991, 0.8458186984062195, 0.14440807700157166, 0.9803227186203003, 0.04409699887037277, 0.0027560624293982983, 0.7689414024353027, 0.0055121248587965965, 0.0385848730802536, 0.06614549458026886, 0.07441368699073792, 0.36627620458602905, 0.16253505647182465, 0.05265220254659653, 0.12018437683582306, 0.14879970252513885, 0.06180910766124725, 0.08813521265983582, 0.9631415009498596, 0.085729219019413, 0.9144449830055237, 0.947944164276123, 0.15183709561824799, 0.8351039886474609, 0.07397487759590149, 0.03945326805114746, 0.09863317012786865, 0.6263206005096436, 0.014794975519180298, 0.06411156058311462, 0.08383819460868835, 0.9573320746421814, 0.02783580869436264, 0.9185816645622253, 0.02783580869436264, 0.061554692685604095, 0.26362818479537964, 0.21077819168567657, 0.17160701751708984, 0.09264291822910309, 0.09761703759431839, 0.10321291536092758, 0.020086584612727165, 0.944069504737854, 0.020086584612727165, 0.08202026039361954, 0.21584278345108032, 0.48780471086502075, 0.008633711375296116, 0.1295056790113449, 0.051802270114421844, 0.021584277972579002, 0.05873038247227669, 0.18597954511642456, 0.009788396768271923, 0.009788396768271923, 0.009788396768271923, 0.7243413925170898, 0.11378778517246246, 0.027814792469143867, 0.027814792469143867, 0.012643087655305862, 0.3009054660797119, 0.25286173820495605, 0.26044759154319763, 0.04861582815647125, 0.07639630138874054, 0.020835354924201965, 0.0972316563129425, 0.09028653800487518, 0.6667313575744629, 0.012651707977056503, 0.012651707977056503, 0.9109230041503906, 0.012651707977056503, 0.03795512393116951, 0.9526953101158142, 0.9823789596557617, 0.9402211308479309, 0.9838755130767822, 0.9674631357192993, 0.006763900630176067, 0.1420419067144394, 0.020291700959205627, 0.06087510287761688, 0.7710846662521362, 0.6090708374977112, 0.024860035628080368, 0.12181416898965836, 0.02237403206527233, 0.04474806413054466, 0.07333710044622421, 0.10441214591264725, 0.15320925414562225, 0.17711424827575684, 0.31728440523147583, 0.07497474551200867, 0.06410883367061615, 0.16624833643436432, 0.0467233881354332, 0.09333368390798569, 0.03360012546181679, 0.11200042068958282, 0.11200042068958282, 0.05600021034479141, 0.5936022400856018, 0.05270518362522125, 0.0210820734500885, 0.07730093598365784, 0.07378725707530975, 0.042164146900177, 0.6711126565933228, 0.0632462203502655, 0.05392846837639809, 0.9167839884757996, 0.026964234188199043, 0.20713576674461365, 0.014499503187835217, 0.016570860520005226, 0.5551238656044006, 0.03314172104001045, 0.09113973379135132, 0.08285430818796158, 0.03423231467604637, 0.6922534704208374, 0.13692925870418549, 0.005071453750133514, 0.049446675926446915, 0.01901795156300068, 0.0621253103017807, 0.2087155133485794, 0.5818735361099243, 0.07589654624462128, 0.00632471265271306, 0.11384482681751251, 0.01897413656115532, 0.1700504720211029, 0.7848483324050903, 0.03924241662025452, 0.160186305642128, 0.07119391113519669, 0.4805589020252228, 0.008899238891899586, 0.12162292748689651, 0.13052217662334442, 0.02966412901878357, 0.08486229926347733, 0.017128171399235725, 0.0451560877263546, 0.38849806785583496, 0.2156592458486557, 0.10588324069976807, 0.1440323442220688, 0.9778862595558167, 0.9687888622283936, 0.6051520705223083, 0.01152670569717884, 0.04610682278871536, 0.1786639392375946, 0.07300247251987457, 0.06723912060260773, 0.01921117678284645, 0.08470816910266876, 0.06190212443470955, 0.5962151885032654, 0.006516012828797102, 0.013032025657594204, 0.07819215953350067, 0.1596423238515854, 0.0510791651904583, 0.0897216647863388, 0.666694164276123, 0.03553333133459091, 0.07106666266918182, 0.05685333162546158, 0.029314998537302017, 0.15233522653579712, 0.022402239963412285, 0.2889888882637024, 0.04256425425410271, 0.008960896171629429, 0.4413241147994995, 0.04256425425410271, 0.029490629211068153, 0.029490629211068153, 0.8404829502105713, 0.08847188949584961, 0.014745314605534077, 0.014745314605534077, 0.9582456946372986, 0.029037749394774437, 0.9820221662521362, 0.9519935250282288, 0.1555071771144867, 0.6090697646141052, 0.19438397884368896, 0.038876794278621674, 0.021546658128499985, 0.11491551250219345, 0.07900441437959671, 0.03591109812259674, 0.6320353150367737, 0.021546658128499985, 0.1005510687828064, 0.9528738260269165, 0.03970307484269142, 0.9580835103988647, 0.03501931205391884, 0.9280117154121399, 0.01750965602695942, 0.01750965602695942, 0.6139909029006958, 0.051568787544965744, 0.021755581721663475, 0.0539860725402832, 0.07251860946416855, 0.13859111070632935, 0.04834573715925217, 0.11706799268722534, 0.003658374771475792, 0.014633499085903168, 0.029266998171806335, 0.01829187385737896, 0.8085008263587952, 0.010975124314427376], \"Term\": [\"able\", \"able\", \"able\", \"able\", \"able\", \"able\", \"able\", \"absolute_truth\", \"absolute_truth\", \"absolute_truth\", \"ac\", \"accelerate\", \"accelerated\", \"accelerated\", \"acceptance\", \"access_time\", \"accuse\", \"adaptec\", \"adaptec\", \"adaptec\", \"adaptec\", \"add\", \"add\", \"add\", \"add\", \"add\", \"add\", \"add\", \"address\", \"address\", \"address\", \"address\", \"address\", \"address\", \"address\", \"adjust\", \"adjust\", \"adjust\", \"adjust\", \"administrator\", \"afternoon\", \"agree\", \"agree\", \"agree\", \"agree\", \"agree\", \"agree\", \"ah\", \"al\", \"al\", \"al\", \"al\", \"al\", \"allen\", \"allen\", \"allen\", \"allen\", \"allow\", \"allow\", \"allow\", \"allow\", \"allow\", \"allow\", \"allow\", \"american_league\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"apostle\", \"app\", \"app\", \"app\", \"app\", \"app\", \"app\", \"appear\", \"appear\", \"appear\", \"appear\", \"appear\", \"appear\", \"appear\", \"applelink\", \"appreciate\", \"appreciate\", \"appreciate\", \"appreciate\", \"appreciate\", \"appreciate\", \"architecture\", \"architecture\", \"arrogance\", \"arrogance\", \"article\", \"article\", \"article\", \"article\", \"article\", \"article\", \"article\", \"ask\", \"ask\", \"ask\", \"ask\", \"ask\", \"ask\", \"assistance\", \"austin\", \"auto\", \"available\", \"available\", \"available\", \"available\", \"available\", \"available\", \"available\", \"babylon\", \"babylon\", \"balance\", \"balloon\", \"barrier\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"beg\", \"believe\", \"believe\", \"believe\", \"believe\", \"believe\", \"believe\", \"believe\", \"bellow\", \"benchmark\", \"bible\", \"bible\", \"bible\", \"bible\", \"bible\", \"bible\", \"billboard\", \"billion\", \"billion\", \"billion\", \"billion\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"board\", \"board\", \"board\", \"board\", \"board\", \"board\", \"board\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"bread\", \"brown\", \"brown\", \"brown\", \"brown\", \"brown\", \"brown\", \"bsd\", \"buf\", \"buf\", \"buf\", \"buffalo\", \"buffalo\", \"buffalo\", \"buffalo\", \"buffalo\", \"buffalo\", \"bunch\", \"bunch\", \"bunch\", \"bunch\", \"bunch\", \"bunch\", \"bus\", \"bus\", \"bus\", \"bus\", \"bus\", \"bus\", \"bus\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"cable\", \"cable\", \"cable\", \"cable\", \"cable\", \"cable\", \"cable\", \"candida\", \"candida_albican\", \"canon_law\", \"card\", \"card\", \"card\", \"card\", \"card\", \"card\", \"card\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"cdc\", \"certain\", \"certain\", \"certain\", \"certain\", \"certain\", \"certain\", \"cf\", \"cf\", \"chance\", \"chance\", \"chance\", \"chance\", \"chance\", \"chance\", \"chance\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"channel\", \"channel\", \"channel\", \"channel\", \"character\", \"character\", \"character\", \"character\", \"character\", \"character\", \"cheap\", \"cheap\", \"cheap\", \"cheap\", \"cheap\", \"cheer\", \"cheer\", \"chi\", \"chi\", \"chi\", \"chicago\", \"chicago\", \"chicago\", \"chicago\", \"chicago\", \"chicago\", \"chicago\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"christian\", \"christian\", \"christian\", \"christian\", \"christian\", \"christian\", \"christian\", \"church\", \"church\", \"church\", \"church\", \"church\", \"church\", \"church\", \"city\", \"city\", \"city\", \"city\", \"city\", \"city\", \"color\", \"color\", \"color\", \"color\", \"color\", \"color\", \"color\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"community\", \"community\", \"community\", \"community\", \"community\", \"confirm\", \"confirm\", \"congress\", \"consecration\", \"consideration\", \"consideration\", \"consortium\", \"consortium\", \"controller\", \"controller\", \"controller\", \"controller\", \"controller\", \"controller\", \"controller\", \"county\", \"couple\", \"couple\", \"couple\", \"couple\", \"couple\", \"couple\", \"couple\", \"course\", \"course\", \"course\", \"course\", \"course\", \"course\", \"course\", \"crack\", \"crater\", \"crystal\", \"crystal\", \"cy_young\", \"dan\", \"dan\", \"dan\", \"dan\", \"danger\", \"darren\", \"david\", \"david\", \"david\", \"david\", \"david\", \"david\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"dc\", \"dc\", \"dc\", \"dc\", \"deal\", \"deal\", \"deal\", \"deal\", \"deal\", \"deal\", \"deal\", \"decnet\", \"definitely\", \"definitely\", \"definitely\", \"definitely\", \"definitely\", \"definitely\", \"desert\", \"desk\", \"det\", \"det\", \"det\", \"det\", \"det\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"difficult\", \"difficult\", \"difficult\", \"difficult\", \"display\", \"display\", \"display\", \"display\", \"display\", \"display\", \"display\", \"distinguish\", \"dma\", \"dma\", \"dma\", \"dma\", \"dma\", \"doug\", \"doug\", \"doug\", \"doug\", \"doug\", \"dr\", \"dr\", \"dr\", \"dr\", \"dr\", \"dr\", \"dram\", \"draw_line\", \"drive\", \"drive\", \"drive\", \"drive\", \"drive\", \"drive\", \"drive\", \"driver\", \"driver\", \"driver\", \"driver\", \"driver\", \"driver\", \"driver\", \"e\", \"e\", \"e\", \"e\", \"e\", \"e_mail\", \"e_mail\", \"e_mail\", \"e_mail\", \"e_mail\", \"e_mail\", \"echo\", \"echo\", \"echo\", \"echo\", \"edm\", \"edm\", \"edm\", \"edm\", \"edm\", \"email_response\", \"emphasize\", \"emphasize\", \"employee\", \"employee\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"entry\", \"entry\", \"entry\", \"entry\", \"entry\", \"entry\", \"entry\", \"esdi\", \"etc_etc\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"expose\", \"expose\", \"expose\", \"expose\", \"external\", \"external\", \"external\", \"external\", \"external\", \"extreme\", \"extreme\", \"extreme\", \"extreme\", \"factor\", \"factor\", \"factor\", \"factor\", \"factory\", \"far_know\", \"far_know\", \"far_know\", \"far_know\", \"faster\", \"faster\", \"faster\", \"faster\", \"faster\", \"fiber\", \"file\", \"file\", \"file\", \"file\", \"file\", \"file\", \"file\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"fix\", \"fix\", \"fix\", \"fix\", \"fix\", \"fix\", \"fix\", \"flame\", \"flame\", \"flame\", \"flame\", \"flame\", \"flame\", \"fleury\", \"fleury\", \"flip\", \"float\", \"float\", \"floppy_drive\", \"floppy_drive\", \"floppy_drive\", \"florida\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"font\", \"font\", \"font\", \"font\", \"font\", \"font\", \"fortunately\", \"fpu\", \"fpu\", \"fpu\", \"fpu\", \"fpu\", \"france\", \"free\", \"free\", \"free\", \"free\", \"free\", \"free\", \"free\", \"fujitsu\", \"fujitsu\", \"gainey\", \"galaxy\", \"galaxy\", \"galaxy\", \"galaxy\", \"galaxy\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"gc\", \"general\", \"general\", \"general\", \"general\", \"general\", \"general\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get_rid\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"god\", \"god\", \"god\", \"god\", \"god\", \"god\", \"god\", \"gonorrhea\", \"gonorrhea\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"gordon_bank\", \"gordon_bank\", \"gordon_bank\", \"gps\", \"gr\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"growth\", \"gun\", \"gut\", \"guy\", \"guy\", \"guy\", \"guy\", \"guy\", \"guy\", \"guy\", \"h\", \"h\", \"h\", \"h\", \"h\", \"h\", \"hack\", \"happen\", \"happen\", \"happen\", \"happen\", \"happen\", \"happen\", \"happen\", \"hard\", \"hard\", \"hard\", \"hard\", \"hard\", \"hard\", \"harddisk\", \"hash\", \"heal\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hell\", \"hell\", \"hell\", \"hell\", \"hell\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help_appreciate\", \"help_appreciate\", \"help_greatly_appreciate\", \"hewlett_packard\", \"hi\", \"hi\", \"hi\", \"hi\", \"hi\", \"hi\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"highlight\", \"hiv\", \"hiv\", \"hiv\", \"hm\", \"hm\", \"hmmm\", \"hmmm\", \"holy_spirit\", \"hope_help\", \"hope_help\", \"hull\", \"hull\", \"hypothesis\", \"hypothesis\", \"hypothesis\", \"ibm\", \"ibm\", \"ibm\", \"ibm\", \"ibm\", \"ibm\", \"ibm\", \"icccm\", \"ide\", \"ide\", \"ide\", \"ide\", \"ide\", \"ide\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"iici\", \"iivx\", \"imake\", \"imake\", \"include\", \"include\", \"include\", \"include\", \"include\", \"include\", \"include\", \"infallible\", \"infallible\", \"infect\", \"inflammatory\", \"influenza\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"initially\", \"instead\", \"instead\", \"instead\", \"instead\", \"instead\", \"instead\", \"instead\", \"interleave\", \"invent\", \"invoke\", \"invoke\", \"invoke\", \"iron\", \"ivy_league_champ\", \"jeff\", \"jeff\", \"jeff\", \"jeremy\", \"jesus\", \"jesus\", \"jesus\", \"jesus\", \"jesus\", \"jesus\", \"jesus\", \"johansson\", \"johansson\", \"john\", \"john\", \"john\", \"john\", \"john\", \"john\", \"jon\", \"jon\", \"judgment\", \"juneau\", \"juneau\", \"juneau\", \"jupiter\", \"jupiter\", \"keenan\", \"keyboard\", \"keyboard\", \"keyboard\", \"keyboard\", \"keyboard\", \"keyboard\", \"kinda\", \"km\", \"km\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know_truth\", \"kovalev\", \"l\", \"l\", \"l\", \"l\", \"l\", \"l\", \"la\", \"la\", \"la\", \"la\", \"la\", \"larson\", \"last\", \"ld\", \"lead\", \"lead\", \"lead\", \"lead\", \"lead\", \"lead\", \"let\", \"let\", \"let\", \"let\", \"let\", \"let\", \"let\", \"letter\", \"letter\", \"letter\", \"letter\", \"lewi\", \"lib\", \"lib\", \"lib\", \"lib\", \"lib\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"linden\", \"lindro\", \"lindro\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"list\", \"list\", \"list\", \"list\", \"list\", \"list\", \"list\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"london\", \"long_time\", \"long_time\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"loose\", \"lose\", \"lose\", \"lose\", \"lose\", \"lose\", \"lose\", \"louis\", \"louis\", \"louis\", \"louis\", \"louis\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"lssu\", \"lucky\", \"lucky\", \"lucky\", \"luther\", \"mac\", \"mac\", \"mac\", \"mac\", \"mac\", \"mac\", \"mac\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"macinnis\", \"macintosh\", \"macintosh\", \"macintosh\", \"macintosh\", \"macintosh\", \"major\", \"major\", \"major\", \"major\", \"major\", \"major\", \"makefile\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man_page\", \"manson\", \"manual\", \"manual\", \"manual\", \"manual\", \"manual\", \"manual\", \"mariner\", \"mary_shafer_nasa_ame\", \"matthew\", \"matthew\", \"maxtor\", \"maxtor\", \"mb\", \"mb\", \"mb\", \"mb\", \"mb\", \"mb\", \"mcsorley\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"measurement\", \"mediocre\", \"melrose\", \"mention\", \"mention\", \"mention\", \"mention\", \"mention\", \"mention\", \"mention\", \"micro\", \"min\", \"min\", \"min\", \"min\", \"mind\", \"mind\", \"mind\", \"mind\", \"mind\", \"mind\", \"mind\", \"minimize\", \"minute\", \"minute\", \"minute\", \"minute\", \"minute\", \"minute\", \"minute\", \"mission\", \"mission\", \"mission\", \"mission\", \"mission\", \"mission\", \"mission\", \"mitchell\", \"monitor\", \"monitor\", \"monitor\", \"monitor\", \"monitor\", \"monitor\", \"motif_application\", \"mr\", \"mr\", \"mr\", \"mr\", \"msdo\", \"msdo\", \"msdo\", \"msdo\", \"mtl\", \"muslim\", \"mydisplay\", \"nasa\", \"nasa\", \"nasa\", \"nasa\", \"nasa\", \"nasa\", \"nasa\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"neely\", \"neely\", \"net\", \"net\", \"net\", \"net\", \"net\", \"net\", \"net\", \"neurologist\", \"neuron\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"nj\", \"nj\", \"nj\", \"nj\", \"nj\", \"nl\", \"nl\", \"nl\", \"nl\", \"nl\", \"noonan\", \"noonan\", \"noonan\", \"nope\", \"nope\", \"nope\", \"note\", \"note\", \"note\", \"note\", \"note\", \"note\", \"note\", \"nov\", \"nubus\", \"nubus\", \"nubus_card\", \"obvious\", \"obvious\", \"obvious\", \"obvious\", \"obvious\", \"obvious\", \"oct\", \"offend\", \"offend\", \"offer\", \"offer\", \"offer\", \"offer\", \"offer\", \"offer\", \"offer\", \"oh\", \"oh\", \"oh\", \"oh\", \"oh\", \"okay\", \"okay\", \"okay\", \"okay\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"open_window\", \"organ\", \"original_poster\", \"oriole\", \"os\", \"os\", \"os\", \"os\", \"os\", \"os\", \"packet\", \"particle\", \"pass\", \"pass\", \"pass\", \"pass\", \"pass\", \"pass\", \"pass\", \"patch\", \"patch\", \"patch\", \"patch\", \"patch\", \"paul\", \"paul\", \"paul\", \"paul\", \"paul\", \"paul\", \"paul\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"permission\", \"persuade\", \"phenylalanine\", \"phi\", \"phi\", \"phi\", \"phi\", \"phi\", \"phi\", \"phone\", \"phone\", \"phone\", \"phone\", \"phone\", \"pill\", \"pit\", \"pit\", \"pit\", \"pit\", \"pit\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"plastic\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"player\", \"player\", \"player\", \"player\", \"player\", \"player\", \"player\", \"plug\", \"plug\", \"plug\", \"plug\", \"plug\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"pointer\", \"pointer\", \"pointer\", \"position\", \"position\", \"position\", \"position\", \"position\", \"position\", \"position\", \"post\", \"post\", \"post\", \"post\", \"post\", \"post\", \"post\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power_play_scorer_g\", \"power_play_scorer_g\", \"power_play_scorer_g\", \"power_play_scorer_g\", \"power_play_scorer_g\", \"practical\", \"practical\", \"practical\", \"preferably\", \"preferably\", \"prize\", \"prize\", \"probably\", \"probably\", \"probably\", \"probably\", \"probably\", \"probably\", \"probably\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"profit\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"proton\", \"proton\", \"pt\", \"pt\", \"pt\", \"pt\", \"pt\", \"publish\", \"publish\", \"publish\", \"publish\", \"publish\", \"publish\", \"qi\", \"quadra\", \"quadra\", \"quadra\", \"quadra\", \"question\", \"question\", \"question\", \"question\", \"question\", \"question\", \"question\", \"quiet\", \"raise\", \"raise\", \"raise\", \"raise\", \"ramsey\", \"ramsey\", \"rash\", \"rating\", \"rating\", \"read\", \"read\", \"read\", \"read\", \"read\", \"read\", \"read\", \"reardon\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"rebuild\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"red_sox\", \"red_sox\", \"red_sox\", \"ref\", \"ref\", \"reference\", \"reference\", \"reference\", \"reference\", \"reference\", \"reference\", \"reference\", \"reichel\", \"reichel\", \"repeatedly\", \"require\", \"require\", \"require\", \"require\", \"require\", \"require\", \"require\", \"responsible\", \"responsible\", \"responsible\", \"responsible\", \"reston\", \"resurrection\", \"resurrection\", \"resurrection\", \"resurrection\", \"rev\", \"rev\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"rom\", \"rom\", \"rom\", \"rom\", \"ronn\", \"royal\", \"royal\", \"run\", \"run\", \"run\", \"run\", \"run\", \"run\", \"run\", \"s\", \"s\", \"s\", \"s\", \"s\", \"s\", \"sacred\", \"sander\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"scanner\", \"scanner\", \"scanner\", \"scholar\", \"sci\", \"science\", \"science\", \"science\", \"science\", \"science\", \"science\", \"science\", \"score\", \"score\", \"score\", \"score\", \"score\", \"score\", \"score\", \"scsi\", \"scsi\", \"scsi\", \"scsi\", \"scsi\", \"scsi\", \"scsi\", \"seagate\", \"seagate\", \"sect\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"send\", \"send\", \"send\", \"send\", \"send\", \"send\", \"send\", \"sens\", \"separation\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"sh\", \"sh\", \"sh\", \"sh\", \"shameful_surrender_soon\", \"shameful_surrender_soon\", \"shameful_surrender_soon\", \"share\", \"share\", \"share\", \"share\", \"share\", \"shark\", \"shark\", \"shark\", \"shark\", \"shop\", \"shop\", \"shop\", \"sincerely\", \"single_drive\", \"sinus\", \"skepticism_chastity_intellect\", \"skepticism_chastity_intellect\", \"smartdrive\", \"software\", \"software\", \"software\", \"software\", \"software\", \"software\", \"software\", \"son\", \"son\", \"son\", \"son\", \"son\", \"son\", \"sound_like\", \"sound_like\", \"sound_like\", \"sound_like\", \"sound_like\", \"sp\", \"sp\", \"sp\", \"sp\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"speculation\", \"speed\", \"speed\", \"speed\", \"speed\", \"speed\", \"speed\", \"speed\", \"spin\", \"spin\", \"square\", \"staff\", \"staff\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"starter\", \"starter\", \"starter\", \"store\", \"store\", \"store\", \"store\", \"strict\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"success\", \"success\", \"success\", \"success\", \"sudden\", \"suffer\", \"suffer\", \"suffer\", \"sun\", \"sun\", \"sun\", \"sun\", \"sun\", \"sun\", \"sun\", \"supplement\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"sure\", \"sure\", \"sure\", \"sure\", \"sure\", \"sure\", \"sure\", \"surveillance\", \"symbol\", \"symbol\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"tablet\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk\", \"tape\", \"tape\", \"tape\", \"tape\", \"tape\", \"tape\", \"tape_backup\", \"tape_backup\", \"tape_backup\", \"tar\", \"tar\", \"tb\", \"tb\", \"tb\", \"tb\", \"tb\", \"tb\", \"teaching\", \"teaching\", \"teaching\", \"team\", \"team\", \"team\", \"team\", \"team\", \"team\", \"team\", \"tech_support\", \"technical_support\", \"technician\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"thank\", \"thank\", \"thank\", \"thank\", \"thank\", \"thank\", \"thank\", \"thank_advance\", \"thank_advance\", \"thank_advance\", \"thank_advance\", \"thank_advance\", \"thank_help\", \"thank_help\", \"thank_help\", \"thank_lot\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"thruster\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"timing\", \"tippett\", \"tippett\", \"title\", \"title\", \"title\", \"title\", \"title\", \"title\", \"title\", \"tolerate\", \"tor\", \"tor\", \"tor\", \"tor\", \"tract\", \"transfer_datum\", \"transfer_datum\", \"transmit\", \"trial\", \"trial\", \"trinity\", \"true\", \"true\", \"true\", \"true\", \"true\", \"true\", \"true\", \"try\", \"try\", \"try\", \"try\", \"try\", \"try\", \"try\", \"tuesday\", \"turbo\", \"turbo\", \"uart\", \"united_state\", \"united_state\", \"university\", \"university\", \"university\", \"university\", \"university\", \"university\", \"university\", \"up\", \"usage\", \"usage\", \"usage\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"vaccine\", \"vaccine\", \"vaccine\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"van\", \"van\", \"van\", \"van\", \"van\", \"van\", \"version\", \"version\", \"version\", \"version\", \"version\", \"version\", \"version\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video_card\", \"video_card\", \"video_card\", \"video_card\", \"video_card\", \"viking\", \"violate\", \"virginia\", \"vitamin\", \"voting\", \"w\", \"w\", \"w\", \"w\", \"w\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"widget\", \"widget\", \"widget\", \"widget\", \"widget\", \"widget\", \"widget\", \"william\", \"william\", \"william\", \"win\", \"win\", \"win\", \"win\", \"win\", \"win\", \"win\", \"window\", \"window\", \"window\", \"window\", \"window\", \"window\", \"window\", \"window_manager\", \"window_manager\", \"window_manager\", \"window_manager\", \"window_manager\", \"window_manager\", \"wire\", \"wire\", \"wire\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"wright\", \"wrist\", \"write\", \"write\", \"write\", \"write\", \"write\", \"write\", \"write\", \"wrong\", \"wrong\", \"wrong\", \"wrong\", \"wrong\", \"wrong\", \"wrong\", \"x\", \"x\", \"x\", \"x\", \"x\", \"x\", \"x\", \"x_x\", \"x_x\", \"x_x\", \"x_x\", \"x_x\", \"x_x\", \"x_x\", \"x_x_x\", \"x_x_x\", \"x_x_x\", \"x_x_x\", \"x_x_x\", \"x_x_x\", \"xmu\", \"xmu\", \"xpert\", \"xremote\", \"xt\", \"xt\", \"xt\", \"xt\", \"xterm\", \"xterm\", \"xterm\", \"xterm\", \"xterm\", \"xterm\", \"xterm\", \"xtpointer\", \"xtpointer\", \"xvt\", \"yeah\", \"yeah\", \"yeah\", \"yeah\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 4, 5, 3, 7, 1, 6]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el802711402767692085046047230137\", ldavis_el802711402767692085046047230137_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el802711402767692085046047230137\", ldavis_el802711402767692085046047230137_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el802711402767692085046047230137\", ldavis_el802711402767692085046047230137_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "\n",
    "pyLDAvis.display(LDAvis_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. TOPIC2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argmax example:\n",
    "# >>> kkk\n",
    "# array([[1, 2, 3],\n",
    "#       [0, 4, 2]])\n",
    "# >>> np.argmax(kkk, 0)\n",
    "# array([0, 1, 0])\n",
    "# >>> np.argmax(kkk, 1)\n",
    "# array([2, 1])\n",
    "#\n",
    "# this will select the topic with the most word weight for each word in the vocabulary\n",
    "# after this, we can easily lookup the best topic of each vocabulary word by \n",
    "# most_p_topic[word_voca_index] -> word's topic (0 -7 in this case) \n",
    "most_p_topic = np.argmax(per_topic_distr_LDA, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per_topic_distr_LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17197,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_p_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_and_topic = zip(tf_feature_names, most_p_topic)\n",
    "# word2topic_dict = {word : 'topic_' + np.array_str(topic) for word, topic in word_and_topic}\n",
    "word2topic_dict = {word : 'topic_{}'.format(topic) for word, topic in word_and_topic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('disrespectful', 'topic_4'),\n",
       " ('closed', 'topic_4'),\n",
       " ('fraud', 'topic_5'),\n",
       " ('ventura', 'topic_7'),\n",
       " ('powerful', 'topic_1')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the top 5 words and their belonged topics\n",
    "from itertools import islice\n",
    "list(islice(word2topic_dict.items(), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(document):\n",
    "    text = \"\".join([ch for ch in document if ch not in string.punctuation])\n",
    "    text_list = text.split()\n",
    "    normalized_text = [x.lower() for x in text_list]\n",
    "    # Define an empty list\n",
    "    nostopwords_text = []\n",
    "    # Scan the words\n",
    "    for word in normalized_text:\n",
    "        # Determine if the word is contained in the stop words list\n",
    "        if word not in ENGLISH_STOP_WORDS:\n",
    "            # If the word is not contained I append it\n",
    "            nostopwords_text.append(word)\n",
    "    tokenized_text = [word for word in nostopwords_text if re.search('[a-zA-Z]{2,}', word)]\n",
    "            \n",
    "    return tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_doc_to_topic(tokenized_text, prefix, doc_id_number, word2topic_dict):\n",
    "    doc_to_topic_list = [prefix + '_' + str(doc_id_number)]\n",
    "    # print('adding doc_to_topic header element {}'.format(doc_to_topic_list[0]))\n",
    "\n",
    "    for word in tokenized_text:\n",
    "        if word in word2topic_dict.keys():\n",
    "            doc_to_topic_list.append(word2topic_dict[word])\n",
    "        # else:\n",
    "        #    print('{} not found in word2topic_dict.keys'.format(word))\n",
    "\n",
    "    return doc_to_topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.deprecated.doc2vec import LabeledSentence"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, docs_list, word2topic_dict):\n",
    "        self.labels_list = word2topic_dict\n",
    "        self.docs_list = docs_list\n",
    "    def __iter__(self):\n",
    "        for idx, doc in enumerate(self.docs_list):\n",
    "            words_doc=tokenizer(doc)\n",
    "            tags_doc = map_doc_to_topic(words_doc, idx, word2topic_dict)\n",
    "            yield LabeledSentence(words = words_doc,\n",
    "                                                 tags = tags_doc)\n",
    "            \n",
    "    def sentences_perm(self):\n",
    "        shuffle(models.doc2vec.LabeledSentence)\n",
    "        return models.doc2vec.LabeledSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledLineSentence_training(object):\n",
    "    def __init__(self, sources, word2topic_dict):\n",
    "        self.labels_list = word2topic_dict\n",
    "        self.sources = sources\n",
    "        flipped = {}\n",
    "        # make sure that keys are unique\n",
    "        for key, value in sources.items():\n",
    "            if value not in flipped:\n",
    "                flipped[value] = [key]\n",
    "            else:\n",
    "                raise Exception('Non-unique prefix encountered')\n",
    "    \n",
    "    def __iter__(self):\n",
    "        print('len of sources is {}'.format(len(self.sources)))\n",
    "        for source, prefix in self.sources.items():\n",
    "            print(source)\n",
    "            newsgroups_train_cat = fetch_20newsgroups(subset='train',\n",
    "                                                      remove=('headers', 'footers', 'quotes'),\n",
    "                                                      categories=[source])\n",
    "            # print('len of newsgroups_train_cat is {}'.format(len(newsgroups_train_cat)))\n",
    "            # (Pdb) newsgroups_train_cat.keys() -> \n",
    "            # dict_keys(['data', 'filenames', 'target', 'description', 'DESCR', 'target_names'])\n",
    "            # import pdb; pdb.set_trace()\n",
    "            for idx, doc in enumerate(newsgroups_train_cat.data):\n",
    "                words_doc=tokenizer(doc)\n",
    "                tags_doc = map_doc_to_topic(words_doc, prefix, idx, word2topic_dict)\n",
    "                yield LabeledSentence(words = words_doc,\n",
    "                                                     tags = tags_doc)\n",
    "                \n",
    "    def to_array(self):\n",
    "        self.sentences = []\n",
    "        print('len of sources is {}'.format(len(self.sources)))\n",
    "        for source, prefix in self.sources.items():\n",
    "            newsgroups_train_cat = fetch_20newsgroups(subset='train',\n",
    "                                                      remove=('headers', 'footers', 'quotes'),\n",
    "                                                      categories=[source])\n",
    "            # print('len of newsgroups_train_cat is {}'.format(len(newsgroups_train_cat)))\n",
    "            # import pdb; pdb.set_trace()\n",
    "            # (Pdb) type(newsgroups_train_cat) -> <class 'sklearn.utils.Bunch'> => len is 6\n",
    "            # (Pdb) type(newsgroups_train_cat.data) -> <class 'list'>\n",
    "            # (Pdb) len(newsgroups_train_cat.data) -> 593\n",
    "            # (Pdb) newsgroups_train_cat.data[0] -> document 1 strings, with newlines inside\n",
    "            # (Pdb) newsgroups_train_cat.data[1] -> document 2 strings, with newlines inside\n",
    "            # (Pdb) newsgroups_train_cat.target.shape -> (593,)\n",
    "            # (Pdb) newsgroups_train_cat.target.max() -> 0\n",
    "            for idx, doc in enumerate(newsgroups_train_cat.data):\n",
    "                words_doc=tokenizer(doc)\n",
    "                tags_doc = map_doc_to_topic(words_doc, prefix, idx, word2topic_dict)\n",
    "                self.sentences.append(LabeledSentence(words = words_doc,\n",
    "                                                     tags = tags_doc))\n",
    "        return self.sentences\n",
    "            \n",
    "    def sentences_perm(self):\n",
    "        shuffle(self.sentences)\n",
    "        return self.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3.1 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisit parameters before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comp.sys.ibm.pc.hardware': 'comp_sys_ibm_pc_hardware',\n",
       " 'comp.sys.mac.hardware': 'comp_sys_mac_hardware',\n",
       " 'comp.windows.x': 'comp_windows_x',\n",
       " 'rec.sport.baseball': 'rec_sport_baseball',\n",
       " 'rec.sport.hockey': 'rec_sport_hockey',\n",
       " 'sci.med': 'sci_med',\n",
       " 'sci.space': 'sci_space',\n",
       " 'soc.religion.christian': 'soc_religion_christian'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('disrespectful', 'topic_4'),\n",
       " ('closed', 'topic_4'),\n",
       " ('fraud', 'topic_5'),\n",
       " ('ventura', 'topic_7'),\n",
       " ('powerful', 'topic_1')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(islice(word2topic_dict.items(), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all input news group documents\n",
    "#    For all sentences in that document\n",
    "#        Generate gensim.models.deprecated.doc2vec.LabeledSentence\n",
    "#            (words, tags with group name and word's topics)\n",
    "it = LabeledLineSentence_training(categories_source, word2topic_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quote notes about LabeledSentence and TaggedDocument\n",
    "1. LabeledSentence is an older, deprecated name for the same simple object-type to encapsulate a text-example that is now called TaggedDocument. \n",
    "2. Any objects that have words and tags properties, each a list, will do.\n",
    "    - words is always a list of strings\n",
    "    - tags can be a mix of integers and strings, but in the common and most-efficient case, is just a list with a single id integer, starting at 0.)\n",
    "\n",
    "#### [Info about how to use Gensim doc2vec](https://medium.com/@mishra.thedeepak/doc2vec-in-a-simple-way-fa80bfe81104)\n",
    "1. In this example it uses filename and doc label\n",
    "2. And after the training it can print the vector of the file using its name\n",
    "\n",
    "    ```\n",
    "    docvec = d2v_model.docvecs[‘1.txt’] #if string tag used in training\n",
    "    print docvec\n",
    "    ```\n",
    "3. Or to get most similar document with similarity scores using document-index\n",
    "\n",
    "    ```\n",
    "    similar_doc = d2v_model.docvecs.most_similar(14) \n",
    "    print similar_doc\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of sources is 8\n",
      "sci.space\n",
      "<class 'gensim.models.deprecated.doc2vec.LabeledSentence'>\n",
      "LabeledSentence(['lunar', 'satellite', 'needs', 'fuel', 'regular', 'orbit', 'corrections', 'fuel', 'runs', 'crash', 'months', 'orbits', 'apollo', 'motherships', 'changed', 'noticeably', 'lunar', 'missions', 'lasting', 'days', 'possible', 'stable', 'orbits', 'moons', 'gravitational', 'field', 'poorly', 'mapped', 'know', 'perturbations', 'sun', 'earth', 'relatively', 'minor', 'issues', 'low', 'altitudes', 'big', 'problem', 'moons', 'gravitational', 'field', 'quite', 'lumpy', 'irregular', 'distribution', 'mass', 'moon'], ['sci_space_0', 'topic_5', 'topic_5', 'topic_5', 'topic_7', 'topic_5', 'topic_5', 'topic_1', 'topic_5', 'topic_5', 'topic_1', 'topic_1', 'topic_5', 'topic_5', 'topic_1', 'topic_1', 'topic_5', 'topic_5', 'topic_1', 'topic_7', 'topic_1', 'topic_1', 'topic_1', 'topic_5', 'topic_5', 'topic_1', 'topic_5', 'topic_5', 'topic_5', 'topic_5'])\n",
      "30 48\n",
      "['sci_space_0', 'topic_5', 'topic_5', 'topic_5', 'topic_7', 'topic_5', 'topic_5', 'topic_1', 'topic_5', 'topic_5'] ['lunar', 'satellite', 'needs', 'fuel', 'regular', 'orbit', 'corrections', 'fuel', 'runs', 'crash']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:28: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n"
     ]
    }
   ],
   "source": [
    "# print the first new group's item #1\n",
    "inspect_item = next(iter(it))\n",
    "print(type(inspect_item))\n",
    "print(inspect_item)\n",
    "print(len(inspect_item.tags), len(inspect_item.words))\n",
    "print(inspect_item.tags[:10], inspect_item.words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/gensim/models/doc2vec.py:359: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of sources is 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:50: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n"
     ]
    }
   ],
   "source": [
    "# type(models.Doc2Vec)\n",
    "model = models.Doc2Vec(size=100, window=10, min_count=4, dm=1, dbow_words=1,\n",
    "                              workers=50, alpha=0.025, min_alpha=0.025) # use fixed learning rate\n",
    "model.build_vocab(it.to_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [04:39<00:00, 13.99s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for epoch in tqdm(range(20)):\n",
    "    model.train(it.sentences_perm(), total_examples=model.corpus_count, epochs=1)\n",
    "    model.alpha -= 0.002 # decrease the learning rate\n",
    "    model.min_alpha = model.alpha # fix the learning rate, no decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname =  os.getcwd() # Prints the working directory\n",
    "fname = fname + '/topic2vec_20NG_2_ndoc' + str(n_docs) + 'n_topic' + str(n_topics) + '.model'\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results\n",
    "A quick info about [how to use gensim doc2vec model to query words by label vector or vice versa](https://github.com/RaRe-Technologies/gensim/issues/1397)\n",
    "\n",
    "1. search words using word\n",
    "\n",
    "    ```\n",
    "    model.most_similar('word')\n",
    "    # only similar words were returned but not labels\n",
    "    ```\n",
    "2. search label by label\n",
    "    - use model.docvecs.most_similar to search for similar labels using labels\n",
    "3. search words by label\n",
    "\n",
    "    ```\n",
    "    model.docvecs['label']\n",
    "    model.similar_by_vector(label_vec)\n",
    "    # only similar words were returned\n",
    "    ```\n",
    "4. search labels by word\n",
    "\n",
    "    ```\n",
    "    word_vec = model['word']\n",
    "    model.docvecs.most_similar([word_vec])\n",
    "    # returns similar labels\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from /home/aimladmin/notebooks/home/ksong/Topic2Vec/topic2vec_20NG_2_ndoc4744n_topic8.model\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "\n",
    "# load the model back\n",
    "fname = fname if fname is not None else 'topic2vec_20NG_2_ndoc4744n_topic8.model'\n",
    "print('loading model from {}'.format(fname))\n",
    "d2v_model = models.doc2vec.Doc2Vec.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4752 [('comp_sys_ibm_pc_hardware_354', Doctag(offset=2148, word_count=224, doc_count=1)), ('comp_sys_ibm_pc_hardware_326', Doctag(offset=2120, word_count=13, doc_count=1)), ('comp_windows_x_442', Doctag(offset=4601, word_count=72, doc_count=1)), ('soc_religion_christian_326', Doctag(offset=1521, word_count=10, doc_count=1)), ('comp_sys_ibm_pc_hardware_291', Doctag(offset=2085, word_count=58, doc_count=1))]\n"
     ]
    }
   ],
   "source": [
    "# list the top 5 tags in the model\n",
    "from itertools import islice\n",
    "\n",
    "paragraphs_tag = d2v_model.docvecs.doctags\n",
    "type(paragraphs_tag)\n",
    "print(len(paragraphs_tag), list(islice(paragraphs_tag.items(),5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `doctag_syn0` (Attribute will be removed in 4.0.0, use docvecs.vectors_docs instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4752, 100)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragraphs_vector = d2v_model.docvecs.doctag_syn0\n",
    "ragraphs_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rec_sport_baseball_389', 0.35365036129951477),\n",
       " ('rec_sport_baseball_378', 0.34690025448799133),\n",
       " ('comp_sys_ibm_pc_hardware_563', 0.3393045663833618),\n",
       " ('sci_med_524', 0.3304837942123413),\n",
       " ('comp_sys_mac_hardware_518', 0.32284557819366455),\n",
       " ('sci_med_125', 0.3165658116340637),\n",
       " ('rec_sport_hockey_94', 0.28935739398002625),\n",
       " ('comp_sys_mac_hardware_292', 0.289227157831192),\n",
       " ('rec_sport_hockey_203', 0.285552978515625),\n",
       " ('rec_sport_baseball_449', 0.28499162197113037)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_model.docvecs.most_similar(positive = ['sci_space_96'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lords', 0.39834630489349365),\n",
       " ('doesnt', 0.3908179998397827),\n",
       " ('darling', 0.3805291950702667),\n",
       " ('ahola', 0.35309669375419617),\n",
       " ('worry', 0.3530368208885193),\n",
       " ('destroyed', 0.3495197892189026),\n",
       " ('tale', 0.33816206455230713),\n",
       " ('cpus', 0.33736613392829895),\n",
       " ('lzone', 0.325408935546875),\n",
       " ('ears', 0.3231354355812073)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_vec = d2v_model.docvecs['sci_space_96']\n",
    "d2v_model.wv.similar_by_vector(label_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> top 10 relevant words of topic 0\n",
      "[('al', 0.8068424463272095), ('holds', 0.7901829481124878), ('rd3', 0.7826679944992065), ('percentage', 0.7784439921379089), ('behalf', 0.7727761268615723), ('spouse', 0.7723900079727173), ('intensive', 0.7632749080657959), ('crime', 0.7625982165336609), ('molecular', 0.7587553858757019), ('experimental', 0.7542406320571899)]\n",
      ">>> top 10 relevant words of topic 1\n",
      "[('echohostname', 0.922170877456665), ('hank', 0.9113080501556396), ('echo', 0.9076107144355774), ('set', 0.9072037935256958), ('woof', 0.8928797841072083), ('aaron', 0.8849927186965942), ('tail', 0.8846719264984131), ('iivx', 0.8805248141288757), ('finished', 0.8791848421096802), ('cdrom', 0.8782916069030762)]\n",
      ">>> top 10 relevant words of topic 2\n",
      "[('decs', 0.8631792068481445), ('create', 0.8595727682113647), ('exposuremask', 0.8494325876235962), ('waking', 0.8476630449295044), ('spoke', 0.8470355272293091), ('event', 0.8446255922317505), ('program', 0.8435776829719543), ('meditating', 0.8421506881713867), ('restored', 0.8416558504104614), ('icon', 0.8404950499534607)]\n",
      ">>> top 10 relevant words of topic 3\n",
      "[('crap', 0.7798736095428467), ('dram', 0.7096757292747498), ('fluid', 0.6836119890213013), ('cycle', 0.6735010147094727), ('someones', 0.6624869108200073), ('falling', 0.6527544856071472), ('affect', 0.6497668623924255), ('propulsion', 0.6358532309532166), ('minors', 0.6320293545722961), ('single', 0.6275367736816406)]\n",
      ">>> top 10 relevant words of topic 4\n",
      "[('dreams', 0.7711558938026428), ('mu', 0.7572609186172485), ('mean', 0.7414233684539795), ('connection', 0.7377687692642212), ('judge', 0.7367845177650452), ('explosions', 0.7366541624069214), ('ideas', 0.736388623714447), ('choosing', 0.7312091588973999), ('believed', 0.729036808013916), ('reformat', 0.7234945297241211)]\n",
      ">>> top 10 relevant words of topic 5\n",
      "[('icon', 0.8683058023452759), ('set', 0.8650736808776855), ('mechanism', 0.8590324521064758), ('ms', 0.8565715551376343), ('coordinates', 0.8454750776290894), ('blit', 0.8400388360023499), ('save', 0.8353490829467773), ('xclrs', 0.834591269493103), ('en', 0.8300473690032959), ('woof', 0.8297919034957886)]\n",
      ">>> top 10 relevant words of topic 6\n",
      "[('health', 0.845354437828064), ('snuff', 0.7913036346435547), ('tobacco', 0.7913007736206055), ('pray', 0.783969521522522), ('brother', 0.7774941921234131), ('punishment', 0.776374340057373), ('chewing', 0.7514508962631226), ('sisterinlaw', 0.7512537837028503), ('yankees', 0.7459442019462585), ('smokeless', 0.7427297830581665)]\n",
      ">>> top 10 relevant words of topic 7\n",
      "[('receive', 0.8917831778526306), ('warned', 0.8816089630126953), ('expose', 0.8808605074882507), ('drawable', 0.868147611618042), ('mainwinwin', 0.8607932925224304), ('drawing', 0.846565842628479), ('excerpts', 0.832735538482666), ('detailwinwin', 0.8278787136077881), ('decs', 0.827242374420166), ('receives', 0.8075612783432007)]\n"
     ]
    }
   ],
   "source": [
    "for topic_idx in range(8):\n",
    "    print('>>> top 10 relevant words of topic {}'.format(topic_idx))\n",
    "    topic_vec = d2v_model.docvecs['topic_{}'.format(topic_idx)]\n",
    "    print(d2v_model.wv.similar_by_vector(topic_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sci_space_411', 0.6604948043823242),\n",
       " ('comp_sys_mac_hardware_42', 0.6437797546386719),\n",
       " ('soc_religion_christian_278', 0.6072692275047302),\n",
       " ('rec_sport_baseball_549', 0.5811659097671509),\n",
       " ('comp_windows_x_404', 0.5668190717697144),\n",
       " ('rec_sport_hockey_233', 0.5499863028526306),\n",
       " ('soc_religion_christian_28', 0.5372079610824585),\n",
       " ('comp_sys_mac_hardware_476', 0.47990018129348755),\n",
       " ('comp_sys_mac_hardware_125', 0.47634610533714294),\n",
       " ('soc_religion_christian_226', 0.4659426808357239)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vec = d2v_model['nasa']\n",
    "d2v_model.docvecs.most_similar([word_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.644150725372538"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_model.docvecs.n_similarity(['topic_0', 'topic_2'], ['topic_3', 'topic_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3563553612509076"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_model.docvecs.similarity('topic_0', 'topic_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 FastAI",
   "language": "python",
   "name": "fastai-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
